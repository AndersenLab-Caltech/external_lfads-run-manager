



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Documentation of LFADS Run Manager for Matlab">
      
      
      
        <meta name="author" content="Daniel J. O'Shea">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.2.0">
    
    
      
        <title>Running LFADS - LFADS Run Manager</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.572ca0f0.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#ef5350">
      
    
    
      <script src="../assets/javascripts/modernizr.8c900955.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="red" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#running-lfads" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="LFADS Run Manager" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                LFADS Run Manager
              </span>
              <span class="md-header-nav__topic">
                Running LFADS
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/lfads/lfads-run-manager/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      lfads/lfads-run-manager
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href=".." title="LFADS Run Manager" class="md-tabs__link">
          LFADS Run Manager
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../single-session/" title="Training LFADS" class="md-tabs__link md-tabs__link--active">
          Training LFADS
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../analysis/" title="Analyzing LFADS" class="md-tabs__link">
          Analyzing LFADS
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../files/" title="More details" class="md-tabs__link">
          More details
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="LFADS Run Manager" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    LFADS Run Manager
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/lfads/lfads-run-manager/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      lfads/lfads-run-manager
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      LFADS Run Manager
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        LFADS Run Manager
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href=".." title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../install/" title="Installation" class="md-nav__link">
      Installation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../matlab/" title="Matlab Classes and Packages" class="md-nav__link">
      Matlab Classes and Packages
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../concepts/" title="Key Concepts" class="md-nav__link">
      Key Concepts
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../interfacing/" title="Interfacing with your Datasets" class="md-nav__link">
      Interfacing with your Datasets
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Training LFADS
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Training LFADS
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../single-session/" title="Setting up a single-session run" class="md-nav__link">
      Setting up a single-session run
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Running LFADS
      </label>
    
    <a href="./" title="Running LFADS" class="md-nav__link md-nav__link--active">
      Running LFADS
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lfads-queue-automatically-queueing-many-runs" title="LFADS Queue: Automatically queueing many runs" class="md-nav__link">
    LFADS Queue: Automatically queueing many runs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#launching-each-run-individually-from-shell-scripts" title="Launching each run individually from shell scripts" class="md-nav__link">
    Launching each run individually from shell scripts
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-the-model" title="Training the model" class="md-nav__link">
    Training the model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sampling-the-posterior-means" title="Sampling the posterior means" class="md-nav__link">
    Sampling the posterior means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#writing-the-model-parameters" title="Writing the model parameters" class="md-nav__link">
    Writing the model parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#launching-tensorboard" title="Launching Tensorboard" class="md-nav__link">
    Launching Tensorboard
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../hyperparameters/" title="Hyperparameters" class="md-nav__link">
      Hyperparameters
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../multisession/" title="Multisession Stitched Models" class="md-nav__link">
      Multisession Stitched Models
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Analyzing LFADS
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Analyzing LFADS
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../analysis/" title="Analyzing LFADS Posterior Means" class="md-nav__link">
      Analyzing LFADS Posterior Means
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../trained-params/" title="Loading the Model Trained Parameters" class="md-nav__link">
      Loading the Model Trained Parameters
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      More details
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        More details
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../files/" title="File Organization" class="md-nav__link">
      File Organization
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lfads-queue-automatically-queueing-many-runs" title="LFADS Queue: Automatically queueing many runs" class="md-nav__link">
    LFADS Queue: Automatically queueing many runs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#launching-each-run-individually-from-shell-scripts" title="Launching each run individually from shell scripts" class="md-nav__link">
    Launching each run individually from shell scripts
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-the-model" title="Training the model" class="md-nav__link">
    Training the model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sampling-the-posterior-means" title="Sampling the posterior means" class="md-nav__link">
    Sampling the posterior means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#writing-the-model-parameters" title="Writing the model parameters" class="md-nav__link">
    Writing the model parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#launching-tensorboard" title="Launching Tensorboard" class="md-nav__link">
    Launching Tensorboard
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lfads/lfads-run-manager/edit/master/docs/running.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="running-lfads">Running LFADS<a class="headerlink" href="#running-lfads" title="Permanent link">&para;</a></h1>
<p>To train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call <code class="codehilite">run_lfads.py</code> and do the work of training the model. <code class="codehilite">lfads-run-manager</code> provides two ways to go about this.</p>
<div class="admonition warning">
<p class="admonition-title">Add the <code class="codehilite">run_lfads.py</code> folder to your shell PATH</p>
<p>Be sure that the LFADS python source folder is on your shell path, such that running <code class="codehilite">which run_lfads.py</code> prints the directory where the Python+Tensorflow code LFADS is located. If not, you&rsquo;ll need to run something like <code class="codehilite">export PATH=$PATH:/path/to/models/research/lfads</code> and consider adding this to your <code class="codehilite"><span class="na">.bashrc</span></code> file.</p>
<p>If Matlab is able to determine the location of <code class="codehilite">run_lfads.py</code> (meaning that it&rsquo;s own inherited <code class="codehilite">PATH</code> was set correctly), it will prepend an <code class="codehilite">export PATH=...</code> statement to each generated shell script for you. If not, you can try calling <code class="codehilite">setenv(&#39;PATH&#39;, &#39;...&#39;)</code> from within Matlab to add <code class="codehilite">run_lfads.py</code> to the path. before generating the shell scripts.</p>
<p>Alternatively, you can hard-code the location to <code class="codehilite">run_lfads.py</code> by passing along the fully specified path to each of the <code class="codehilite">writeShellScript...</code> methods as <code class="codehilite">&#39;path_run_lfads_py&#39;, &#39;/path/to/run_lfads.py&#39;</code></p>
</div>
<div class="admonition tip">
<p class="admonition-title">Virtualenv support</p>
<p>Each of the methods below supports a <code class="codehilite"><span class="s">&#39;virtualenv&#39;</span><span class="p">,</span> <span class="s">&#39;environmentName&#39;</span></code> parameter-value argument. If specified, a <code class="codehilite">source activate environmentName</code> will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment (or a conda virtual environment).</p>
</div>
<h2 id="lfads-queue-automatically-queueing-many-runs">LFADS Queue: Automatically queueing many runs<a class="headerlink" href="#lfads-queue-automatically-queueing-many-runs" title="Permanent link">&para;</a></h2>
<p>If you wish to run each LFADS model manually at the command line, <a href="#launching-each-run-individually-from-shell-scripts">skip ahead</a>. However, manually running each of these shell scripts in sequence can be tedious, especially if you don&rsquo;t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the LFADS Queue model queueing system which will take care of training all the LFADS models for you.</p>
<div class="admonition warning">
<p class="admonition-title">Only supported on Linux</p>
<p>Unfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on <code class="codehilite">nvidia-smi</code>, though it&rsquo;s theoretically possible with <code class="codehilite">cuda-smi</code> with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you&rsquo;d need to get <code class="codehilite">tmux</code> working.</p>
</div>
<p>First, we&rsquo;ll generate the Python script from Matlab that enumerates all of the runs:</p>
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">writeShellScriptRunQueue</span><span class="p">(</span><span class="s">&#39;display&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">&#39;virtualenv&#39;</span><span class="p">,</span> <span class="s">&#39;tensorflow&#39;</span><span class="p">);</span>
</pre></div>

<p>Optional parameters include:</p>
<dl>
<dt><strong><code class="codehilite">display</code></strong>:</dt>
<dd>The numeric value of the X display to target. <code class="codehilite">0</code> means target display <code class="codehilite">DISPLAY=:0</code>. A display is needed to draw plots using <code class="codehilite">matplotlib</code>. If you&rsquo;re running on a VM, you may want to launch a VNC Server and point at that display. By default the display will be set according to the <code class="codehilite">DISPLAY</code> environment variable as it is seen inside <code class="codehilite">tmux</code>.</dd>
<dt><strong><code class="codehilite">gpuList</code></strong>:</dt>
<dd>List of GPU indices to include in the queue. By default, this will include all GPUs detected by <code class="codehilite">nvidia-smi</code>.</dd>
<dt><strong><code class="codehilite">runIdx</code></strong>:</dt>
<dd>Scalar indices of all runs to include in the queue. By default this will include all runs in <code class="codehilite"><span class="na">.runs</span></code>.</dd>
<dt><strong><code class="codehilite">virtualenv</code></strong>:</dt>
<dd>String indicating the virtual environment to source before launching the Python LFADS task, where TensorFlow must be installed.</dd>
<dt><strong><code class="codehilite">rerun</code></strong>:</dt>
<dd>By default, any run which already has an <code class="codehilite">lfads.done</code> file in the directory will be skipped, allowing you to regenerate and rerun the queue script whenever new runs are added. If <code class="codehilite">rerun</code> is <code class="codehilite">true</code>, all runs will be executed, although the old LFADS output checkpoint will be used during training. If you want to re-train from scratch, you&rsquo;ll need to delete the <code class="codehilite">lfadsOutput</code> directories, or call <code class="codehilite">rc.deleteLFADSOutput()</code>.</dd>
<dt><strong><code class="codehilite">oneTaskPerGPU</code></strong>:</dt>
<dd>By default, only one LFADS model will be trained per GPU, as empirically we&rsquo;ve found that the switching costs outweigh any benefit from running multiple models simultaneously on each GPU. If you set this to <code class="codehilite">false</code>, ensure that you&rsquo;ve set <code class="codehilite">c_allow_gpu_growth</code> to <code class="codehilite">true</code> in the <code class="codehilite">RunParams</code>.</dd>
<dt><strong><code class="codehilite">gpuMemoryRequired</code></strong></dt>
<dd>Estimated maximum MB of GPU RAM needed per model, used to schedule models onto GPUs when <code class="codehilite">oneTaskPerGPU</code> is <code class="codehilite">false</code>.</dd>
<dt><strong><code class="codehilite">maxTasksSimultaneously</code></strong></dt>
<dd>A manual cap on the number of models to train simultaneously. This is only relevant when <code class="codehilite">oneTaskPerGPU</code> is false, and will default to the number of CPUs minus one.</dd>
<dt><strong><code class="codehilite">prependPathToLFADSQueue</code></strong></dt>
<dd>If true, automatically appends the path to <code class="codehilite">lfadsqueue.py</code> to the <code class="codehilite">PYTHONPATH</code> inside the generated script. Defaults to <code class="codehilite">false</code> to avoid confusion.</dd>
</dl>
<p>This will generate a Python script <code class="codehilite">run_lfads.py</code>, which for our example can be launched via:</p>
<div class="codehilite"><pre><span></span>python ~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py
</pre></div>

<div class="admonition note">
<p class="admonition-title">Run Manager <code class="codehilite">src</code> folder should be added to your <code class="codehilite">PYTHONPATH</code></p>
<p>The <code class="codehilite">run_lfadsqueue.py</code> script depends on <code class="codehilite">lfadsqueue.py</code>, which lives in <code class="codehilite">lfads-run-manager/src</code>. You should add this to your <code class="codehilite">PYTHONPATH</code> or request that it be added to your PYTHONPATH environment variable in the <code class="codehilite">run_lfadsqueue.py</code> script by setting <code class="codehilite">prependPathToLFADSQueue</code> to <code class="codehilite">true</code>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Install and configure <code class="codehilite">tmux</code></p>
<p>The LFADS queue launches each LFADS run inside its own <code class="codehilite">tmux</code> session to make it easy to monitor the runs as they are running. You&rsquo;ll need to install <code class="codehilite">tmux</code>.</p>
<p>Also, <code class="codehilite">tmux</code> is finnicky about environment variables, which are only loaded when the <code class="codehilite">tmux</code> server first launches, not when a new session is started. The main one you need is that <code class="codehilite">run_lfads.py</code> must be on your <code class="codehilite">PATH</code> somewhere. If Matlab is able to determine this location (meaning that it&rsquo;s own inherited <code class="codehilite">PATH</code> was set correctly), it will prepend an <code class="codehilite">export PATH=...</code> statement to each <code class="codehilite">lfads_train.sh</code> script for you. If not, you can try calling <code class="codehilite">setenv(&#39;PATH&#39;, &#39;...&#39;)</code> from within Matlab to add <code class="codehilite">run_lfads.py</code> to the path. before generating the shell scripts.</p>
<p>If you&rsquo;re having trouble, you might want to launch a new <code class="codehilite">tmux</code> session using:</p>
<div class="codehilite"><pre><span></span>tmux new-session
</pre></div>

<p>Then from inside <code class="codehilite">tmux</code>, test that <code class="codehilite">which run_lfads.py</code> prints a location and that you are able to launch python and run <code class="codehilite"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span></code> without any issues.</p>
</div>
<p>You can then kick everything off by running <code class="codehilite">python run_lfadsqueue.py</code> at the command line. It&rsquo;s recommended to do this from inside your own <code class="codehilite">tmux</code> session if you&rsquo;re running on a remote server, so you can monitor the task runner.</p>
<div class="admonition tip">
<p class="admonition-title">Python virtual environments</p>
<p>If tensorflow is installed in a Python virtual environment, you can have this environment be automatically activated via <code class="codehilite">source activate</code> within the training scripts using:
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">writeShellScriptRunQueue</span><span class="p">(</span><span class="s">&#39;virtualenv&#39;</span><span class="p">,</span> <span class="s">&#39;tensorflow&#39;</span><span class="p">);</span>
</pre></div></p>
</div>
<p>A few notes on how the system works:</p>
<ul>
<li>Output from Python will be <code class="codehilite">tee</code>&lsquo;d into <code class="codehilite">lfads.out</code>, so you can check the output during or afterwards either there or in the <code class="codehilite">tmux</code> session.</li>
<li>When a model finishes training and posterior mean sampling, a file called <code class="codehilite">lfads.done</code> will be created</li>
<li>If the task runner detects an <code class="codehilite">lfads.done</code> file, it will skip that run. Unless you pass <code class="codehilite"><span class="s">&#39;rerun&#39;</span><span class="p">,</span> <span class="n">true</span></code> to <code class="codehilite">writeShellScriptRunQueue</code>, in which case every run will be rerun. This is convenient if you&rsquo;ve added additional runs and just want the new ones to run.</li>
<li>If a run fails, the error will be printed by the task runner and <code class="codehilite">lfads.done</code> will not be created</li>
<li>A running tally of how many runs are currently running, have finished, or have failed will be printed</li>
<li>You can enter a run&rsquo;s <code class="codehilite">tmux</code> session directly to monitor it. The list of sessions can be obtained using <code class="codehilite">tmux list-sessions</code>. You can also abort it using <code class="codehilite">Ctrl-C</code> and it will be marked as failed by the task runner.</li>
<li>If you <code class="codehilite">Ctrl-C</code> the <code class="codehilite">run_lfadsqueue.py</code> script itself, the already launched runs will continue running. If you want to abort them, you can <code class="codehilite">pkill python</code> although this will kill all python processes you&rsquo;ve created. In either case, you should be able to relaunch the <code class="codehilite">run_lfadsqueue.py</code> script and have it pick up where it left off as well.</li>
</ul>
<p>The <code class="codehilite">run_lfadsqueue.py</code> script will periodically output updates about how the runs are proceeding:</p>
<div class="codehilite"><pre><span></span><span class="o">(</span>tensorflow<span class="o">)</span> ➜  python run_lfadsqueue.py
Warning: tmux sessions will be nested inside the current session
Queue: Launching TensorBoard on port <span class="m">42561</span> in tmux session exampleRun_tensorboard_port42561
bash /home/djoshea/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh --port<span class="o">=</span><span class="m">42561</span>
Queue: Initializing with <span class="m">2</span> GPUs and <span class="m">12</span> CPUs, max <span class="m">4</span> simultaneous tasks
Task lfads_param_Qr2PeG__single_dataset001: launching on gpu <span class="m">0</span>
Task lfads_param_Qr2PeG__single_dataset001: started in tmux session lfads_param_Qr2PeG__single_dataset001 on GPU <span class="m">0</span> with PID <span class="m">19498</span>
Task lfads_param_Qr2PeG__single_dataset002: launching on gpu <span class="m">1</span>
Task lfads_param_Qr2PeG__single_dataset002: started in tmux session lfads_param_Qr2PeG__single_dataset002 on GPU <span class="m">1</span> with PID <span class="m">19527</span>
Task lfads_param_Qr2PeG__single_dataset003: launching on gpu <span class="m">0</span>
Task lfads_param_Qr2PeG__single_dataset003: started in tmux session lfads_param_Qr2PeG__single_dataset003 on GPU <span class="m">0</span> with PID <span class="m">19551</span>
Task lfads_param_Qr2PeG__all: launching on gpu <span class="m">1</span>
Task lfads_param_Qr2PeG__all: started in tmux session lfads_param_Qr2PeG__all on GPU <span class="m">1</span> with PID <span class="m">19585</span>
Task lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to <span class="m">0</span>.009800.
Task lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to <span class="m">0</span>.009800.
Task lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to <span class="m">0</span>.009604.
Task lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to <span class="m">0</span>.009604.
Task lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to <span class="m">0</span>.009412.
Task lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to <span class="m">0</span>.009412.
</pre></div>

<p>As the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits <code class="codehilite">c_learning_rate_stop</code>). When a task fails or completes, the queue will print out a running tally.</p>
<p>Note that TensorBoard has automatically been launched on an available port, here on <code class="codehilite">42561</code>. You can also directly attach to the tmux sessions whose names are indicated in the script as &ldquo;Tasks&rdquo;, which can be listed using <code class="codehilite">tmux list-sessions</code>.</p>
<div class="codehilite"><pre><span></span><span class="o">(</span>tensorflow<span class="o">)</span> ➜ tmux list-sessions
matlab: <span class="m">4</span> windows <span class="o">(</span>created Tue Oct  <span class="m">3</span> <span class="m">21</span>:51:49 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x114<span class="o">]</span> <span class="o">(</span>attached<span class="o">)</span>
exampleRun_tensorboard_port42561: <span class="m">1</span> windows <span class="o">(</span>created Fri Oct  <span class="m">6</span> <span class="m">14</span>:43:16 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x113<span class="o">]</span>
lfads_param_Qr2PeG__all: <span class="m">1</span> windows <span class="o">(</span>created Fri Oct  <span class="m">6</span> <span class="m">14</span>:43:17 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x113<span class="o">]</span>
lfads_param_Qr2PeG__single_dataset001: <span class="m">1</span> windows <span class="o">(</span>created Fri Oct  <span class="m">6</span> <span class="m">14</span>:43:16 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x114<span class="o">]</span>
lfads_param_Qr2PeG__single_dataset002: <span class="m">1</span> windows <span class="o">(</span>created Fri Oct  <span class="m">6</span> <span class="m">14</span>:43:16 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x113<span class="o">]</span>
lfads_param_Qr2PeG__single_dataset003: <span class="m">1</span> windows <span class="o">(</span>created Fri Oct  <span class="m">6</span> <span class="m">14</span>:43:17 <span class="m">2017</span><span class="o">)</span> <span class="o">[</span>201x113<span class="o">]</span>
</pre></div>

<p>If you wish to abort ongoing runs, you can either attach to them directly and use <code class="codehilite">Ctrl-C</code>, or use <code class="codehilite">tmux kill-session SESSIONNAME</code>. When everything has completed, you&rsquo;ll see something like this:</p>
<div class="codehilite"><pre><span></span>Task lfads_param_Qr2PeG__all: Stopping optimization based on learning rate criteria.
Task lfads_param_Qr2PeG__all: completed successfully
Queue: All tasks completed.
Queue: <span class="m">0</span> skipped, <span class="m">4</span> finished, <span class="m">0</span> failed, <span class="m">0</span> running
</pre></div>

<h2 id="launching-each-run-individually-from-shell-scripts">Launching each run individually from shell scripts<a class="headerlink" href="#launching-each-run-individually-from-shell-scripts" title="Permanent link">&para;</a></h2>
<p>Follow these instructions to run each model individually, but you&rsquo;ll probably prefer to <a href="#lfads-queue-automatically-queueing-many-runs">queue everything at once</a>.</p>
<h3 id="training-the-model">Training the model<a class="headerlink" href="#training-the-model" title="Permanent link">&para;</a></h3>
<p>The first is to manually generate shell scripts for each run and then run them yourself. First, for each run <code class="codehilite">i</code>, you will call:</p>
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">runs</span><span class="p">(</span><span class="nb">i</span><span class="p">).</span><span class="n">writeShellScriptLFADSTrain</span><span class="p">(</span><span class="s">&#39;cuda_visible_devices&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s">&#39;display&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</pre></div>

<p>Here, you should specify options that will be written into the shell script, the key ones being:</p>
<ul>
<li><code class="codehilite">cuda_visible_devices</code> - which GPU index to run this model on, e.g. <code class="codehilite">0</code>. Use the <code class="codehilite">nvidia-smi</code> to enumerate the available GPUs on your system</li>
<li><code class="codehilite">display</code> - the X display to use, e.g. <code class="codehilite">0</code>, which will set <code class="codehilite">DISPLAY</code> to <code class="codehilite">:0</code>. The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you&rsquo;ll need to specify this, and possibly to launch an X server using something like <code class="codehilite">tightvnc</code> or <code class="codehilite">vncserver</code>.</li>
<li><code class="codehilite">appendPosteriorMeanSample</code> - <code class="codehilite">true</code> or <code class="codehilite">false</code> specifying whether to chain the posterior mean sampling operation after the training is finished. The default is <code class="codehilite">false</code>, but if you set this to <code class="codehilite">true</code>, you won&rsquo;t need to call <code class="codehilite">writeShellScriptPosteriorMeanSample</code> below.</li>
<li><code class="codehilite">appendWriteModelParams</code> - <code class="codehilite">true</code> or <code class="codehilite">false</code> specifying whether to chain the posterior mean sampling operation after the training is finished. The default is <code class="codehilite">false</code>, but if you set this to <code class="codehilite">true</code>, you won&rsquo;t need to call <code class="codehilite">writeShellScriptWriteModelParams</code> below.</li>
</ul>
<p>This will generate an <code class="codehilite">lfads_train.sh</code> in the corresponding run&rsquo;s folder. For the first run in our example, this is at
<div class="codehilite"><pre><span></span>~/lorenz_example/runs/exampleSingleSession/param_Qr2PeG/single_dataset001/lfads_train.sh
</pre></div></p>
<p>The script essentially launches Python to run <code class="codehilite">run_lfads.py</code> with the specific parameters you&rsquo;ve indicated in <code class="codehilite">RunParams</code> and pointing at the corresponding datasets, which were saved earlier when we called <code class="codehilite">rc.prepareForLFADS</code>.</p>
<div class="codehilite"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nv">path_to_run_lfads</span><span class="o">=</span><span class="k">$(</span>which run_lfads.py<span class="k">)</span>
<span class="k">if</span> <span class="o">[</span> ! -n <span class="s2">&quot;</span><span class="nv">$path_to_run_lfads</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nb">echo</span> <span class="s2">&quot;Error: run_lfads.py not found on PATH. Ensure you add LFADS to your system PATH.&quot;</span>
    <span class="nb">exit</span> <span class="m">1</span>
<span class="k">fi</span>

<span class="nv">DISPLAY</span><span class="o">=</span>:0 <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span> python <span class="k">$(</span>which run_lfads.py<span class="k">)</span> --data_dir<span class="o">=</span>/home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsInput --data_filename_stem<span class="o">=</span>lfads --lfads_save_dir<span class="o">=</span>/home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsOutput --cell_clip_value<span class="o">=</span><span class="m">5</span>.000000 --factors_dim<span class="o">=</span><span class="m">8</span> --ic_enc_dim<span class="o">=</span><span class="m">64</span> --ci_enc_dim<span class="o">=</span><span class="m">128</span> --gen_dim<span class="o">=</span><span class="m">64</span> --keep_prob<span class="o">=</span><span class="m">0</span>.950000 --learning_rate_decay_factor<span class="o">=</span><span class="m">0</span>.980000 --device<span class="o">=</span>/gpu:0 --co_dim<span class="o">=</span><span class="m">0</span> --do_causal_controller<span class="o">=</span><span class="nb">false</span> --do_feed_factors_to_controller<span class="o">=</span><span class="nb">true</span> --feedback_factors_or_rates<span class="o">=</span>factors --controller_input_lag<span class="o">=</span><span class="m">1</span> --do_train_readin<span class="o">=</span><span class="nb">true</span> --l2_gen_scale<span class="o">=</span><span class="m">500</span>.000000 --l2_con_scale<span class="o">=</span><span class="m">500</span>.000000 --batch_size<span class="o">=</span><span class="m">150</span> --kl_increase_steps<span class="o">=</span><span class="m">900</span> --l2_increase_steps<span class="o">=</span><span class="m">900</span> --ic_dim<span class="o">=</span><span class="m">64</span> --con_dim<span class="o">=</span><span class="m">128</span> --learning_rate_stop<span class="o">=</span><span class="m">0</span>.001000 --temporal_spike_jitter_width<span class="o">=</span><span class="m">0</span> --allow_gpu_growth<span class="o">=</span><span class="nb">true</span> --kl_ic_weight<span class="o">=</span><span class="m">1</span>.000000 --kl_co_weight<span class="o">=</span><span class="m">1</span>.000000 --inject_ext_input_to_gen<span class="o">=</span><span class="nb">false</span>
</pre></div>

<p>Running the <code class="codehilite">lfads_train.sh</code> script will launch the Tensorflow training which will take some time. You likely want to launch this in a <code class="codehilite">tmux</code> session if running remotely.</p>
<h3 id="sampling-the-posterior-means">Sampling the posterior means<a class="headerlink" href="#sampling-the-posterior-means" title="Permanent link">&para;</a></h3>
<p>Next, generate the <code class="codehilite">lfads_posterior_mean_sample.sh</code> script to sample the posterior means, which can be launched after training has completed. If you set <code class="codehilite">appendPosteriorMeanSample</code> to <code class="codehilite">true</code> in <code class="codehilite">writeShellScriptLFADSTrain</code>, you can skip this step.</p>
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">runs</span><span class="p">(</span><span class="nb">i</span><span class="p">).</span><span class="n">writeShellScriptLFADSPosteriorMeanSample</span><span class="p">(</span><span class="s">&#39;cuda_visible_devices&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</pre></div>

<h3 id="writing-the-model-parameters">Writing the model parameters<a class="headerlink" href="#writing-the-model-parameters" title="Permanent link">&para;</a></h3>
<p>Lastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using</p>
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">runs</span><span class="p">(</span><span class="nb">i</span><span class="p">).</span><span class="n">writeShellScriptWriteModelParams</span><span class="p">(</span><span class="s">&#39;cuda_visible_devices&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</pre></div>

<p>If you set <code class="codehilite">appendWriteModelParams</code> to <code class="codehilite">true</code> in <code class="codehilite">writeShellScriptLFADSTrain</code>, you can skip this step. These results will be written to a file called <code class="codehilite">lfadsOutput/model_params</code>, though these results can be loaded into Matlab using <code class="codehilite">run.loadModelTrainedParams()</code>.</p>
<h3 id="launching-tensorboard">Launching Tensorboard<a class="headerlink" href="#launching-tensorboard" title="Permanent link">&para;</a></h3>
<p>You can monitor the progress of each run by generating a script that launches TensorBoard.
<div class="codehilite"><pre><span></span><span class="n">rc</span><span class="p">.</span><span class="n">writeTensorboardShellScript</span><span class="p">();</span>
</pre></div></p>
<p>This will create <code class="codehilite">launch_tensorboard.sh</code> which will launch Tensorboard which can then be visited at <code class="codehilite">http://localhost:PORT</code>.</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../single-session/" title="Setting up a single-session run" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Setting up a single-session run
              </span>
            </div>
          </a>
        
        
          <a href="../hyperparameters/" title="Hyperparameters" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Hyperparameters
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 &mdash; <a href="http://djoshea.com">Daniel J. O&#39;Shea</a>
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/lfads" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://twitter.com/djoshea" class="md-footer-social__link fa fa-twitter"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.b41f3d20.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-322693-7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-322693-7');
</script>

  </body>
</html>