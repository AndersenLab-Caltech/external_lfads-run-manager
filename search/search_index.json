{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LFADS Run Manager for Matlab Documentation \u00b6 LFADS, or Latent Factor Analysis via Dynamical Systems , is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018denoised\u2019 single-trial firing rates from neural spiking data. Read the LFADS manuscript , published at Nature Methods, or the LFADS pre-print for more details. LFADS Run Manager is a set of tools, written in Matlab with some accompanying Python code, that help organize, train, and analyze LFADS models. It accompanies the actual Python+Tensorflow LFADS code which you will also need. We recommend using the Run Manager to organize your LFADS runs and to facilitate generation of the appropriate scripts to train your models and loading of the resulting model predictions for further analysis. LFADS Run Manager was authored by Daniel J O\u2019Shea ( @djoshea ) with contributions from Chethan Pandarinath ( @chethan ), David Sussillo ( @SussilloDavid ), and Reza Keshtkaran. LFADS Run Manager helps you to: Organize your spiking neural datasets that will be used to train LFADS models. Setup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating stitched multisession LFADS models. Generate shell scripts that will launch individual LFADS training runs or generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs. Load the posterior means and parameters of individual LFADS models after each has finished training. Facilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc. The code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on Github . To use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. The goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk. Quick example \u00b6 We\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs. % Identify the datasets you'll be using % Here we'll add one at ~/lorenz_example/datasets/dataset001.mat dc = LorenzExperiment . DatasetCollection ( '~/lorenz_example/datasets' ); dc . name = 'lorenz_example' ; ds = LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); % adds this dataset to the collection dc . loadInfo ; % loads dataset metadata % Run a single model for each dataset, and one stitched run with all datasets runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'example' , dc ); % run files will live at ~/lorenz_example/runs/example/ % Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8 par = LorenzExperiment . RunParams ; par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller outputs --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop really early for the demo parSet = par . generateSweep ( 'c_factors_dim' , [ 2 4 6 8 ]); rc . addParams ( parSet ); % Setup which datasets are included in each run, here just the one runName = dc . datasets ( 1 ). getSingleRunName (); % == 'single_dataset001' rc . addRunSpec ( LorenzExperiment . RunSpec ( runName , dc , 1 )); % Generate files needed for LFADS input on disk rc . prepareForLFADS (); % Write a python script that will train all of the LFADS runs using a % load-balancer against the available CPUs and GPUs rc . writeShellScriptRunQueue ( 'display' , 0 , 'virtualenv' , 'tensorflow' ); You\u2019ve now setup a 1x 4 grid of LFADS runs, spanning 4 different hyperparameter settings all on the same individual dataset >> rc LorenzExperiment . RunCollection \" exampleRun \" ( 16 runs total ) Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleRun 4 parameter settings [ 1 param_7I6XSW data_cgrfui ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 2 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 2 param_O4V73g data_2_zdvC ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 4 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 3 param_ngqEhM data_GeiefE ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 6 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 4 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) name : 'exampleRun' comment : '' rootPath : '~/lorenz_example/runs' version : 20171107 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x4 LorenzExperiment . Run ] params : [ 4 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 4 nRunSpecs : 1 nRunsTotal : 4 nDatasets : 1 datasetNames : { 1 x1 cell } path : '~/lorenz_example/runs/exampleRun' pathsCommonDataForParams : { 4 x1 cell } pathsForParams : { 4 x1 cell } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleRun/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleRun/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleRun/run_lfadsqueue.py' Then you can simply run python run_lfadsqueue.py , a script which was automatically generated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026 As they finish, you can load and visualize the results easily in Matlab. Here we plot the inferred, single-trial firing rates of the first neuron: run = rc . findRuns ( 'single_dataset001' , 1 ); pm = run . loadPosteriorMeans (); rates1 = squeeze ( pm . rates ( 1 , :, :)); % time x trials ... The single-trial smoothed rates, colored by condition then look like:","title":"Overview"},{"location":"#lfads-run-manager-for-matlab-documentation","text":"LFADS, or Latent Factor Analysis via Dynamical Systems , is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018denoised\u2019 single-trial firing rates from neural spiking data. Read the LFADS manuscript , published at Nature Methods, or the LFADS pre-print for more details. LFADS Run Manager is a set of tools, written in Matlab with some accompanying Python code, that help organize, train, and analyze LFADS models. It accompanies the actual Python+Tensorflow LFADS code which you will also need. We recommend using the Run Manager to organize your LFADS runs and to facilitate generation of the appropriate scripts to train your models and loading of the resulting model predictions for further analysis. LFADS Run Manager was authored by Daniel J O\u2019Shea ( @djoshea ) with contributions from Chethan Pandarinath ( @chethan ), David Sussillo ( @SussilloDavid ), and Reza Keshtkaran. LFADS Run Manager helps you to: Organize your spiking neural datasets that will be used to train LFADS models. Setup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating stitched multisession LFADS models. Generate shell scripts that will launch individual LFADS training runs or generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs. Load the posterior means and parameters of individual LFADS models after each has finished training. Facilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc. The code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on Github . To use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. The goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk.","title":"LFADS Run Manager for Matlab Documentation"},{"location":"#quick-example","text":"We\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs. % Identify the datasets you'll be using % Here we'll add one at ~/lorenz_example/datasets/dataset001.mat dc = LorenzExperiment . DatasetCollection ( '~/lorenz_example/datasets' ); dc . name = 'lorenz_example' ; ds = LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); % adds this dataset to the collection dc . loadInfo ; % loads dataset metadata % Run a single model for each dataset, and one stitched run with all datasets runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'example' , dc ); % run files will live at ~/lorenz_example/runs/example/ % Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8 par = LorenzExperiment . RunParams ; par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller outputs --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop really early for the demo parSet = par . generateSweep ( 'c_factors_dim' , [ 2 4 6 8 ]); rc . addParams ( parSet ); % Setup which datasets are included in each run, here just the one runName = dc . datasets ( 1 ). getSingleRunName (); % == 'single_dataset001' rc . addRunSpec ( LorenzExperiment . RunSpec ( runName , dc , 1 )); % Generate files needed for LFADS input on disk rc . prepareForLFADS (); % Write a python script that will train all of the LFADS runs using a % load-balancer against the available CPUs and GPUs rc . writeShellScriptRunQueue ( 'display' , 0 , 'virtualenv' , 'tensorflow' ); You\u2019ve now setup a 1x 4 grid of LFADS runs, spanning 4 different hyperparameter settings all on the same individual dataset >> rc LorenzExperiment . RunCollection \" exampleRun \" ( 16 runs total ) Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleRun 4 parameter settings [ 1 param_7I6XSW data_cgrfui ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 2 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 2 param_O4V73g data_2_zdvC ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 4 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 3 param_ngqEhM data_GeiefE ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 6 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 [ 4 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) name : 'exampleRun' comment : '' rootPath : '~/lorenz_example/runs' version : 20171107 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x4 LorenzExperiment . Run ] params : [ 4 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 4 nRunSpecs : 1 nRunsTotal : 4 nDatasets : 1 datasetNames : { 1 x1 cell } path : '~/lorenz_example/runs/exampleRun' pathsCommonDataForParams : { 4 x1 cell } pathsForParams : { 4 x1 cell } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleRun/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleRun/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleRun/run_lfadsqueue.py' Then you can simply run python run_lfadsqueue.py , a script which was automatically generated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026 As they finish, you can load and visualize the results easily in Matlab. Here we plot the inferred, single-trial firing rates of the first neuron: run = rc . findRuns ( 'single_dataset001' , 1 ); pm = run . loadPosteriorMeans (); rates1 = squeeze ( pm . rates ( 1 , :, :)); % time x trials ... The single-trial smoothed rates, colored by condition then look like:","title":"Quick example"},{"location":"analysis/","text":"Loading and Analyzing LFADS Posterior Means \u00b6 Reusing the drive_script \u00b6 The LFADS.Run instances you created earlier with the drive_script uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters. Using your RunCollection rc , you can access individual runs by indexing directly into rc.runs which has size rc.nRunSpecs x rc.nParams . You can also search for a specific run using rc.findRun run1 = rc . findRuns ( 'single_dataset001' , 'param_pqQbzB' ); The first argument searches over the RunSpec s by name, the second searches over the RunParams by hash value. Loading the posterior means \u00b6 Using the Run instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully): >> run1 . checkPosteriorMeansExist () logical 1 And then load the posterior means using: pm = run1 . loadPosteriorMeans (); Or alternatively, load all of your runs\u2019 posterior means by calling rc.loadPosteriorMeans() . Then you can access the cached posterior means in each run\u2019s .posteriorMeans property. pm will be an instance of LFADS.PosteriorMeans : >> pm = rc . runs ( 1 ). posteriorMeans pm = PosteriorMeans with properties : time : [ 500 x1 double ] controller_outputs : [] factors : [ 8 x500x1560 double ] generator_ics : [ 64 x1560 double ] generator_states : [ 64 x500x1560 double ] rates : [ 29 x500x1560 double ] validInds : [ 312 x1 uint16 ] trainInds : [ 1248 x1 double ] params : [ 1 x1 MyExperiment . RunParams ] isValid : 1 nControllerOutputs : 0 nGeneratorUnits : 64 nFactors : 8 nNeurons : 29 T : 500 nTrials : 1560 Whose key properties are: time : nTime x 1 time vector associated with each of the output fields, which you provided in your generateRatesForDataset() implementation controller_outputs : nControllerOutputs x nTime . Inferred inputs to the generator network. Or empty, if no controller is used ( c_co_dim == 0 ) factors : : nFactors x nTime x nTrials . Factor outputs from the generator network. generator_ics : nGeneratorUnits x nTrials . Initial conditions for the generator units. generator_states : nGeneratorUnits x nTime x nTrials . Trajectories of the generator units. rates : nNeurons x nTime x nTrials . Inferred firing rates of the neurons validInds : List of trial indices used in the validation set trainInds : List of trial indices used in the training set If the run stitches together multiple datasets, then the posteriorMeans will be an nDatasets x 1 vector of LFADS.PosteriorMeans instances, each corresponding to an included dataset. Visualizing the factors \u00b6 Single trial plot of factor 1 on first 10 conditions (color-coded), i.e. pm . factors ( 1 , :, pm . conditionId < = 10 ) . Condition-average plot of factor 1 on all conditions, flanked by standard error of the mean. Comparing factor trajectories across datasets \u00b6 Single-dataset models \u00b6 Looking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models pmSingleRuns = [ rc . runs ( 1 ). loadPosteriorMeans (); ... rc . runs ( 2 ). loadPosteriorMeans (); ... rc . runs ( 3 ). loadPosteriorMeans ()]; Stitched multi-session model \u00b6 However, if we load the posterior means for the stitched multi-session model (named all ). we find that these same factor trajectories are now highly similar across datasets. We can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot. We can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the","title":"Analyzing LFADS Posterior Means"},{"location":"analysis/#loading-and-analyzing-lfads-posterior-means","text":"","title":"Loading and Analyzing LFADS Posterior Means"},{"location":"analysis/#reusing-the-drive_script","text":"The LFADS.Run instances you created earlier with the drive_script uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters. Using your RunCollection rc , you can access individual runs by indexing directly into rc.runs which has size rc.nRunSpecs x rc.nParams . You can also search for a specific run using rc.findRun run1 = rc . findRuns ( 'single_dataset001' , 'param_pqQbzB' ); The first argument searches over the RunSpec s by name, the second searches over the RunParams by hash value.","title":"Reusing the drive_script"},{"location":"analysis/#loading-the-posterior-means","text":"Using the Run instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully): >> run1 . checkPosteriorMeansExist () logical 1 And then load the posterior means using: pm = run1 . loadPosteriorMeans (); Or alternatively, load all of your runs\u2019 posterior means by calling rc.loadPosteriorMeans() . Then you can access the cached posterior means in each run\u2019s .posteriorMeans property. pm will be an instance of LFADS.PosteriorMeans : >> pm = rc . runs ( 1 ). posteriorMeans pm = PosteriorMeans with properties : time : [ 500 x1 double ] controller_outputs : [] factors : [ 8 x500x1560 double ] generator_ics : [ 64 x1560 double ] generator_states : [ 64 x500x1560 double ] rates : [ 29 x500x1560 double ] validInds : [ 312 x1 uint16 ] trainInds : [ 1248 x1 double ] params : [ 1 x1 MyExperiment . RunParams ] isValid : 1 nControllerOutputs : 0 nGeneratorUnits : 64 nFactors : 8 nNeurons : 29 T : 500 nTrials : 1560 Whose key properties are: time : nTime x 1 time vector associated with each of the output fields, which you provided in your generateRatesForDataset() implementation controller_outputs : nControllerOutputs x nTime . Inferred inputs to the generator network. Or empty, if no controller is used ( c_co_dim == 0 ) factors : : nFactors x nTime x nTrials . Factor outputs from the generator network. generator_ics : nGeneratorUnits x nTrials . Initial conditions for the generator units. generator_states : nGeneratorUnits x nTime x nTrials . Trajectories of the generator units. rates : nNeurons x nTime x nTrials . Inferred firing rates of the neurons validInds : List of trial indices used in the validation set trainInds : List of trial indices used in the training set If the run stitches together multiple datasets, then the posteriorMeans will be an nDatasets x 1 vector of LFADS.PosteriorMeans instances, each corresponding to an included dataset.","title":"Loading the posterior means"},{"location":"analysis/#visualizing-the-factors","text":"Single trial plot of factor 1 on first 10 conditions (color-coded), i.e. pm . factors ( 1 , :, pm . conditionId < = 10 ) . Condition-average plot of factor 1 on all conditions, flanked by standard error of the mean.","title":"Visualizing the factors"},{"location":"analysis/#comparing-factor-trajectories-across-datasets","text":"","title":"Comparing factor trajectories across datasets"},{"location":"analysis/#single-dataset-models","text":"Looking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models pmSingleRuns = [ rc . runs ( 1 ). loadPosteriorMeans (); ... rc . runs ( 2 ). loadPosteriorMeans (); ... rc . runs ( 3 ). loadPosteriorMeans ()];","title":"Single-dataset models"},{"location":"analysis/#stitched-multi-session-model","text":"However, if we load the posterior means for the stitched multi-session model (named all ). we find that these same factor trajectories are now highly similar across datasets. We can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot. We can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the","title":"Stitched multi-session model"},{"location":"concepts/","text":"Key Concepts \u00b6 The run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab. LFADS.Dataset \u00b6 A Dataset instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session. LFADS.DatasetCollection \u00b6 A DatasetCollection is a set or array of one or more datasets. LFADS.RunSpec \u00b6 A RunSpec , short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a stitched model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models. LFADS.RunParams \u00b6 A RunParams encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates. When adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a timeWindowPre and timeWindowPost that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g. keepSuccessTrialsOnly or includePerturbationTrials . The advantage of including your dataset-specific hyperparameters in your RunParams subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters. LFADS.Run \u00b6 A Run encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An Run is defined by the combination of an RunSpec instance (which specifies the datasets included) and an RunParams instance (which specifies the hyperparameters). Each Run will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model. LFADS.RunCollection \u00b6 A RunCollection is a set of one or more LFADS.Run s. This collection is organized as a two-dimensional matrix of runs. The first dimension of this matrix is specified by an array of LFADS.RunSpec instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10 LFADS.RunSpec s, each specifying an individual dataset to be included. The second dimension of this matrix is specified by an array of LFADS.RunParams instances. This enables you to vary hyperparameter settings across the runs. Each cell of this matrix, defined by a particular RunSpec and RunParams combination defines a specific Run which can then be generated and trained using Tensorflow.","title":"Key Concepts"},{"location":"concepts/#key-concepts","text":"The run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab.","title":"Key Concepts"},{"location":"concepts/#lfadsdataset","text":"A Dataset instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session.","title":"LFADS.Dataset"},{"location":"concepts/#lfadsdatasetcollection","text":"A DatasetCollection is a set or array of one or more datasets.","title":"LFADS.DatasetCollection"},{"location":"concepts/#lfadsrunspec","text":"A RunSpec , short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a stitched model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models.","title":"LFADS.RunSpec"},{"location":"concepts/#lfadsrunparams","text":"A RunParams encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates. When adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a timeWindowPre and timeWindowPost that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g. keepSuccessTrialsOnly or includePerturbationTrials . The advantage of including your dataset-specific hyperparameters in your RunParams subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters.","title":"LFADS.RunParams"},{"location":"concepts/#lfadsrun","text":"A Run encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An Run is defined by the combination of an RunSpec instance (which specifies the datasets included) and an RunParams instance (which specifies the hyperparameters). Each Run will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model.","title":"LFADS.Run"},{"location":"concepts/#lfadsruncollection","text":"A RunCollection is a set of one or more LFADS.Run s. This collection is organized as a two-dimensional matrix of runs. The first dimension of this matrix is specified by an array of LFADS.RunSpec instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10 LFADS.RunSpec s, each specifying an individual dataset to be included. The second dimension of this matrix is specified by an array of LFADS.RunParams instances. This enables you to vary hyperparameter settings across the runs. Each cell of this matrix, defined by a particular RunSpec and RunParams combination defines a specific Run which can then be generated and trained using Tensorflow.","title":"LFADS.RunCollection"},{"location":"files/","text":"File organization used by LFADS Run Manager \u00b6 You won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to running your model . Run collection organization \u00b6 After running MyExperiment.drive_script and calling rc.prepareForLFADS() , you\u2019ll see the following directory tree on your hard drive: $ tree -L 4 ~/lorenz_example/ . \u251c\u2500\u2500 datasets \u2502 \u251c\u2500\u2500 dataset001.mat \u2502 \u251c\u2500\u2500 dataset002.mat \u2502 \u251c\u2500\u2500 dataset003.mat \u2502 \u2514\u2500\u2500 dataset004.mat \u2514\u2500\u2500 runs \u2514\u2500\u2500 exampleRun \u251c\u2500\u2500 data_RE1kuL \u2502 \u251c\u2500\u2500 all \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 \u2502 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u2502 \u251c\u2500\u2500 single_dataset001 \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 single_dataset002 \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 single_dataset003 \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u251c\u2500\u2500 param_Qr2PeG \u2502 \u251c\u2500\u2500 all \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 single_dataset001 \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 single_dataset002 \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u2514\u2500\u2500 single_dataset003 \u2502 \u2514\u2500\u2500 lfadsInput \u2514\u2500\u2500 summary.txt 9 directories, 13 files datasets : Inside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called LFADS.Utils.generateDemoDatasets(...) . runs : The root runs folder you specified in the constructor to RunCollection . runRoot = '~/lorenz_example/runs' ; rc = MyExperiment . RunCollection ( runRoot , 'exampleRun' , dc ); exampleRun : The location of this specific RunCollection , based on the name you passed to constructor of RunCollection rc = MyExperiment . RunCollection ( runRoot , 'exampleRun' , dc ); data_RE1kuL : The location of the exported datasets for RunParams whose data hash is RE1kuL . The data hash includes properties of RunParams that affect the exported data, as described here . Each subfolder corresponds to the name of a RunSpec . inputInfo_datasetName.mat Contains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets. lfads_datasetName.h5 : The spike counts data directly read by LFADS param_Qr2PeG : : Location of the individual runs generated with the RunParams instance whose param hash is Qr2PeG . The subfolders correspond to the run names passed to RunSpec , and their contents will be discussed below. rc . addRunSpec ( MyExperiment . RunSpec ( 'all' , dc , 1 : dc . nDatasets )); launch_tensorboard.sh : Shell script which will launch TensorBoard, optionally on a specific port sh launch_tensorboard.sh 50000 run_lfadsqueue.py : Python script which will launch the LFADS Run Queue on all runs within the exampleRun RunCollection : python run_lfadsqueue.py Individual run folders \u00b6 Within an run folder, we find: $ tree ~/lorenz_example/runs/exampleRuns/param_Qr2PeG/all . \u251c\u2500\u2500 lfads.done \u251c\u2500\u2500 lfads.out \u251c\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_RE1kuL/all/inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_RE1kuL/all/inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_RE1kuL/all/inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_RE1kuL/all/lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_RE1kuL/all/lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_RE1kuL/all/lfads_dataset003.h5 \u251c\u2500\u2500 lfadsOutput \u2502 \u251c\u2500\u2500 checkpoint \u2502 \u251c\u2500\u2500 checkpoint_lve \u2502 \u251c\u2500\u2500 fitlog.csv \u2502 \u251c\u2500\u2500 hyperparameters-0.txt \u2502 \u251c\u2500\u2500 hyperparameters-38740.txt \u2502 \u251c\u2500\u2500 lfads_log \u2502 \u2502 \u2514\u2500\u2500 events.out... \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001 \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 model_params \u2502 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average \u2502 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average \u2514\u2500\u2500 lfads_train.sh lfadsInput : Contains relative symbolic links to the contents of data_RE1kuL , enabling multiple runs to share data without duplication. The .h5 files will be read in by LFADS. lfadsOutput : The directory to which LFADS will write generated output. Some of the key files within are: checkpoint_lve : Contains the saved checkpoint with the lowest validation error. fitlog.csv : Contains information about the various costs through training hyperparameters-0.txt : Records the hyperparameters used by LFADS model_runs_datasetName.h5_train_posterior_sample_and_average : Contains the posterior mean samples and averages for the training trials model_runs_datasetName.h5_valid_posterior_sample_and_average : Contains the posterior mean samples and averages for the validation trials lfads_train.sh : Shell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager. lfads.done : Empty text file indicating to the LFADS Run Queue that this model has already completed successfully lfads.out : Logged output of LFADS generated by the LFADS Run Queue Clearing LFADS Output \u00b6 If you wanted to re-train a model from scratch, you can call run.deleteLFADSOutput() from Matlab, or you could manually delete the lfadsOutput folder, lfads.done , and lfads.out .","title":"File Organization"},{"location":"files/#file-organization-used-by-lfads-run-manager","text":"You won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to running your model .","title":"File organization used by LFADS Run Manager"},{"location":"files/#run-collection-organization","text":"After running MyExperiment.drive_script and calling rc.prepareForLFADS() , you\u2019ll see the following directory tree on your hard drive: $ tree -L 4 ~/lorenz_example/ . \u251c\u2500\u2500 datasets \u2502 \u251c\u2500\u2500 dataset001.mat \u2502 \u251c\u2500\u2500 dataset002.mat \u2502 \u251c\u2500\u2500 dataset003.mat \u2502 \u2514\u2500\u2500 dataset004.mat \u2514\u2500\u2500 runs \u2514\u2500\u2500 exampleRun \u251c\u2500\u2500 data_RE1kuL \u2502 \u251c\u2500\u2500 all \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 \u2502 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u2502 \u251c\u2500\u2500 single_dataset001 \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 single_dataset002 \u2502 \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u2502 \u2514\u2500\u2500 lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 single_dataset003 \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u251c\u2500\u2500 param_Qr2PeG \u2502 \u251c\u2500\u2500 all \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 single_dataset001 \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 single_dataset002 \u2502 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u2514\u2500\u2500 single_dataset003 \u2502 \u2514\u2500\u2500 lfadsInput \u2514\u2500\u2500 summary.txt 9 directories, 13 files datasets : Inside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called LFADS.Utils.generateDemoDatasets(...) . runs : The root runs folder you specified in the constructor to RunCollection . runRoot = '~/lorenz_example/runs' ; rc = MyExperiment . RunCollection ( runRoot , 'exampleRun' , dc ); exampleRun : The location of this specific RunCollection , based on the name you passed to constructor of RunCollection rc = MyExperiment . RunCollection ( runRoot , 'exampleRun' , dc ); data_RE1kuL : The location of the exported datasets for RunParams whose data hash is RE1kuL . The data hash includes properties of RunParams that affect the exported data, as described here . Each subfolder corresponds to the name of a RunSpec . inputInfo_datasetName.mat Contains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets. lfads_datasetName.h5 : The spike counts data directly read by LFADS param_Qr2PeG : : Location of the individual runs generated with the RunParams instance whose param hash is Qr2PeG . The subfolders correspond to the run names passed to RunSpec , and their contents will be discussed below. rc . addRunSpec ( MyExperiment . RunSpec ( 'all' , dc , 1 : dc . nDatasets )); launch_tensorboard.sh : Shell script which will launch TensorBoard, optionally on a specific port sh launch_tensorboard.sh 50000 run_lfadsqueue.py : Python script which will launch the LFADS Run Queue on all runs within the exampleRun RunCollection : python run_lfadsqueue.py","title":"Run collection organization"},{"location":"files/#individual-run-folders","text":"Within an run folder, we find: $ tree ~/lorenz_example/runs/exampleRuns/param_Qr2PeG/all . \u251c\u2500\u2500 lfads.done \u251c\u2500\u2500 lfads.out \u251c\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_RE1kuL/all/inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_RE1kuL/all/inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_RE1kuL/all/inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_RE1kuL/all/lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_RE1kuL/all/lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_RE1kuL/all/lfads_dataset003.h5 \u251c\u2500\u2500 lfadsOutput \u2502 \u251c\u2500\u2500 checkpoint \u2502 \u251c\u2500\u2500 checkpoint_lve \u2502 \u251c\u2500\u2500 fitlog.csv \u2502 \u251c\u2500\u2500 hyperparameters-0.txt \u2502 \u251c\u2500\u2500 hyperparameters-38740.txt \u2502 \u251c\u2500\u2500 lfads_log \u2502 \u2502 \u2514\u2500\u2500 events.out... \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001 \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index \u2502 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 model_params \u2502 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average \u2502 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average \u2502 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average \u2514\u2500\u2500 lfads_train.sh lfadsInput : Contains relative symbolic links to the contents of data_RE1kuL , enabling multiple runs to share data without duplication. The .h5 files will be read in by LFADS. lfadsOutput : The directory to which LFADS will write generated output. Some of the key files within are: checkpoint_lve : Contains the saved checkpoint with the lowest validation error. fitlog.csv : Contains information about the various costs through training hyperparameters-0.txt : Records the hyperparameters used by LFADS model_runs_datasetName.h5_train_posterior_sample_and_average : Contains the posterior mean samples and averages for the training trials model_runs_datasetName.h5_valid_posterior_sample_and_average : Contains the posterior mean samples and averages for the validation trials lfads_train.sh : Shell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager. lfads.done : Empty text file indicating to the LFADS Run Queue that this model has already completed successfully lfads.out : Logged output of LFADS generated by the LFADS Run Queue","title":"Individual run folders"},{"location":"files/#clearing-lfads-output","text":"If you wanted to re-train a model from scratch, you can call run.deleteLFADSOutput() from Matlab, or you could manually delete the lfadsOutput folder, lfads.done , and lfads.out .","title":"Clearing LFADS Output"},{"location":"hyperparameters/","text":"LFADS Hyperparameters \u00b6 The following is an nearly exhaustive list of hyperparameters that affect the training and posterior mean sampling of the model. If the parameter name begins with c_ , this parameter will be passed to the LFADS Python code directly, without the c_ prefix. All of these values are specified in the RunParams instance that accompanies each Run . While there are many parameters, you will likely care about only a small subset of them. We have color-coded the hyperparameters below according to how often they require tuning: th { font-weight: bold; } tr.hp-common td:first-child { background: #F44336; font-weight: bold; color: #ffffff; } tr.hp-medium td:first-child { background: #FFCDD2; } tr.hp-rare td:first-child { background: #ffffff; color: #455A64; } tbody.hp tr td:first-child { font-family: \"Roboto Mono\",\"Courier New\",Courier,monospace; } Tuning Frequency Description Common Typically requires tuning on a per-project basis and/or is important to set appropriately upfront. Occasional Might be adjusted for fine tuning. Rare Infrequently requires tuning and/or primarily intended for advanced users. Run Manager logistics and data Processing \u00b6 Name Default Description name '' Name of this set of parameters, used for convenience only. Note that this parameter does not affect either the param or data hash. version n/a This value you should not assign directly , as it will automatically be set to match the version of the RunCollection to which it is added. This is used for graceful backwards compatibility. Note that this parameter does not affect either the param or data hash. spikeBinMs 2 Spike bin width in milliseconds. This must be an integer multiple of the original bin width provided by the `Run` class by `generateCountsForDataset`. TensorFlow logistics \u00b6 Name Default Description c_allow_gpu_growth true Allow the GPU to dynamically allocate memory instead of allocating all the GPU's memory at the start c_max_ckpt_to_keep 5 Max number of checkpoints to keep (rolling) c_max_ckpt_to_keep_lve 5 Max number of checkpoints to keep for lowest validation error models (rolling) c_device 'gpu:0' Which visible GPU or CPU to use. Note that GPUs are typically scheduled by setting `CUDA_VISIBLE_DEVICES` rather than using this parameter. Optimization \u00b6 Rather put the learning rate on an exponentially decreasing schedule, the current algorithm pays attention to the learning rate, and if it isn\u2019t regularly decreasing, it will decrease the learning rate. So far, it works fine, though it is not perfect. Name Default Description c_learning_rate_init 0.01 Initial learning rate c_learning_rate_decay_factor 0.95 Factor by which to decrease the learning rate if progress isn't being made. c_learning_rate_n_to_compare 6 Number of previous costs current cost has to be worse than, in order to lower learning rate. c_learning_rate_stop 0.00001 Stop training when the learning rate reaches this threshold. c_max_grad_norm 200 Max norm of gradient before clipping. This sets a value, above which, the gradients will be clipped. This hp is extremely useful to avoid an infrequent, but highly pathological problem whereby the gradient is so large that it destroys the optimization by setting parameters too large, leading to a vicious cycle that ends in NaNs. If it's too large, it's useless, if it's too small, it essentially becomes the learning rate. It's pretty insensitive, though. trainToTestRatio 4 Ratio of training vs testing trials used. c_batch_size 256 Number of trials to use during each training pass. The total trial count must be \u2265 c_batch_size * (trainToTestRatio + 1) . c_cell_clip_value 5 Max value recurrent cell can take before being clipped. If your optimizations start \"NaN-ing out\", reduce this value so that the values of the network don't grow out of control. Typically, once this parameter is set to a reasonable value, one stops having numerical problems. Overfitting \u00b6 If controller is heavily penalized, then it won\u2019t have any output. If dynamics are heavily penalized, then generator won\u2019t make dynamics. Note this l2 penalty is only on the recurrent portion of the RNNs, as dropout is also available, penalizing the feed-forward connections. Name Default Description c_temporal_spike_jitter_width 0 Enables jittering spike times during training. It appears that the system will happily fit spikes (blessing or curse, depending). You may not want this. Jittering the spikes a bit may help (-/+ bin size, as specified here). The idea is to prevent LFADS from trying to learn very fine temporal structure in the data if you believe this to be noise. c_keep_prob 0.95 Fraction of units to randomly drop during each training pass. Dropout is done on the input data, on controller inputs (from encoder), and on outputs from generator to factors. c_l2_gen_scale 500 L2 regularization cost for the generator only. c_co_mean_corr_scale 0 Cost of correlation (through time) in the means of controller output. Underfitting \u00b6 If the primary task of LFADS is \u201cfiltering\u201d of data and not generation, then it is possible that the KL penalty is too strong. Empirically, we have found this to be the case. So we add a hyperparameter in front of the the two KL terms (one for the initial conditions to the generator, the other for the controller outputs). You should always think of the the default values as 1.0, and that leads to a standard VAE formulation whereby the numbers that are optimized are a lower-bound on the log-likelihood of the data. When these 2 HPs deviate from 1.0, one cannot make any statement about what those LL lower bounds mean anymore, and they cannot be compared (AFAIK). Sometimes the task can be sufficiently hard to learn that the optimizer takes the \u2018easy route\u2019, and simply minimizes the KL divergence, setting it to near zero, and the optimization gets stuck. The same possibility is true for the L2 regularizer. One wants a simple generator, for scientific reasons, but not at the expense of hosing the optimization. The last 5 parameters help avoid that by by getting the optimization to \u2018latch\u2019 on to the main optimization, and only turning on the regularizers gradually by increasing their weighting in the overall cost functions later. Name Default Description c_kl_ic_weight 1 Strength of KL weight on initial conditions KL penalty. c_kl_co_weight 1 Strength of KL weight on controller output KL penalty. c_kl_start_step 0 Start increasing KL weight after this many steps. c_kl_increase_steps 900 Number of steps over which the KL weight increases. c_l2_start_step 0 Start increasing L2 weight after this many steps. c_l2_increase_steps 900 Number of steps over which the L2 weight increases. c_l2_start_step 0 Start increasing L2 weight after this many steps scaleIncreaseStepsWithDatasets true If true, c_kl_increase_steps and c_l2_increase_steps will be multiplied by the number of datasets in a stitching run. External inputs \u00b6 If there are observed inputs, there are two ways to add that observed input to the model. The first is by treating as something to be inferred, and thus encoding the observed input via the encoders, and then input to the generator via the \u201cinferred inputs\u201d channel. Second, one can input the input directly into the generator. This has the downside of making the generation process strictly dependent on knowing the observed input for any generated trial. Name Default Description c_ext_input_dim 0 Number of external, known (or observed) inputs. c_inject_ext_input_to_gen false Should the known inputs be input to model via encoders (false) or injected directly into generator (true)? Controller and inferred inputs \u00b6 The controller will be more powerful if it can see the encoding of the entire trial. However, this allows the controller to create inferred inputs that are acausal with respect to the actual data generation process. For example, the data generator could have an input at time t , but the controller, after seeing the entirety of the trial could infer that the input is coming a little before time t , because there are no restrictions on the data the controller sees. One can force the controller to be causal (with respect to perturbations in the data generator) so that it only sees forward encodings of the data at time t that originate at times before or at time t . One can also control the data the controller sees by using an input lag (forward encoding at time t-tlag for controller input at time t . The same can be done in the reverse direction (controller input at time t from reverse encoding at time t+tlag , in the case of an acausal controller). Setting this lag > 0 (even lag=1) can be a powerful way of avoiding very spiky decodes. Finally, one can manually control whether the factors at time t-1 are fed to the controller at time t . If you don\u2019t care about any of this, and just want to smooth your data, set do_causal_controller = False , do_feed_factors_to_controller = True , controller_input_lag = 0 . Name Default Description c_co_dim 4 Number of inferred inputs (controller outputs). This parameter critically controls whether or not there is a controller (along with controller encoders placed into the LFADS graph. If equal to 0, no controller will be added. c_prior_ar_atau 10 Initial autocorrelation of AR(1) priors (in time bins) c_do_train_prior_ar_atau true Is the value for atau an initial value (true) or the constant value (false)? c_prior_ar_nvar 0.1 Initial noise variance for AR(1) priors c_do_train_prior_ar_nvar true Is the value for the noise var an initial value (true) or the constant value (false)? c_do_causal_controller false Restrict input encoder from seeing the future? c_do_feed_factors_to_controller true Should factors[t-1] be input to controller at time t? Strictly speaking, feeding either the factors or the rates to the controller violates causality, since the g0 gets to see all the data. This may or may not be only a theoretical concern. c_feedback_factors_or_rates 'factors' Feedback the factors or the rates to the controller? Set to either 'factors' or 'rates' c_controller_input_lag 1 Time lag on the encoding to controller t-lag for forward, t+lag for reverse. c_ci_enc_dim 128 Network size for controller input encoder. c_con_dim 128 Controller dimensionality. c_co_prior_var_scale 0.1 Variance of control input prior distribution. Encoder and initial conditions for generator \u00b6 Note that the dimension of the initial conditions is separated from the dimensions of the generator initial conditions (and a linear matrix will adapt the shapes if necessary). This is just another way to control complexity. In all likelihood, setting the IC dims to the size of the generator hidden state is just fine. For the initial condition prior variance parameters, it\u2019s best to leave them alone. IThe defaults should be fine for most cases, irregardless of other parameters. If you don\u2019t want the prior variance to be learned, set the following values to the same thing: ic_prior_var_min , ic_prior_var_scale , ic_prior_var_max . The prior mean will still be learned. If you really want to limit the information from encoder to decoder, increase ic_post_var_min above 0. Name Default Description c_num_steps_for_gen_ic MAXINT Number of steps to train the generator initial condition. c_ic_dim 64 Dimensionality of the initial conditions. c_ic_enc_dim 128 Network size for IC encoder. c_ic_prior_var_min 0.1 Minimum variance of IC prior distribution c_ic_prior_var_scale 0.1 Variance of IC prior distribution c_ic_prior_var_max 0.1 Maximum variance of IC prior distribution c_ic_post_var_min 0.0001 Minimum variance of IC posterior distribution Generator network, factors, rates \u00b6 Controlling the size of the generator is one way to control complexity of the dynamics (there is also l2, which will squeeze out unnecessary dynamics also). The modern deep learning approach is to make these cells as large as tolerable (from a waiting perspective), and then regularize them to death with drop out or whatever. It is not clear if this is correct for the LFADS application or not. Name Default Description c_cell_weight_scale 1.0 Input scaling for input weights in generator. The combined recurrent and input weights of the encoder and controller cells are by default set to scale at ws/sqrt(#inputs) with ws=1.0. You can change this scaling with this parameter. c_gen_dim 100 Generator network size/td> c_gen_cell_input_weight_scale 1.0 Input scaling for input weights in generator, which will be divided by sqrt(#inputs) c_gen_cell_rec_weight_scale 1.0 Input scaling for recurrent weights in generator. c_factors_dim 50 Dimensionality of factors read out from generator network. This provides dimensionality reduction from generator dimensionality down to factors and then back out to the neural rates. Note that this property does affect the data and param hashes, unlikely the other c_ prefixed parameters, which only affect the param hash. c_output_dist 'poisson' Type of output distribution for rates, either 'poisson' or 'gaussian' Stitching multi-session models \u00b6 Name Default Description c_do_train_readin true For stitching models, make the readin matrices trainable (true) or fix them to equal the alignment matrices (false). The per-session readin matrices map from neurons to input factors which are fed into the shared encoder. These are initialized by the alignment matrices and can subsequently be fixed or made trainable. useAlignmentMatrix false Whether to use an alignment matrix when stitching datasets together./td> useSingleDatasetAlignmentMatrix false When only using a single dataset, it is also possible to use a readin matrix that reduces the dimensionality of the spikes before inputting these input factors to the encoder networks. If set true, this will set up this readin matrix and seed it with an alignment matrix computed using PCA. alignmentApproach 'regressGlobalPCs' Algorithm to use when calculating the initial alignment (readin) matrices that map from each session-specific set of neurons to common input factors. Default 'regressGlobalPCs' computes the PCs of all neurons together, and then regresses those PCs on the neurons from each session separately. This mapping produces the best possible linear reconstruction of the global PCs from each session. 'ridgeRegressGlobalPCs' does the same but uses ridge regression (L2 regularization) for more robustness, using a lambda value optimized via cross-validation. This approach may yield better results if some neurons are quite variable or exhibit sparse firing. Additional modes can be implemented; see LFADS.Run/prepareAlignmentMatrices which you may override in your derived `Run` class. alignmentExtraArgs {} Extra arguments to be passed by LFADS.Run/prepareAlignmentMatrices , either to LFADS.MultisessionAlignmentTool.computeAlignmentMatricesUsingTrialAveragedPCR in the default implementation, or as additional parameters to a custom alignment algorithm. Posterior sampling \u00b6 Name Default Description posterior_mean_kind 'posterior_sample_and_average' Mechanism to obtain the posterior mean. Either 'posterior_sample_and_average' to take a specified number of samples from the posterior distribution, run them through the model, and average the results. Or 'posterior_push_mean' to use the posterior mean of the ICs and inputs and push those through the model directly. Since there are nonlinearities in the network, this need not be equivalent to the mean of the samples, but in practice it's usually pretty close, and is much faster to compute. Note that this parameter does not affect either the param or data hash. num_samples_posterior 512 Number of samples of the posterior to use when using 'posterior_sample_and_average' . Note that this parameter does not affect either the param or data hash.","title":"Hyperparameters"},{"location":"hyperparameters/#lfads-hyperparameters","text":"The following is an nearly exhaustive list of hyperparameters that affect the training and posterior mean sampling of the model. If the parameter name begins with c_ , this parameter will be passed to the LFADS Python code directly, without the c_ prefix. All of these values are specified in the RunParams instance that accompanies each Run . While there are many parameters, you will likely care about only a small subset of them. We have color-coded the hyperparameters below according to how often they require tuning: th { font-weight: bold; } tr.hp-common td:first-child { background: #F44336; font-weight: bold; color: #ffffff; } tr.hp-medium td:first-child { background: #FFCDD2; } tr.hp-rare td:first-child { background: #ffffff; color: #455A64; } tbody.hp tr td:first-child { font-family: \"Roboto Mono\",\"Courier New\",Courier,monospace; } Tuning Frequency Description Common Typically requires tuning on a per-project basis and/or is important to set appropriately upfront. Occasional Might be adjusted for fine tuning. Rare Infrequently requires tuning and/or primarily intended for advanced users.","title":"LFADS Hyperparameters"},{"location":"hyperparameters/#run-manager-logistics-and-data-processing","text":"Name Default Description name '' Name of this set of parameters, used for convenience only. Note that this parameter does not affect either the param or data hash. version n/a This value you should not assign directly , as it will automatically be set to match the version of the RunCollection to which it is added. This is used for graceful backwards compatibility. Note that this parameter does not affect either the param or data hash. spikeBinMs 2 Spike bin width in milliseconds. This must be an integer multiple of the original bin width provided by the `Run` class by `generateCountsForDataset`.","title":"Run Manager logistics and data Processing"},{"location":"hyperparameters/#tensorflow-logistics","text":"Name Default Description c_allow_gpu_growth true Allow the GPU to dynamically allocate memory instead of allocating all the GPU's memory at the start c_max_ckpt_to_keep 5 Max number of checkpoints to keep (rolling) c_max_ckpt_to_keep_lve 5 Max number of checkpoints to keep for lowest validation error models (rolling) c_device 'gpu:0' Which visible GPU or CPU to use. Note that GPUs are typically scheduled by setting `CUDA_VISIBLE_DEVICES` rather than using this parameter.","title":"TensorFlow logistics"},{"location":"hyperparameters/#optimization","text":"Rather put the learning rate on an exponentially decreasing schedule, the current algorithm pays attention to the learning rate, and if it isn\u2019t regularly decreasing, it will decrease the learning rate. So far, it works fine, though it is not perfect. Name Default Description c_learning_rate_init 0.01 Initial learning rate c_learning_rate_decay_factor 0.95 Factor by which to decrease the learning rate if progress isn't being made. c_learning_rate_n_to_compare 6 Number of previous costs current cost has to be worse than, in order to lower learning rate. c_learning_rate_stop 0.00001 Stop training when the learning rate reaches this threshold. c_max_grad_norm 200 Max norm of gradient before clipping. This sets a value, above which, the gradients will be clipped. This hp is extremely useful to avoid an infrequent, but highly pathological problem whereby the gradient is so large that it destroys the optimization by setting parameters too large, leading to a vicious cycle that ends in NaNs. If it's too large, it's useless, if it's too small, it essentially becomes the learning rate. It's pretty insensitive, though. trainToTestRatio 4 Ratio of training vs testing trials used. c_batch_size 256 Number of trials to use during each training pass. The total trial count must be \u2265 c_batch_size * (trainToTestRatio + 1) . c_cell_clip_value 5 Max value recurrent cell can take before being clipped. If your optimizations start \"NaN-ing out\", reduce this value so that the values of the network don't grow out of control. Typically, once this parameter is set to a reasonable value, one stops having numerical problems.","title":"Optimization"},{"location":"hyperparameters/#overfitting","text":"If controller is heavily penalized, then it won\u2019t have any output. If dynamics are heavily penalized, then generator won\u2019t make dynamics. Note this l2 penalty is only on the recurrent portion of the RNNs, as dropout is also available, penalizing the feed-forward connections. Name Default Description c_temporal_spike_jitter_width 0 Enables jittering spike times during training. It appears that the system will happily fit spikes (blessing or curse, depending). You may not want this. Jittering the spikes a bit may help (-/+ bin size, as specified here). The idea is to prevent LFADS from trying to learn very fine temporal structure in the data if you believe this to be noise. c_keep_prob 0.95 Fraction of units to randomly drop during each training pass. Dropout is done on the input data, on controller inputs (from encoder), and on outputs from generator to factors. c_l2_gen_scale 500 L2 regularization cost for the generator only. c_co_mean_corr_scale 0 Cost of correlation (through time) in the means of controller output.","title":"Overfitting"},{"location":"hyperparameters/#underfitting","text":"If the primary task of LFADS is \u201cfiltering\u201d of data and not generation, then it is possible that the KL penalty is too strong. Empirically, we have found this to be the case. So we add a hyperparameter in front of the the two KL terms (one for the initial conditions to the generator, the other for the controller outputs). You should always think of the the default values as 1.0, and that leads to a standard VAE formulation whereby the numbers that are optimized are a lower-bound on the log-likelihood of the data. When these 2 HPs deviate from 1.0, one cannot make any statement about what those LL lower bounds mean anymore, and they cannot be compared (AFAIK). Sometimes the task can be sufficiently hard to learn that the optimizer takes the \u2018easy route\u2019, and simply minimizes the KL divergence, setting it to near zero, and the optimization gets stuck. The same possibility is true for the L2 regularizer. One wants a simple generator, for scientific reasons, but not at the expense of hosing the optimization. The last 5 parameters help avoid that by by getting the optimization to \u2018latch\u2019 on to the main optimization, and only turning on the regularizers gradually by increasing their weighting in the overall cost functions later. Name Default Description c_kl_ic_weight 1 Strength of KL weight on initial conditions KL penalty. c_kl_co_weight 1 Strength of KL weight on controller output KL penalty. c_kl_start_step 0 Start increasing KL weight after this many steps. c_kl_increase_steps 900 Number of steps over which the KL weight increases. c_l2_start_step 0 Start increasing L2 weight after this many steps. c_l2_increase_steps 900 Number of steps over which the L2 weight increases. c_l2_start_step 0 Start increasing L2 weight after this many steps scaleIncreaseStepsWithDatasets true If true, c_kl_increase_steps and c_l2_increase_steps will be multiplied by the number of datasets in a stitching run.","title":"Underfitting"},{"location":"hyperparameters/#external-inputs","text":"If there are observed inputs, there are two ways to add that observed input to the model. The first is by treating as something to be inferred, and thus encoding the observed input via the encoders, and then input to the generator via the \u201cinferred inputs\u201d channel. Second, one can input the input directly into the generator. This has the downside of making the generation process strictly dependent on knowing the observed input for any generated trial. Name Default Description c_ext_input_dim 0 Number of external, known (or observed) inputs. c_inject_ext_input_to_gen false Should the known inputs be input to model via encoders (false) or injected directly into generator (true)?","title":"External inputs"},{"location":"hyperparameters/#controller-and-inferred-inputs","text":"The controller will be more powerful if it can see the encoding of the entire trial. However, this allows the controller to create inferred inputs that are acausal with respect to the actual data generation process. For example, the data generator could have an input at time t , but the controller, after seeing the entirety of the trial could infer that the input is coming a little before time t , because there are no restrictions on the data the controller sees. One can force the controller to be causal (with respect to perturbations in the data generator) so that it only sees forward encodings of the data at time t that originate at times before or at time t . One can also control the data the controller sees by using an input lag (forward encoding at time t-tlag for controller input at time t . The same can be done in the reverse direction (controller input at time t from reverse encoding at time t+tlag , in the case of an acausal controller). Setting this lag > 0 (even lag=1) can be a powerful way of avoiding very spiky decodes. Finally, one can manually control whether the factors at time t-1 are fed to the controller at time t . If you don\u2019t care about any of this, and just want to smooth your data, set do_causal_controller = False , do_feed_factors_to_controller = True , controller_input_lag = 0 . Name Default Description c_co_dim 4 Number of inferred inputs (controller outputs). This parameter critically controls whether or not there is a controller (along with controller encoders placed into the LFADS graph. If equal to 0, no controller will be added. c_prior_ar_atau 10 Initial autocorrelation of AR(1) priors (in time bins) c_do_train_prior_ar_atau true Is the value for atau an initial value (true) or the constant value (false)? c_prior_ar_nvar 0.1 Initial noise variance for AR(1) priors c_do_train_prior_ar_nvar true Is the value for the noise var an initial value (true) or the constant value (false)? c_do_causal_controller false Restrict input encoder from seeing the future? c_do_feed_factors_to_controller true Should factors[t-1] be input to controller at time t? Strictly speaking, feeding either the factors or the rates to the controller violates causality, since the g0 gets to see all the data. This may or may not be only a theoretical concern. c_feedback_factors_or_rates 'factors' Feedback the factors or the rates to the controller? Set to either 'factors' or 'rates' c_controller_input_lag 1 Time lag on the encoding to controller t-lag for forward, t+lag for reverse. c_ci_enc_dim 128 Network size for controller input encoder. c_con_dim 128 Controller dimensionality. c_co_prior_var_scale 0.1 Variance of control input prior distribution.","title":"Controller and inferred inputs"},{"location":"hyperparameters/#encoder-and-initial-conditions-for-generator","text":"Note that the dimension of the initial conditions is separated from the dimensions of the generator initial conditions (and a linear matrix will adapt the shapes if necessary). This is just another way to control complexity. In all likelihood, setting the IC dims to the size of the generator hidden state is just fine. For the initial condition prior variance parameters, it\u2019s best to leave them alone. IThe defaults should be fine for most cases, irregardless of other parameters. If you don\u2019t want the prior variance to be learned, set the following values to the same thing: ic_prior_var_min , ic_prior_var_scale , ic_prior_var_max . The prior mean will still be learned. If you really want to limit the information from encoder to decoder, increase ic_post_var_min above 0. Name Default Description c_num_steps_for_gen_ic MAXINT Number of steps to train the generator initial condition. c_ic_dim 64 Dimensionality of the initial conditions. c_ic_enc_dim 128 Network size for IC encoder. c_ic_prior_var_min 0.1 Minimum variance of IC prior distribution c_ic_prior_var_scale 0.1 Variance of IC prior distribution c_ic_prior_var_max 0.1 Maximum variance of IC prior distribution c_ic_post_var_min 0.0001 Minimum variance of IC posterior distribution","title":"Encoder and initial conditions for generator"},{"location":"hyperparameters/#generator-network-factors-rates","text":"Controlling the size of the generator is one way to control complexity of the dynamics (there is also l2, which will squeeze out unnecessary dynamics also). The modern deep learning approach is to make these cells as large as tolerable (from a waiting perspective), and then regularize them to death with drop out or whatever. It is not clear if this is correct for the LFADS application or not. Name Default Description c_cell_weight_scale 1.0 Input scaling for input weights in generator. The combined recurrent and input weights of the encoder and controller cells are by default set to scale at ws/sqrt(#inputs) with ws=1.0. You can change this scaling with this parameter. c_gen_dim 100 Generator network size/td> c_gen_cell_input_weight_scale 1.0 Input scaling for input weights in generator, which will be divided by sqrt(#inputs) c_gen_cell_rec_weight_scale 1.0 Input scaling for recurrent weights in generator. c_factors_dim 50 Dimensionality of factors read out from generator network. This provides dimensionality reduction from generator dimensionality down to factors and then back out to the neural rates. Note that this property does affect the data and param hashes, unlikely the other c_ prefixed parameters, which only affect the param hash. c_output_dist 'poisson' Type of output distribution for rates, either 'poisson' or 'gaussian'","title":"Generator network, factors, rates"},{"location":"hyperparameters/#stitching-multi-session-models","text":"Name Default Description c_do_train_readin true For stitching models, make the readin matrices trainable (true) or fix them to equal the alignment matrices (false). The per-session readin matrices map from neurons to input factors which are fed into the shared encoder. These are initialized by the alignment matrices and can subsequently be fixed or made trainable. useAlignmentMatrix false Whether to use an alignment matrix when stitching datasets together./td> useSingleDatasetAlignmentMatrix false When only using a single dataset, it is also possible to use a readin matrix that reduces the dimensionality of the spikes before inputting these input factors to the encoder networks. If set true, this will set up this readin matrix and seed it with an alignment matrix computed using PCA. alignmentApproach 'regressGlobalPCs' Algorithm to use when calculating the initial alignment (readin) matrices that map from each session-specific set of neurons to common input factors. Default 'regressGlobalPCs' computes the PCs of all neurons together, and then regresses those PCs on the neurons from each session separately. This mapping produces the best possible linear reconstruction of the global PCs from each session. 'ridgeRegressGlobalPCs' does the same but uses ridge regression (L2 regularization) for more robustness, using a lambda value optimized via cross-validation. This approach may yield better results if some neurons are quite variable or exhibit sparse firing. Additional modes can be implemented; see LFADS.Run/prepareAlignmentMatrices which you may override in your derived `Run` class. alignmentExtraArgs {} Extra arguments to be passed by LFADS.Run/prepareAlignmentMatrices , either to LFADS.MultisessionAlignmentTool.computeAlignmentMatricesUsingTrialAveragedPCR in the default implementation, or as additional parameters to a custom alignment algorithm.","title":"Stitching multi-session models"},{"location":"hyperparameters/#posterior-sampling","text":"Name Default Description posterior_mean_kind 'posterior_sample_and_average' Mechanism to obtain the posterior mean. Either 'posterior_sample_and_average' to take a specified number of samples from the posterior distribution, run them through the model, and average the results. Or 'posterior_push_mean' to use the posterior mean of the ICs and inputs and push those through the model directly. Since there are nonlinearities in the network, this need not be equivalent to the mean of the samples, but in practice it's usually pretty close, and is much faster to compute. Note that this parameter does not affect either the param or data hash. num_samples_posterior 512 Number of samples of the posterior to use when using 'posterior_sample_and_average' . Note that this parameter does not affect either the param or data hash.","title":"Posterior sampling"},{"location":"install/","text":"Installation \u00b6 These instructions will walk you through the basic setup process to get you up and running with LFADS. Use Python 2.7 While TensorFlow fully supports Python 3, the LFADS code itself does not yet. We expect to fix the few incompatibilities soon, but for now, use Python 2.7. If you\u2019re using Anaconda , you can create a conda environment like this: conda create --name tensorflow python = 2 .7 Install TensorFlow \u00b6 You\u2019ll need to install TensorFlow to run LFADS. Follow the documentation for installing Tensorflow and be sure to install the version for GPUs if you wish to take advantage of the LFADS run queue. You may wish to install everything in a Python virtualenv or inside a conda environment, both of which are supported by lfads-run-manager . Be sure to test that you can import tensorflow in Python correctly: # Python import tensorflow as tf hello = tf . constant ( 'Hello, TensorFlow!' ) sess = tf . Session () print ( sess . run ( hello )) Which should output: Hello, TensorFlow! Install LFADS \u00b6 You\u2019ll then need to clone the Tensorflow models repo containing LFADS somewhere convenient on your system. git clone https://github.com/lfads/models.git Then add this LFADS folder both to your PYTHONPATH and system PATH . The LFADS Run Manager src folder should also be added to your PYTHONPATH . Add the following to your .bashrc : export PYTHONPATH = $PYTHONPATH :/path/to/models/research/lfads/:/path/to/lfads-run-manager/src export PATH = $PATH :/path/to/models/research/lfads/ Ensure that typing which run_lfads.py at your terminal prompt shows the path to run_lfads.py . LFADS depends on the Python libraries h5py and matplotlib being installed as well: pip install h5py matplotlib Install tmux \u00b6 LFADS Run Manager uses tmux to run LFADS within to enable queuing many runs across the available GPUs and to facilitate online monitoring. Fortunately, installing tmux is pretty straightforward on most distributions. Ubuntu: sudo apt-get install tmux Mac: brew install tmux using Homebrew . There are many nice guides to using tmux : A Quick and Easy Guide to tmux - Ham Vocke A tmux Crash Course - Josh Clayton Install LFADS Run Manager \u00b6 Finally, clone the lfads-run-manager repository somewhere convenient on your system. git clone https://github.com/djoshea/lfads-run-manager.git You\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using pathtool or by running: addpath ( '/path/to/lfads-run-manager/src' ) No need to add the subfolders to the path recursively.","title":"Installation"},{"location":"install/#installation","text":"These instructions will walk you through the basic setup process to get you up and running with LFADS. Use Python 2.7 While TensorFlow fully supports Python 3, the LFADS code itself does not yet. We expect to fix the few incompatibilities soon, but for now, use Python 2.7. If you\u2019re using Anaconda , you can create a conda environment like this: conda create --name tensorflow python = 2 .7","title":"Installation"},{"location":"install/#install-tensorflow","text":"You\u2019ll need to install TensorFlow to run LFADS. Follow the documentation for installing Tensorflow and be sure to install the version for GPUs if you wish to take advantage of the LFADS run queue. You may wish to install everything in a Python virtualenv or inside a conda environment, both of which are supported by lfads-run-manager . Be sure to test that you can import tensorflow in Python correctly: # Python import tensorflow as tf hello = tf . constant ( 'Hello, TensorFlow!' ) sess = tf . Session () print ( sess . run ( hello )) Which should output: Hello, TensorFlow!","title":"Install TensorFlow"},{"location":"install/#install-lfads","text":"You\u2019ll then need to clone the Tensorflow models repo containing LFADS somewhere convenient on your system. git clone https://github.com/lfads/models.git Then add this LFADS folder both to your PYTHONPATH and system PATH . The LFADS Run Manager src folder should also be added to your PYTHONPATH . Add the following to your .bashrc : export PYTHONPATH = $PYTHONPATH :/path/to/models/research/lfads/:/path/to/lfads-run-manager/src export PATH = $PATH :/path/to/models/research/lfads/ Ensure that typing which run_lfads.py at your terminal prompt shows the path to run_lfads.py . LFADS depends on the Python libraries h5py and matplotlib being installed as well: pip install h5py matplotlib","title":"Install LFADS"},{"location":"install/#install-tmux","text":"LFADS Run Manager uses tmux to run LFADS within to enable queuing many runs across the available GPUs and to facilitate online monitoring. Fortunately, installing tmux is pretty straightforward on most distributions. Ubuntu: sudo apt-get install tmux Mac: brew install tmux using Homebrew . There are many nice guides to using tmux : A Quick and Easy Guide to tmux - Ham Vocke A tmux Crash Course - Josh Clayton","title":"Install tmux"},{"location":"install/#install-lfads-run-manager","text":"Finally, clone the lfads-run-manager repository somewhere convenient on your system. git clone https://github.com/djoshea/lfads-run-manager.git You\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using pathtool or by running: addpath ( '/path/to/lfads-run-manager/src' ) No need to add the subfolders to the path recursively.","title":"Install LFADS Run Manager"},{"location":"interfacing/","text":"Using LFADS Run Manager with your datasets \u00b6 Copying the LorenzExperiment working example code \u00b6 Below we describe how to use the run manager code with datasets from your specific experiment. The recommended way to begin this process is to copy the folder +LorenzExperiment inside the lfads-run-manager repository to some other folder on your Matlab path, and then to rename it to something related to the experiment, keeping the + in the folder name to keep it in a Matlab package . Below, we\u2019ll stick with the name LorenzExperiment . Each of the classes you have just created are defined to inherit from the corresponding LFADS.ClassName inside the lfads-run-manager repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the +LFADS folder in the repo. Editing the core classes \u00b6 Here we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are: loadData in Dataset.m - specify how to load a dataset from disk. The default implementation assumes that the data live in a .mat file that can be loaded using load . generateCountsForDataset in Run.m - preprocess data and perform spike binning Editing DatasetCollection.m (Optional) \u00b6 Edit the file +LorenzExperiment/DatasetCollection.m . Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor: function ds = DatasetCollection ( path ) ds = ds @ LFADS . DatasetCollection ( path ); end You may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run: dc = LorenzExperiment . DatasetCollection ( '/path/to/experimentData' ); This path will then be used as the parent folder by all of the datasets that are added to this collection. Below is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function filterDatasets to specify the indices or mask over datasets to keep. function filterHavingMinimumTrials ( dc, minTrials ) % example of a function that will filter down datasets based on % their metadata. nTrials = cat ( 1 , dc . datasets . nTrials ); % filterDatasets is provided by DatasetCollection dc . filterDatasets ( nTrials > = minTrials ); end No edits are necessary to DatasetCollection.m to get up and running , but feel free to add any additional methods or properties as needed for your application. Auto-detecting datasets You might consider adding a method to your DatasetCollection class which can automatically detect all of the datasets in a specific folder. An example, which would add every .mat file detected in the folder might look like this: function autoDetectDatasets ( dc ) dc . clearDatasets (); % in case there are existing datasets already added % automatically find all .mat files within dc.path and build datasets for each files = dir ( dc . path ); for iF = 1 : numel ( files ) if strncmp ( files ( iF ). name , '.' , 1 ), continue , end info = files ( iF ); [ ~ , ~ , ext ] = fileparts ( info . name ); if ~ strcmp ( ext , '.mat' ), continue ; end % get YourPackage.Dataset constructor datasetFn = str2func ( strrep ( class ( r ), 'DatasetCollection' , 'Dataset' )); ds = datasetFn ( dc , info . name ); end end Editing Dataset.m (Required) \u00b6 Edit the file +LorenzExperiment/Dataset.m . Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset. First, look at the constructor. function ds = Dataset ( collection, relPath ) ds = ds @ LFADS . Dataset ( collection , relPath ); end In order to encapsulate a particular dataset on disk, you will create a new LorenzExperiment.Dataset instance in Matlab. The first argument collection is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument relPath specifies the path to this dataset relative to the collection. For example, if the dataset were stored in /path/to/experimentalData/dataset001.mat , you might run: ds1 = LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); You may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s load method and assumes that ds.path points to a .mat file. ds.path will be equal to the dataset collection path joined to relPath . If your data is stored differently, you will need to replace the implementation of loadData : function data = loadData ( ds ) % load this dataset's data file from .path in = load ( ds . path ); data = in . data ; end You can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the Dataset class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property infoLoaded can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed. function loadInfo ( ds ) % Load this Dataset's metadata if not already loaded if ds . infoLoaded , return ; end % modify this to extract the metadata loaded from the data file data = ds . loadData (); ds . subject = data . subject ; ds . saveTags = data . saveTags ; ds . datenum = data . datenum ; ds . nChannels = data . nChannels ; ds . nTrials = numel ( data . trials ); ds . infoLoaded = true ; end The metadata fields you might assign are as follows: subject - dataset subject or participant name datenum - a Matlab datenum identifying the collection time of the dataset nChannels - the number of unique spiking channels recorded in this dataset nTrials - the number of trials included in this dataset saveTags - a vector of numbers indicating within-day blocks of trials included Metadata are optional We note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your Dataset class. Editing RunParams.m (Optional) \u00b6 Edit the file +LorenzExperiment/RunParams.m . Recall that RunParams encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add. You can add these additional properties anywhere in the file: classdef RunParams < LFADS . RunParams properties % Add additional custom parameters here. The default you assign to % them will be used when computing the hash value. Any params whose value % differs from the default will be included in the hash value, to allow new % parameters to be added without invalidating old hashes. So choose % the default once and don't change it. If you decide to use another % value later by default, override it in the constructor instead. end Pick default values carefully The default values you assign next to each property should be chosen carefully and never changed once added. The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the RunParams constructor without affecting the hash. However, you will then want to manually assign this property to its old value in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values. Specifying data-hash affecting parameters As described here , the parameter values inside RunParams will be used to generate two different hashes, a param_ hash that includes all properties that affect LFADS whose values differ from their defaults, and a data_ hash that includes the subset of those properties that affect the raw data input to LFADS. This design allows us to reuse data on disk when sweeping parameters that only affect LFADS internal architecture, e.g. the size of the generator RNN. By default, the data_ hash includes all properties that do not begin with c_ as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to RunParams . If you need to adjust this behavior, override the method getListPropertiesNotAffectingInputData in your RunParams instance. You should probably take a union of your custom properties with the properties returned by the superclass method LFADS . Run / getListPropertiesNotAffectingInputData . No changes are required to RunParams.m to get up and running. Editing RunCollection.m (Optional) \u00b6 Edit the file +LorenzExperiment/RunCollection.m . Recall that a RunCollection specifies a set of individual LFADS runs defined by an array of RunSpec s crossed with an array of RunParams . classdef RunCollection < LFADS . RunCollection % no need to modify anything here, but feel free to add useful methods % and properties as useful methods function rc = RunCollection ( varargin ) rc @ LFADS . RunCollection ( varargin {:}); end end end No changes are required to RunCollection.m to get up and running , but you can add any utility methods to facilitate analysis for your specific application. Editing Run.m (Required) \u00b6 Edit the file +LorenzExperiment/Run.m . Recall that a Run represents a specific LFADS model training run. The main function you will need to provide a definition for is generateCountsForDataset . This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this: function out = generateCountsForDataset ( r, dataset, mode, varargin ) Here, r refers to the LorenzExperiment.Run instance. It may be particularly helpful to refer to the RunParams instance assigned to this run via r.params , especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included. Inputs to generateCountsForDataset : \u00b6 r : The Run instance. The current RunParams instance can be accessed through r.params . dataset : LorenzExperiment.Dataset instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run, generateCountsForDataset will be called once for each dataset, one at a time. You might use dataset.loadData() to load the actual data, as you defined above. mode : String that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined: export - indicates that the sequence data will be exported as the actual input to the Python+Tensorflow LFADS run alignment - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run. If you decide you do wish to handle the alignment case differently, you will need to override the usesDifferentDataForAlignment method in your Run class to return true , by adding: function tf = usesDifferentDataForAlignment ( r ) tf = true ; end varargin : Currently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g. 'paramName' , paramValue , ... ) in the future without breaking existing implementations. Outputs to generateCountsForDataset : \u00b6 out : A scalar struct which holds the following fields: . counts (Required): A tensor of binned spike counts (not rates) with size nTrials x nChannels x nTime . These should be total counts, not normalized rates, as they will be added together during re-binning. . timeVecMs (Optional): A vector of timepoints with length nTime in milliseconds associated with each time bin in counts . You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the raw spike bin width used when the data are later rebinned to match r.params.spikeBinMs . Default is 1 : size ( counts , 3 ) . . conditionId (Optional): Vector with length nTrials identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector. Default is [] . . truth (Optional): For synthetic datasets, provides the ground-truth counts for each trial. Same size as .counts . Default is [] . . externalInputs (Optional): Specifies the observed, external inputs which will be passed either to the generator directly or to the encoder. Default is [] . A note on bin widths There are two different bin widths in lfads-run-manager . First is this binWidthMs within seq , which is the spike binning that you will do to the data inside generateCountsForDataset . We recommend binning here at 1 ms or the smallest bin width you might wish to use. Second is the field spikeBinMs inside the RunParams class. The expectation is that you will bin using a small bin width inside generateCountsForDataset , and then the run manager code will automatically re-bin the data at the larger bin width set by r.params.spikeBinMs for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.","title":"Interfacing with your Datasets"},{"location":"interfacing/#using-lfads-run-manager-with-your-datasets","text":"","title":"Using LFADS Run Manager with your datasets"},{"location":"interfacing/#copying-the-lorenzexperiment-working-example-code","text":"Below we describe how to use the run manager code with datasets from your specific experiment. The recommended way to begin this process is to copy the folder +LorenzExperiment inside the lfads-run-manager repository to some other folder on your Matlab path, and then to rename it to something related to the experiment, keeping the + in the folder name to keep it in a Matlab package . Below, we\u2019ll stick with the name LorenzExperiment . Each of the classes you have just created are defined to inherit from the corresponding LFADS.ClassName inside the lfads-run-manager repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the +LFADS folder in the repo.","title":"Copying the LorenzExperiment working example code"},{"location":"interfacing/#editing-the-core-classes","text":"Here we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are: loadData in Dataset.m - specify how to load a dataset from disk. The default implementation assumes that the data live in a .mat file that can be loaded using load . generateCountsForDataset in Run.m - preprocess data and perform spike binning","title":"Editing the core classes"},{"location":"interfacing/#editing-datasetcollectionm-optional","text":"Edit the file +LorenzExperiment/DatasetCollection.m . Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor: function ds = DatasetCollection ( path ) ds = ds @ LFADS . DatasetCollection ( path ); end You may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run: dc = LorenzExperiment . DatasetCollection ( '/path/to/experimentData' ); This path will then be used as the parent folder by all of the datasets that are added to this collection. Below is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function filterDatasets to specify the indices or mask over datasets to keep. function filterHavingMinimumTrials ( dc, minTrials ) % example of a function that will filter down datasets based on % their metadata. nTrials = cat ( 1 , dc . datasets . nTrials ); % filterDatasets is provided by DatasetCollection dc . filterDatasets ( nTrials > = minTrials ); end No edits are necessary to DatasetCollection.m to get up and running , but feel free to add any additional methods or properties as needed for your application. Auto-detecting datasets You might consider adding a method to your DatasetCollection class which can automatically detect all of the datasets in a specific folder. An example, which would add every .mat file detected in the folder might look like this: function autoDetectDatasets ( dc ) dc . clearDatasets (); % in case there are existing datasets already added % automatically find all .mat files within dc.path and build datasets for each files = dir ( dc . path ); for iF = 1 : numel ( files ) if strncmp ( files ( iF ). name , '.' , 1 ), continue , end info = files ( iF ); [ ~ , ~ , ext ] = fileparts ( info . name ); if ~ strcmp ( ext , '.mat' ), continue ; end % get YourPackage.Dataset constructor datasetFn = str2func ( strrep ( class ( r ), 'DatasetCollection' , 'Dataset' )); ds = datasetFn ( dc , info . name ); end end","title":"Editing DatasetCollection.m (Optional)"},{"location":"interfacing/#editing-datasetm-required","text":"Edit the file +LorenzExperiment/Dataset.m . Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset. First, look at the constructor. function ds = Dataset ( collection, relPath ) ds = ds @ LFADS . Dataset ( collection , relPath ); end In order to encapsulate a particular dataset on disk, you will create a new LorenzExperiment.Dataset instance in Matlab. The first argument collection is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument relPath specifies the path to this dataset relative to the collection. For example, if the dataset were stored in /path/to/experimentalData/dataset001.mat , you might run: ds1 = LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); You may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s load method and assumes that ds.path points to a .mat file. ds.path will be equal to the dataset collection path joined to relPath . If your data is stored differently, you will need to replace the implementation of loadData : function data = loadData ( ds ) % load this dataset's data file from .path in = load ( ds . path ); data = in . data ; end You can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the Dataset class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property infoLoaded can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed. function loadInfo ( ds ) % Load this Dataset's metadata if not already loaded if ds . infoLoaded , return ; end % modify this to extract the metadata loaded from the data file data = ds . loadData (); ds . subject = data . subject ; ds . saveTags = data . saveTags ; ds . datenum = data . datenum ; ds . nChannels = data . nChannels ; ds . nTrials = numel ( data . trials ); ds . infoLoaded = true ; end The metadata fields you might assign are as follows: subject - dataset subject or participant name datenum - a Matlab datenum identifying the collection time of the dataset nChannels - the number of unique spiking channels recorded in this dataset nTrials - the number of trials included in this dataset saveTags - a vector of numbers indicating within-day blocks of trials included Metadata are optional We note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your Dataset class.","title":"Editing Dataset.m (Required)"},{"location":"interfacing/#editing-runparamsm-optional","text":"Edit the file +LorenzExperiment/RunParams.m . Recall that RunParams encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add. You can add these additional properties anywhere in the file: classdef RunParams < LFADS . RunParams properties % Add additional custom parameters here. The default you assign to % them will be used when computing the hash value. Any params whose value % differs from the default will be included in the hash value, to allow new % parameters to be added without invalidating old hashes. So choose % the default once and don't change it. If you decide to use another % value later by default, override it in the constructor instead. end Pick default values carefully The default values you assign next to each property should be chosen carefully and never changed once added. The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the RunParams constructor without affecting the hash. However, you will then want to manually assign this property to its old value in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values. Specifying data-hash affecting parameters As described here , the parameter values inside RunParams will be used to generate two different hashes, a param_ hash that includes all properties that affect LFADS whose values differ from their defaults, and a data_ hash that includes the subset of those properties that affect the raw data input to LFADS. This design allows us to reuse data on disk when sweeping parameters that only affect LFADS internal architecture, e.g. the size of the generator RNN. By default, the data_ hash includes all properties that do not begin with c_ as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to RunParams . If you need to adjust this behavior, override the method getListPropertiesNotAffectingInputData in your RunParams instance. You should probably take a union of your custom properties with the properties returned by the superclass method LFADS . Run / getListPropertiesNotAffectingInputData . No changes are required to RunParams.m to get up and running.","title":"Editing RunParams.m (Optional)"},{"location":"interfacing/#editing-runcollectionm-optional","text":"Edit the file +LorenzExperiment/RunCollection.m . Recall that a RunCollection specifies a set of individual LFADS runs defined by an array of RunSpec s crossed with an array of RunParams . classdef RunCollection < LFADS . RunCollection % no need to modify anything here, but feel free to add useful methods % and properties as useful methods function rc = RunCollection ( varargin ) rc @ LFADS . RunCollection ( varargin {:}); end end end No changes are required to RunCollection.m to get up and running , but you can add any utility methods to facilitate analysis for your specific application.","title":"Editing RunCollection.m (Optional)"},{"location":"interfacing/#editing-runm-required","text":"Edit the file +LorenzExperiment/Run.m . Recall that a Run represents a specific LFADS model training run. The main function you will need to provide a definition for is generateCountsForDataset . This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this: function out = generateCountsForDataset ( r, dataset, mode, varargin ) Here, r refers to the LorenzExperiment.Run instance. It may be particularly helpful to refer to the RunParams instance assigned to this run via r.params , especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included.","title":"Editing Run.m (Required)"},{"location":"interfacing/#inputs-to-generatecountsfordataset","text":"r : The Run instance. The current RunParams instance can be accessed through r.params . dataset : LorenzExperiment.Dataset instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run, generateCountsForDataset will be called once for each dataset, one at a time. You might use dataset.loadData() to load the actual data, as you defined above. mode : String that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined: export - indicates that the sequence data will be exported as the actual input to the Python+Tensorflow LFADS run alignment - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run. If you decide you do wish to handle the alignment case differently, you will need to override the usesDifferentDataForAlignment method in your Run class to return true , by adding: function tf = usesDifferentDataForAlignment ( r ) tf = true ; end varargin : Currently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g. 'paramName' , paramValue , ... ) in the future without breaking existing implementations.","title":"Inputs to generateCountsForDataset:"},{"location":"interfacing/#outputs-to-generatecountsfordataset","text":"out : A scalar struct which holds the following fields: . counts (Required): A tensor of binned spike counts (not rates) with size nTrials x nChannels x nTime . These should be total counts, not normalized rates, as they will be added together during re-binning. . timeVecMs (Optional): A vector of timepoints with length nTime in milliseconds associated with each time bin in counts . You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the raw spike bin width used when the data are later rebinned to match r.params.spikeBinMs . Default is 1 : size ( counts , 3 ) . . conditionId (Optional): Vector with length nTrials identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector. Default is [] . . truth (Optional): For synthetic datasets, provides the ground-truth counts for each trial. Same size as .counts . Default is [] . . externalInputs (Optional): Specifies the observed, external inputs which will be passed either to the generator directly or to the encoder. Default is [] . A note on bin widths There are two different bin widths in lfads-run-manager . First is this binWidthMs within seq , which is the spike binning that you will do to the data inside generateCountsForDataset . We recommend binning here at 1 ms or the smallest bin width you might wish to use. Second is the field spikeBinMs inside the RunParams class. The expectation is that you will bin using a small bin width inside generateCountsForDataset , and then the run manager code will automatically re-bin the data at the larger bin width set by r.params.spikeBinMs for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.","title":"Outputs to generateCountsForDataset:"},{"location":"matlab/","text":"Matlab language features used \u00b6 The run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. The run manager code also makes use of packages, which helps you organize your code so that names don\u2019t collide in the Matlab path. If you are familiar with these aspects of Matlab programming, skip ahead to Key Concepts . Matlab Classes \u00b6 While there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks: Role of Classes in Matlab Class Syntax Guide In writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though it is not necessary to deeply understand classes in Matlab in order to get up and running . If you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a struct type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term class refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an instance , and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class. y = 3.0 ; myInstance = MyClass (); In this code, y is a normal Matlab variable whose type is double (double-precision floating point). myInstance is an instance whose type is the class MyClass . For illustration of a complete class definition, consider a class Multiplier whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file Mulitplier.m as follows: classdef Multiplier < handle properties gain = 1 ; % constant by which inputs are multiplied end methods % this method is called a constructor, and will be called when creating % new instances of this class. Here we provide a way to specify the gain % when creating the instance function obj = Multiplier ( theGain ) if nargin > 1 obj . gain = theGain ; end end % this method does the actual multiplication. The first argument always refers % to the instance variable itself, enabling you to refer to properties and other % methods in that instance. Otherwise, the code acts like a normal Matlab function function out = mutliply ( obj, in ) out = in * obj . gain ; end end end With this definition complete, we can then use the class at the command line as follows: >> myMult = Multiplier ( 5 ); >> myMult . multiply ( 10 ) 50 >> myOtherMult = Multiplier ( 2 ); >> myOtherMult . multiply ( 10 ) 20 >> myMult . gain = 3 ; % only affects myMult, not myOtherMult >> myMult . multiply ( 10 ) 30 >> myOtherMult . multiply ( 10 ) 20 Here, note that myMult is a Matlab variable which holds an instance of the class Mutliplier . We then assign a value to the property gain of this instance, and then call the method multiply . Matlab Packages \u00b6 The run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a + . Within Matlab, you will then refer to these classes by prefixing the class names with the package name. So within Matlab, LFADS.Run refers to the class located on the file system at +LFADS/Run.m . The main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called +ReachingTask , and within it copy the starter code provided from +LorenzExperiment . Then you can refer to ReachingTask.Dataset and ReachingTask.Run from within Matlab.","title":"Matlab Classes and Packages"},{"location":"matlab/#matlab-language-features-used","text":"The run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. The run manager code also makes use of packages, which helps you organize your code so that names don\u2019t collide in the Matlab path. If you are familiar with these aspects of Matlab programming, skip ahead to Key Concepts .","title":"Matlab language features used"},{"location":"matlab/#matlab-classes","text":"While there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks: Role of Classes in Matlab Class Syntax Guide In writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though it is not necessary to deeply understand classes in Matlab in order to get up and running . If you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a struct type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term class refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an instance , and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class. y = 3.0 ; myInstance = MyClass (); In this code, y is a normal Matlab variable whose type is double (double-precision floating point). myInstance is an instance whose type is the class MyClass . For illustration of a complete class definition, consider a class Multiplier whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file Mulitplier.m as follows: classdef Multiplier < handle properties gain = 1 ; % constant by which inputs are multiplied end methods % this method is called a constructor, and will be called when creating % new instances of this class. Here we provide a way to specify the gain % when creating the instance function obj = Multiplier ( theGain ) if nargin > 1 obj . gain = theGain ; end end % this method does the actual multiplication. The first argument always refers % to the instance variable itself, enabling you to refer to properties and other % methods in that instance. Otherwise, the code acts like a normal Matlab function function out = mutliply ( obj, in ) out = in * obj . gain ; end end end With this definition complete, we can then use the class at the command line as follows: >> myMult = Multiplier ( 5 ); >> myMult . multiply ( 10 ) 50 >> myOtherMult = Multiplier ( 2 ); >> myOtherMult . multiply ( 10 ) 20 >> myMult . gain = 3 ; % only affects myMult, not myOtherMult >> myMult . multiply ( 10 ) 30 >> myOtherMult . multiply ( 10 ) 20 Here, note that myMult is a Matlab variable which holds an instance of the class Mutliplier . We then assign a value to the property gain of this instance, and then call the method multiply .","title":"Matlab Classes"},{"location":"matlab/#matlab-packages","text":"The run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a + . Within Matlab, you will then refer to these classes by prefixing the class names with the package name. So within Matlab, LFADS.Run refers to the class located on the file system at +LFADS/Run.m . The main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called +ReachingTask , and within it copy the starter code provided from +LorenzExperiment . Then you can refer to ReachingTask.Dataset and ReachingTask.Run from within Matlab.","title":"Matlab Packages"},{"location":"multisession/","text":"Multi-dataset Stitching Models \u00b6 If you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a RunSpec , the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through read-in and readout alignment matrices. Below is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset. A similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial. Generating alignment matrices \u00b6 These read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a RunSpec , and the hyperparameter useAlignmentMatrix is set to true in the RunParams , then lfads-run-manager will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as: Generate condition-averaged firing rates for each neuron for each condition for each dataset Concatenate all of neurons from all datasets together to build a matrix which is ( nTime * nConditions ) nNeuronsTotal Perform PCA on this matrix and keep the projections of the data into the top nFactors components. These represent the global shared structure of the data across all datasets. For each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix. These matrices will be computed for you automatically by run.prepareForLFADS() and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by lfads-run-manager . Alignment biases In addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts before projecting through the matrix. Consequently, lfads-run-manager seeds this bias with the negative mean of the rates of each neuron. Setting up a multi-session LFADS run \u00b6 Assuming you have finished reading through the single-dataset LFADS walkthrough , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up another drive script that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling LFADS Run Manager to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as LorenzExperiment , but you should substitute this with your package name. Follow along with LorenzExperiment.drive_script A complete drive script is available as a starting point in +LorenzExperiment/drive_script.m for you to copy/paste from. For this demo, as before, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code: datasetPath = '~/lorenz_example/datasets' ; LFADS . Utils . generateDemoDatasets ( datasetPath , 'nDatasets' , 3 ); This will simulate a chaotic 3 dimensional Lorenz attractor as the underlying dynamical system, initialized from 65 initial conditions. The key in these demonstration datasets is that the 65 conditions start from the same initial state and evolve identically across all 3 datasets. Each dataset, however, contains a disjoint set of neurons that are each a different linear recombination of the 3 dimensions of the Lorenz attractor state. This is analogous to the assumption we make in LFADS stitching\u2013each dataset contains different sets of neurons, which are reconstructed from a shared low-dimensional set of factors. Building a dataset collection and adding datasets \u00b6 First, create a dataset collection that points to a folder on disk where datasets are stored: dataPath = '~/lorenz_example/datasets' ; dc = LorenzExperiment . DatasetCollection ( dataPath ); dc . name = 'lorenz_example' ; Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the DatasetCollection and will replace any dataset that has the same name if present. LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); LorenzExperiment . Dataset ( dc , 'dataset002.mat' ); LorenzExperiment . Dataset ( dc , 'dataset003.mat' ); You can verify that the datasets have been added to the collection: >> dc LorenzExperiment . DatasetCollection \" lorenz_example \" 3 datasets in ~/ lorenz_example / datasets [ 1 ] LorenzExperiment . Dataset \" dataset001 \" [ 2 ] LorenzExperiment . Dataset \" dataset002 \" [ 3 ] LorenzExperiment . Dataset \" dataset003 \" name : 'lorenz_example' comment : '' path : '~/lorenz_example/datasets' datasets : [ 3 x1 LorenzExperiment . Dataset ] nDatasets : 3 datasetNames : { 3 x1 cell } You can access individual datasets using dc . datasets ( 1 ) or by name with dc . matchDatasetsByName ( 'dataset001' ) . You can then load all of the metadata for the datasets using: dc . loadInfo (); How this metadata is determined for each dataset may be customized as described in Interfacing with your Datasets . You can view a summary of the metadata using: >> dc . getDatasetInfoTable subject date saveTags nTrials nChannels ________________ ______________________ ________ _______ _________ dataset001 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1820 35 dataset002 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1885 26 dataset003 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1365 35 Create a RunCollection \u00b6 We\u2019ll now setup a RunCollection that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders. runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'exampleStitching' , dc ); % replace with approximate date script authored as YYYYMMDD % to ensure forwards compatibility rc . version = 20180131 ; Specify the hyperparameters in RunParams \u00b6 We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. The key change we\u2019ll make is to set useAlignmentMatrix to true in order to seed the read-in matrices. par = LorenzExperiment . RunParams ; par . name = 'first_attempt_stitching' ; % completely optional par . useAlignmentMatrix = true ; % use alignment matrices initial guess for multisession stitching par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_factors_dim = 8 ; % and manually set it for multisession stitched models par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop really early for the demo We then add this RunParams to the RunCollection : rc . addParams ( par ); You can access the parameter settings added to rc using rc.params , which will be an array of RunParams instances. Specify the RunSpec set \u00b6 Recall that RunSpec instances specify which datasets are included in a specific run. For stitching, we\u2019ll want to include all three datasets into a single model. % include all datasets runSpecName = 'all' ; runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , 1 : dc . nDatasets ); rc . addRunSpec ( runSpec ); You can adjust the arguments to the constructor of LorenzExperiment.RunSpec , but in the example provided the inputs define: the unique name of the run. Here we use getSingleRunName , a convenience method of Dataset that generates a name like single_datasetName . the DatasetCollection from which datasets will be retrieved the indices or names of datasets (as a string or cell array of strings) to include If you like you can also add RunSpecs to train individual models for each dataset as well to facilitate comparison. % add one run for each single dataset for iR = 1 : dc . nDatasets runSpecName = dc . datasets ( iR ). getSingleRunName (); % 'single_dataset###' runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , iR ); rc . addRunSpec ( runSpec ); end Check the RunCollection and the Run \u00b6 The RunCollection will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total. >> rc LorenzExperiment . RunCollection \" exampleStitching \" ( 1 runs total ) Dataset Collection \" lorenz_example \" ( 3 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleStitching 1 parameter settings [ 1 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams \" first_attempt_stitching \" useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" all \" ( 3 datasets ) name : 'exampleStitching' comment : '' rootPath : '~/lorenz_example/runs' version : 201801 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x1 LorenzExperiment . Run ] params : [ 1 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 1 nRunSpecs : 1 nRunsTotal : 1 nDatasets : 3 datasetNames : { 3 x1 cell } path : '~/lorenz_example/runs/exampleStitching' pathsCommonDataForParams : { '~/lorenz_example/runs/exampleStitching/data_RE1kuL' } pathsForParams : { '~/lorenz_example/runs/exampleStitching/param_Qr2PeG' } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleStitching/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleStitching/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleStitching/run_lfadsqueue.py' >> run = rc . findRuns ( 'all' , 1 ); LorenzExperiment . Run \" all \" ( 3 datasets ) Path : ~/ lorenz_example / runs / exampleStitching / param_Qr2PeG / all Data : ~/ lorenz_example / runs / exampleStitching / data_RE1kuL LorenzExperiment . RunParams \" first_attempt_stitching \" : useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 3 datasets in \" lorenz_example \" [ 1 ] LorenzExperiment . Dataset \" dataset001 \" [ 2 ] LorenzExperiment . Dataset \" dataset002 \" [ 3 ] LorenzExperiment . Dataset \" dataset003 \" ... Verifying the alignment matrices \u00b6 Next, we\u2019ll run the principal components regression that generates the alignment matrices using the algorithm described above . Then we\u2019ll verify that these matrices are able to project the data from each dataset into similar looking low-dimensional trajectories. To visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset. run . doMultisessionAlignment (); Under the hood, the alignment matrix calculations are performed by an instance of LFADS.MutlisessionAlignmentTool . To plot the reconstruction quality, you can call tool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot) , like so: tool = run . multisessionAlignmentTool ; nFactorsPlot = 3 ; conditionsToPlot = [ 1 20 40 ]; tool . plotAlignmentReconstruction ( nFactorsPlot , conditionsToPlot ); In this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance. The actual alignment matrices can be accessed using: tool . alignmentMatrices % nDatasets x 1 cell array of read-in matrices Prepare for LFADS \u00b6 Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS. rc . prepareForLFADS (); This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call prepareForLFADS again. Existing files won\u2019t be overwritten unless you call rc.prepareForLFADS(true) . After running prepareForLFADS , the run manager will create the following files on disk under rc.path : ~/lorenz_example/runs/exampleStitching \u251c\u2500\u2500 data_4MaTKO \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u251c\u2500\u2500 param_YOs74u \u2502 \u2514\u2500\u2500 all \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_4MaTKO/inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_4MaTKO/inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_4MaTKO/lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_4MaTKO/lfads_dataset003.h5 \u2514\u2500\u2500 summary.txt The organization of these files on disk is discussed in more detail here . Also, a summary.txt file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling rc.generateSummaryText() . LorenzExperiment . RunCollection \" exampleStitching2 \" ( 1 runs total ) Path : ~/ lorenz_example / runs / exampleStitching2 Dataset Collection \" lorenz_example \" ( 3 datasets ) in ~/ lorenz_example / datasets ------------------------ 1 Run Specifications : [ runSpec 1 ] LorenzExperiment . RunSpec \" all \" ( 3 datasets ) [ ds 1 ] LorenzExperiment . Dataset \" dataset001 \" [ ds 2 ] LorenzExperiment . Dataset \" dataset002 \" [ ds 3 ] LorenzExperiment . Dataset \" dataset003 \" ------------------------ 1 Parameter Settings : [ 1 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams \" first_attempt_stitching \" useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 spikeBinMs : 2 trainToTestRatio : 4 useAlignmentMatrix : true useSingleDatasetAlignmentMatrix : false scaleIncreaseStepsWithDatasets : true c_cell_clip_value : 5 c_factors_dim : 8 c_ic_enc_dim : 64 c_ci_enc_dim : 128 c_gen_dim : 64 c_keep_prob : 0.95 c_learning_rate_decay_factor : 0.98 c_device : / gpu : 0 c_co_dim : 0 c_do_causal_controller : false c_do_feed_factors_to_controller : true c_feedback_factors_or_rates : factors c_controller_input_lag : 1 c_do_train_readin : true c_l2_gen_scale : 500 c_l2_con_scale : 500 c_batch_size : 150 c_kl_increase_steps : 900 c_l2_increase_steps : 900 c_ic_dim : 64 c_con_dim : 128 c_learning_rate_stop : 0.001 c_temporal_spike_jitter_width : 0 c_allow_gpu_growth : true c_kl_ic_weight : 1 c_kl_co_weight : 1 c_inject_ext_input_to_gen : false c_prior_ar_atau : 10 c_do_train_prior_ar_atau : true c_prior_ar_nvar : 0.1 c_do_train_prior_ar_nvar : true num_samples_posterior : 512 posterior_mean_kind : posterior_sample_and_average After running prepareForLFADS , you can then run the LFADS model or models in the same way as with single-session models, using the instructions here .","title":"Multisession Stitched Models"},{"location":"multisession/#multi-dataset-stitching-models","text":"If you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a RunSpec , the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through read-in and readout alignment matrices. Below is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset. A similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial.","title":"Multi-dataset Stitching Models"},{"location":"multisession/#generating-alignment-matrices","text":"These read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a RunSpec , and the hyperparameter useAlignmentMatrix is set to true in the RunParams , then lfads-run-manager will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as: Generate condition-averaged firing rates for each neuron for each condition for each dataset Concatenate all of neurons from all datasets together to build a matrix which is ( nTime * nConditions ) nNeuronsTotal Perform PCA on this matrix and keep the projections of the data into the top nFactors components. These represent the global shared structure of the data across all datasets. For each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix. These matrices will be computed for you automatically by run.prepareForLFADS() and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by lfads-run-manager . Alignment biases In addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts before projecting through the matrix. Consequently, lfads-run-manager seeds this bias with the negative mean of the rates of each neuron.","title":"Generating alignment matrices"},{"location":"multisession/#setting-up-a-multi-session-lfads-run","text":"Assuming you have finished reading through the single-dataset LFADS walkthrough , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up another drive script that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling LFADS Run Manager to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as LorenzExperiment , but you should substitute this with your package name. Follow along with LorenzExperiment.drive_script A complete drive script is available as a starting point in +LorenzExperiment/drive_script.m for you to copy/paste from. For this demo, as before, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code: datasetPath = '~/lorenz_example/datasets' ; LFADS . Utils . generateDemoDatasets ( datasetPath , 'nDatasets' , 3 ); This will simulate a chaotic 3 dimensional Lorenz attractor as the underlying dynamical system, initialized from 65 initial conditions. The key in these demonstration datasets is that the 65 conditions start from the same initial state and evolve identically across all 3 datasets. Each dataset, however, contains a disjoint set of neurons that are each a different linear recombination of the 3 dimensions of the Lorenz attractor state. This is analogous to the assumption we make in LFADS stitching\u2013each dataset contains different sets of neurons, which are reconstructed from a shared low-dimensional set of factors.","title":"Setting up a multi-session LFADS run"},{"location":"multisession/#building-a-dataset-collection-and-adding-datasets","text":"First, create a dataset collection that points to a folder on disk where datasets are stored: dataPath = '~/lorenz_example/datasets' ; dc = LorenzExperiment . DatasetCollection ( dataPath ); dc . name = 'lorenz_example' ; Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the DatasetCollection and will replace any dataset that has the same name if present. LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); LorenzExperiment . Dataset ( dc , 'dataset002.mat' ); LorenzExperiment . Dataset ( dc , 'dataset003.mat' ); You can verify that the datasets have been added to the collection: >> dc LorenzExperiment . DatasetCollection \" lorenz_example \" 3 datasets in ~/ lorenz_example / datasets [ 1 ] LorenzExperiment . Dataset \" dataset001 \" [ 2 ] LorenzExperiment . Dataset \" dataset002 \" [ 3 ] LorenzExperiment . Dataset \" dataset003 \" name : 'lorenz_example' comment : '' path : '~/lorenz_example/datasets' datasets : [ 3 x1 LorenzExperiment . Dataset ] nDatasets : 3 datasetNames : { 3 x1 cell } You can access individual datasets using dc . datasets ( 1 ) or by name with dc . matchDatasetsByName ( 'dataset001' ) . You can then load all of the metadata for the datasets using: dc . loadInfo (); How this metadata is determined for each dataset may be customized as described in Interfacing with your Datasets . You can view a summary of the metadata using: >> dc . getDatasetInfoTable subject date saveTags nTrials nChannels ________________ ______________________ ________ _______ _________ dataset001 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1820 35 dataset002 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1885 26 dataset003 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1365 35","title":"Building a dataset collection and adding datasets"},{"location":"multisession/#create-a-runcollection","text":"We\u2019ll now setup a RunCollection that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders. runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'exampleStitching' , dc ); % replace with approximate date script authored as YYYYMMDD % to ensure forwards compatibility rc . version = 20180131 ;","title":"Create a RunCollection"},{"location":"multisession/#specify-the-hyperparameters-in-runparams","text":"We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. The key change we\u2019ll make is to set useAlignmentMatrix to true in order to seed the read-in matrices. par = LorenzExperiment . RunParams ; par . name = 'first_attempt_stitching' ; % completely optional par . useAlignmentMatrix = true ; % use alignment matrices initial guess for multisession stitching par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_factors_dim = 8 ; % and manually set it for multisession stitched models par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop really early for the demo We then add this RunParams to the RunCollection : rc . addParams ( par ); You can access the parameter settings added to rc using rc.params , which will be an array of RunParams instances.","title":"Specify the hyperparameters in RunParams"},{"location":"multisession/#specify-the-runspec-set","text":"Recall that RunSpec instances specify which datasets are included in a specific run. For stitching, we\u2019ll want to include all three datasets into a single model. % include all datasets runSpecName = 'all' ; runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , 1 : dc . nDatasets ); rc . addRunSpec ( runSpec ); You can adjust the arguments to the constructor of LorenzExperiment.RunSpec , but in the example provided the inputs define: the unique name of the run. Here we use getSingleRunName , a convenience method of Dataset that generates a name like single_datasetName . the DatasetCollection from which datasets will be retrieved the indices or names of datasets (as a string or cell array of strings) to include If you like you can also add RunSpecs to train individual models for each dataset as well to facilitate comparison. % add one run for each single dataset for iR = 1 : dc . nDatasets runSpecName = dc . datasets ( iR ). getSingleRunName (); % 'single_dataset###' runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , iR ); rc . addRunSpec ( runSpec ); end","title":"Specify the RunSpec set"},{"location":"multisession/#check-the-runcollection-and-the-run","text":"The RunCollection will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total. >> rc LorenzExperiment . RunCollection \" exampleStitching \" ( 1 runs total ) Dataset Collection \" lorenz_example \" ( 3 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleStitching 1 parameter settings [ 1 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams \" first_attempt_stitching \" useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" all \" ( 3 datasets ) name : 'exampleStitching' comment : '' rootPath : '~/lorenz_example/runs' version : 201801 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x1 LorenzExperiment . Run ] params : [ 1 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 1 nRunSpecs : 1 nRunsTotal : 1 nDatasets : 3 datasetNames : { 3 x1 cell } path : '~/lorenz_example/runs/exampleStitching' pathsCommonDataForParams : { '~/lorenz_example/runs/exampleStitching/data_RE1kuL' } pathsForParams : { '~/lorenz_example/runs/exampleStitching/param_Qr2PeG' } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleStitching/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleStitching/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleStitching/run_lfadsqueue.py' >> run = rc . findRuns ( 'all' , 1 ); LorenzExperiment . Run \" all \" ( 3 datasets ) Path : ~/ lorenz_example / runs / exampleStitching / param_Qr2PeG / all Data : ~/ lorenz_example / runs / exampleStitching / data_RE1kuL LorenzExperiment . RunParams \" first_attempt_stitching \" : useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 3 datasets in \" lorenz_example \" [ 1 ] LorenzExperiment . Dataset \" dataset001 \" [ 2 ] LorenzExperiment . Dataset \" dataset002 \" [ 3 ] LorenzExperiment . Dataset \" dataset003 \" ...","title":"Check the RunCollection and the Run"},{"location":"multisession/#verifying-the-alignment-matrices","text":"Next, we\u2019ll run the principal components regression that generates the alignment matrices using the algorithm described above . Then we\u2019ll verify that these matrices are able to project the data from each dataset into similar looking low-dimensional trajectories. To visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset. run . doMultisessionAlignment (); Under the hood, the alignment matrix calculations are performed by an instance of LFADS.MutlisessionAlignmentTool . To plot the reconstruction quality, you can call tool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot) , like so: tool = run . multisessionAlignmentTool ; nFactorsPlot = 3 ; conditionsToPlot = [ 1 20 40 ]; tool . plotAlignmentReconstruction ( nFactorsPlot , conditionsToPlot ); In this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance. The actual alignment matrices can be accessed using: tool . alignmentMatrices % nDatasets x 1 cell array of read-in matrices","title":"Verifying the alignment matrices"},{"location":"multisession/#prepare-for-lfads","text":"Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS. rc . prepareForLFADS (); This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call prepareForLFADS again. Existing files won\u2019t be overwritten unless you call rc.prepareForLFADS(true) . After running prepareForLFADS , the run manager will create the following files on disk under rc.path : ~/lorenz_example/runs/exampleStitching \u251c\u2500\u2500 data_4MaTKO \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 \u251c\u2500\u2500 param_YOs74u \u2502 \u2514\u2500\u2500 all \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/inputInfo_dataset001.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_4MaTKO/inputInfo_dataset002.mat \u2502 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_4MaTKO/inputInfo_dataset003.mat \u2502 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/lfads_dataset001.h5 \u2502 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_4MaTKO/lfads_dataset002.h5 \u2502 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_4MaTKO/lfads_dataset003.h5 \u2514\u2500\u2500 summary.txt The organization of these files on disk is discussed in more detail here . Also, a summary.txt file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling rc.generateSummaryText() . LorenzExperiment . RunCollection \" exampleStitching2 \" ( 1 runs total ) Path : ~/ lorenz_example / runs / exampleStitching2 Dataset Collection \" lorenz_example \" ( 3 datasets ) in ~/ lorenz_example / datasets ------------------------ 1 Run Specifications : [ runSpec 1 ] LorenzExperiment . RunSpec \" all \" ( 3 datasets ) [ ds 1 ] LorenzExperiment . Dataset \" dataset001 \" [ ds 2 ] LorenzExperiment . Dataset \" dataset002 \" [ ds 3 ] LorenzExperiment . Dataset \" dataset003 \" ------------------------ 1 Parameter Settings : [ 1 param_Qr2PeG data_RE1kuL ] LorenzExperiment . RunParams \" first_attempt_stitching \" useAlignmentMatrix = true c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 spikeBinMs : 2 trainToTestRatio : 4 useAlignmentMatrix : true useSingleDatasetAlignmentMatrix : false scaleIncreaseStepsWithDatasets : true c_cell_clip_value : 5 c_factors_dim : 8 c_ic_enc_dim : 64 c_ci_enc_dim : 128 c_gen_dim : 64 c_keep_prob : 0.95 c_learning_rate_decay_factor : 0.98 c_device : / gpu : 0 c_co_dim : 0 c_do_causal_controller : false c_do_feed_factors_to_controller : true c_feedback_factors_or_rates : factors c_controller_input_lag : 1 c_do_train_readin : true c_l2_gen_scale : 500 c_l2_con_scale : 500 c_batch_size : 150 c_kl_increase_steps : 900 c_l2_increase_steps : 900 c_ic_dim : 64 c_con_dim : 128 c_learning_rate_stop : 0.001 c_temporal_spike_jitter_width : 0 c_allow_gpu_growth : true c_kl_ic_weight : 1 c_kl_co_weight : 1 c_inject_ext_input_to_gen : false c_prior_ar_atau : 10 c_do_train_prior_ar_atau : true c_prior_ar_nvar : 0.1 c_do_train_prior_ar_nvar : true num_samples_posterior : 512 posterior_mean_kind : posterior_sample_and_average After running prepareForLFADS , you can then run the LFADS model or models in the same way as with single-session models, using the instructions here .","title":"Prepare for LFADS"},{"location":"running/","text":"Running LFADS \u00b6 To train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call run_lfads.py and do the work of training the model. lfads-run-manager provides two ways to go about this. Add the run_lfads.py folder to your shell PATH Be sure that the LFADS python source folder is on your shell path, such that running which run_lfads.py prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like export PATH=$PATH:/path/to/models/research/lfads and consider adding this to your .bashrc file. If Matlab is able to determine the location of run_lfads.py (meaning that it\u2019s own inherited PATH was set correctly), it will prepend an export PATH=... statement to each generated shell script for you. If not, you can try calling setenv('PATH', '...') from within Matlab to add run_lfads.py to the path. before generating the shell scripts. Alternatively, you can hard-code the location to run_lfads.py by passing along the fully specified path to each of the writeShellScript... methods as 'path_run_lfads_py', '/path/to/run_lfads.py' Virtualenv support Each of the methods below supports a 'virtualenv' , 'environmentName' parameter-value argument. If specified, a source activate environmentName will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment (or a conda virtual environment). LFADS Queue: Automatically queueing many runs \u00b6 If you wish to run each LFADS model manually at the command line, skip ahead . However, manually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the LFADS Queue model queueing system which will take care of training all the LFADS models for you. Only supported on Linux Unfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on nvidia-smi , though it\u2019s theoretically possible with cuda-smi with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get tmux working. First, we\u2019ll generate the Python script from Matlab that enumerates all of the runs: rc . writeShellScriptRunQueue ( 'display' , 0 , 'virtualenv' , 'tensorflow' ); Optional parameters include: display : The numeric value of the X display to target. 0 means target display DISPLAY=:0 . A display is needed to draw plots using matplotlib . If you\u2019re running on a VM, you may want to launch a VNC Server and point at that display. By default the display will be set according to the DISPLAY environment variable as it is seen inside tmux . gpuList : List of GPU indices to include in the queue. By default, this will include all GPUs detected by nvidia-smi . runIdx : Scalar indices of all runs to include in the queue. By default this will include all runs in .runs . virtualenv : String indicating the virtual environment to source before launching the Python LFADS task, where TensorFlow must be installed. rerun : By default, any run which already has an lfads.done file in the directory will be skipped, allowing you to regenerate and rerun the queue script whenever new runs are added. If rerun is true , all runs will be executed, although the old LFADS output checkpoint will be used during training. If you want to re-train from scratch, you\u2019ll need to delete the lfadsOutput directories, or call rc.deleteLFADSOutput() . oneTaskPerGPU : By default, only one LFADS model will be trained per GPU, as empirically we\u2019ve found that the switching costs outweigh any benefit from running multiple models simultaneously on each GPU. If you set this to false , ensure that you\u2019ve set c_allow_gpu_growth to true in the RunParams . gpuMemoryRequired Estimated maximum MB of GPU RAM needed per model, used to schedule models onto GPUs when oneTaskPerGPU is false . maxTasksSimultaneously A manual cap on the number of models to train simultaneously. This is only relevant when oneTaskPerGPU is false, and will default to the number of CPUs minus one. prependPathToLFADSQueue If true, automatically appends the path to lfadsqueue.py to the PYTHONPATH inside the generated script. Defaults to false to avoid confusion. This will generate a Python script run_lfads.py , which for our example can be launched via: python ~/lorenz_example/runs/exampleSingleRun/run_lfadsqueue.py Run Manager src folder should be added to your PYTHONPATH The run_lfadsqueue.py script depends on lfadsqueue.py , which lives in lfads-run-manager/src . You should add this to your PYTHONPATH or request that it be added to your PYTHONPATH environment variable in the run_lfadsqueue.py script by setting prependPathToLFADSQueue to true . Install and configure tmux The LFADS queue launches each LFADS run inside its own tmux session to make it easy to monitor the runs as they are running. You\u2019ll need to install tmux . Also, tmux is finnicky about environment variables, which are only loaded when the tmux server first launches, not when a new session is started. The main one you need is that run_lfads.py must be on your PATH somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited PATH was set correctly), it will prepend an export PATH=... statement to each lfads_train.sh script for you. If not, you can try calling setenv('PATH', '...') from within Matlab to add run_lfads.py to the path. before generating the shell scripts. If you\u2019re having trouble, you might want to launch a new tmux session using: tmux new-session Then from inside tmux , test that which run_lfads.py prints a location and that you are able to launch python and run import tensorflow as tf without any issues. You can then kick everything off by running python run_lfadsqueue.py at the command line. It\u2019s recommended to do this from inside your own tmux session if you\u2019re running on a remote server, so you can monitor the task runner. Python virtual environments If tensorflow is installed in a Python virtual environment, you can have this environment be automatically activated via source activate within the training scripts using: rc . writeShellScriptRunQueue ( 'virtualenv' , 'tensorflow' ); A few notes on how the system works: Output from Python will be tee \u2018d into lfads.out , so you can check the output during or afterwards either there or in the tmux session. When a model finishes training and posterior mean sampling, a file called lfads.done will be created If the task runner detects an lfads.done file, it will skip that run. Unless you pass 'rerun' , true to writeShellScriptRunQueue , in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run. If a run fails, the error will be printed by the task runner and lfads.done will not be created A running tally of how many runs are currently running, have finished, or have failed will be printed You can enter a run\u2019s tmux session directly to monitor it. The list of sessions can be obtained using tmux list-sessions . You can also abort it using Ctrl-C and it will be marked as failed by the task runner. If you Ctrl-C the run_lfadsqueue.py script itself, the already launched runs will continue running. If you want to abort them, you can pkill python although this will kill all python processes you\u2019ve created. In either case, you should be able to relaunch the run_lfadsqueue.py script and have it pick up where it left off as well. The run_lfadsqueue.py script will periodically output updates about how the runs are proceeding: ( tensorflow ) \u279c exampleRun python run_lfadsqueue.py Warning: tmux sessions will be nested inside the current session Queue: Launching TensorBoard on port 42561 in tmux session exampleRun_tensorboard_port42561 bash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port = 42561 Queue: Initializing with 2 GPUs and 12 CPUs, max 4 simultaneous tasks Task lfads_param_Qr2PeG__single_dataset001: launching on gpu 0 Task lfads_param_Qr2PeG__single_dataset001: started in tmux session lfads_param_Qr2PeG__single_dataset001 on GPU 0 with PID 19498 Task lfads_param_Qr2PeG__single_dataset002: launching on gpu 1 Task lfads_param_Qr2PeG__single_dataset002: started in tmux session lfads_param_Qr2PeG__single_dataset002 on GPU 1 with PID 19527 Task lfads_param_Qr2PeG__single_dataset003: launching on gpu 0 Task lfads_param_Qr2PeG__single_dataset003: started in tmux session lfads_param_Qr2PeG__single_dataset003 on GPU 0 with PID 19551 Task lfads_param_Qr2PeG__all: launching on gpu 1 Task lfads_param_Qr2PeG__all: started in tmux session lfads_param_Qr2PeG__all on GPU 1 with PID 19585 Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009800. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009800. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009604. Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009604. Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009412. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009412. As the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits c_learning_rate_stop ). When a task fails or completes, the queue will print out a running tally. Note that TensorBoard has automatically been launched on an available port, here on 42561 . You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using tmux list-sessions . \u279c exampleRun tmux list-sessions matlab: 4 windows ( created Tue Oct 3 21 :51:49 2017 ) [ 201x114 ] ( attached ) exampleRun_tensorboard_port42561: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x113 ] lfads_param_Qr2PeG__all: 1 windows ( created Fri Oct 6 14 :43:17 2017 ) [ 201x113 ] lfads_param_Qr2PeG__single_dataset001: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x114 ] lfads_param_Qr2PeG__single_dataset002: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x113 ] lfads_param_Qr2PeG__single_dataset003: 1 windows ( created Fri Oct 6 14 :43:17 2017 ) [ 201x113 ] If you wish to abort ongoing runs, you can either attach to them directly and use Ctrl-C , or use tmux kill-session SESSIONNAME . When everything has completed, you\u2019ll see something like this: Task lfads_param_Qr2PeG__all: Stopping optimization based on learning rate criteria. Task lfads_param_Qr2PeG__all: completed successfully Queue: All tasks completed. Queue: 0 skipped, 4 finished, 0 failed, 0 running Launching each run individually from shell scripts \u00b6 Follow these instructions to run each model individually, but you\u2019ll probably prefer to queue everything at once . Training the model \u00b6 The first is to manually generate shell scripts for each run and then run them yourself. First, for each run i , you will call: rc . runs ( i ). writeShellScriptLFADSTrain ( 'cuda_visible_devices' , 0 , 'display' , 0 ); Here, you should specify options that will be written into the shell script, the key ones being: cuda_visible_devices - which GPU index to run this model on, e.g. 0 . Use the nvidia-smi to enumerate the available GPUs on your system display - the X display to use, e.g. 0 , which will set DISPLAY to :0 . The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like tightvnc or vncserver . appendPosteriorMeanSample - true or false specifying whether to chain the posterior mean sampling operation after the training is finished. The default is false , but if you set this to true , you won\u2019t need to call writeShellScriptPosteriorMeanSample below. appendWriteModelParams - true or false specifying whether to chain the posterior mean sampling operation after the training is finished. The default is false , but if you set this to true , you won\u2019t need to call writeShellScriptWriteModelParams below. This will generate an lfads_train.sh in the corresponding run\u2019s folder. For the first run in our example, this is at ~/lorenz_example/runs/exampleRun/param_Qr2PeG/single_dataset001/lfads_train.sh The script essentially launches Python to run run_lfads.py with the specific parameters you\u2019ve indicated in RunParams and pointing at the corresponding datasets, which were saved earlier when we called rc.prepareForLFADS . #!/bin/bash path_to_run_lfads = $( which run_lfads.py ) if [ ! -n \" $path_to_run_lfads \" ] ; then echo \"Error: run_lfads.py not found on PATH. Ensure you add LFADS to your system PATH.\" exit 1 fi DISPLAY = :0 CUDA_VISIBLE_DEVICES = 0 python $( which run_lfads.py ) --data_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsInput --data_filename_stem = lfads --lfads_save_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsOutput --cell_clip_value = 5 .000000 --factors_dim = 8 --ic_enc_dim = 64 --ci_enc_dim = 128 --gen_dim = 64 --keep_prob = 0 .950000 --learning_rate_decay_factor = 0 .980000 --device = /gpu:0 --co_dim = 0 --do_causal_controller = false --do_feed_factors_to_controller = true --feedback_factors_or_rates = factors --controller_input_lag = 1 --do_train_readin = true --l2_gen_scale = 500 .000000 --l2_con_scale = 500 .000000 --batch_size = 150 --kl_increase_steps = 900 --l2_increase_steps = 900 --ic_dim = 64 --con_dim = 128 --learning_rate_stop = 0 .001000 --temporal_spike_jitter_width = 0 --allow_gpu_growth = true --kl_ic_weight = 1 .000000 --kl_co_weight = 1 .000000 --inject_ext_input_to_gen = false Running the lfads_train.sh script will launch the Tensorflow training which will take some time. You likely want to launch this in a tmux session if running remotely. Sampling the posterior means \u00b6 Next, generate the lfads_posterior_mean_sample.sh script to sample the posterior means, which can be launched after training has completed. If you set appendPosteriorMeanSample to true in writeShellScriptLFADSTrain , you can skip this step. rc . runs ( i ). writeShellScriptLFADSPosteriorMeanSample ( 'cuda_visible_devices' , 0 ); Writing the model parameters \u00b6 Lastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using rc . runs ( i ). writeShellScriptWriteModelParams ( 'cuda_visible_devices' , 0 ); If you set appendWriteModelParams to true in writeShellScriptLFADSTrain , you can skip this step. These results will be written to a file called lfadsOutput/model_params , though these results can be loaded into Matlab using run.loadModelTrainedParams() . Launching Tensorboard \u00b6 You can monitor the progress of each run by generating a script that launches TensorBoard. rc . writeTensorboardShellScript (); This will create launch_tensorboard.sh which will launch Tensorboard which can then be visited at http://localhost:PORT .","title":"Running LFADS"},{"location":"running/#running-lfads","text":"To train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call run_lfads.py and do the work of training the model. lfads-run-manager provides two ways to go about this. Add the run_lfads.py folder to your shell PATH Be sure that the LFADS python source folder is on your shell path, such that running which run_lfads.py prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like export PATH=$PATH:/path/to/models/research/lfads and consider adding this to your .bashrc file. If Matlab is able to determine the location of run_lfads.py (meaning that it\u2019s own inherited PATH was set correctly), it will prepend an export PATH=... statement to each generated shell script for you. If not, you can try calling setenv('PATH', '...') from within Matlab to add run_lfads.py to the path. before generating the shell scripts. Alternatively, you can hard-code the location to run_lfads.py by passing along the fully specified path to each of the writeShellScript... methods as 'path_run_lfads_py', '/path/to/run_lfads.py' Virtualenv support Each of the methods below supports a 'virtualenv' , 'environmentName' parameter-value argument. If specified, a source activate environmentName will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment (or a conda virtual environment).","title":"Running LFADS"},{"location":"running/#lfads-queue-automatically-queueing-many-runs","text":"If you wish to run each LFADS model manually at the command line, skip ahead . However, manually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the LFADS Queue model queueing system which will take care of training all the LFADS models for you. Only supported on Linux Unfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on nvidia-smi , though it\u2019s theoretically possible with cuda-smi with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get tmux working. First, we\u2019ll generate the Python script from Matlab that enumerates all of the runs: rc . writeShellScriptRunQueue ( 'display' , 0 , 'virtualenv' , 'tensorflow' ); Optional parameters include: display : The numeric value of the X display to target. 0 means target display DISPLAY=:0 . A display is needed to draw plots using matplotlib . If you\u2019re running on a VM, you may want to launch a VNC Server and point at that display. By default the display will be set according to the DISPLAY environment variable as it is seen inside tmux . gpuList : List of GPU indices to include in the queue. By default, this will include all GPUs detected by nvidia-smi . runIdx : Scalar indices of all runs to include in the queue. By default this will include all runs in .runs . virtualenv : String indicating the virtual environment to source before launching the Python LFADS task, where TensorFlow must be installed. rerun : By default, any run which already has an lfads.done file in the directory will be skipped, allowing you to regenerate and rerun the queue script whenever new runs are added. If rerun is true , all runs will be executed, although the old LFADS output checkpoint will be used during training. If you want to re-train from scratch, you\u2019ll need to delete the lfadsOutput directories, or call rc.deleteLFADSOutput() . oneTaskPerGPU : By default, only one LFADS model will be trained per GPU, as empirically we\u2019ve found that the switching costs outweigh any benefit from running multiple models simultaneously on each GPU. If you set this to false , ensure that you\u2019ve set c_allow_gpu_growth to true in the RunParams . gpuMemoryRequired Estimated maximum MB of GPU RAM needed per model, used to schedule models onto GPUs when oneTaskPerGPU is false . maxTasksSimultaneously A manual cap on the number of models to train simultaneously. This is only relevant when oneTaskPerGPU is false, and will default to the number of CPUs minus one. prependPathToLFADSQueue If true, automatically appends the path to lfadsqueue.py to the PYTHONPATH inside the generated script. Defaults to false to avoid confusion. This will generate a Python script run_lfads.py , which for our example can be launched via: python ~/lorenz_example/runs/exampleSingleRun/run_lfadsqueue.py Run Manager src folder should be added to your PYTHONPATH The run_lfadsqueue.py script depends on lfadsqueue.py , which lives in lfads-run-manager/src . You should add this to your PYTHONPATH or request that it be added to your PYTHONPATH environment variable in the run_lfadsqueue.py script by setting prependPathToLFADSQueue to true . Install and configure tmux The LFADS queue launches each LFADS run inside its own tmux session to make it easy to monitor the runs as they are running. You\u2019ll need to install tmux . Also, tmux is finnicky about environment variables, which are only loaded when the tmux server first launches, not when a new session is started. The main one you need is that run_lfads.py must be on your PATH somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited PATH was set correctly), it will prepend an export PATH=... statement to each lfads_train.sh script for you. If not, you can try calling setenv('PATH', '...') from within Matlab to add run_lfads.py to the path. before generating the shell scripts. If you\u2019re having trouble, you might want to launch a new tmux session using: tmux new-session Then from inside tmux , test that which run_lfads.py prints a location and that you are able to launch python and run import tensorflow as tf without any issues. You can then kick everything off by running python run_lfadsqueue.py at the command line. It\u2019s recommended to do this from inside your own tmux session if you\u2019re running on a remote server, so you can monitor the task runner. Python virtual environments If tensorflow is installed in a Python virtual environment, you can have this environment be automatically activated via source activate within the training scripts using: rc . writeShellScriptRunQueue ( 'virtualenv' , 'tensorflow' ); A few notes on how the system works: Output from Python will be tee \u2018d into lfads.out , so you can check the output during or afterwards either there or in the tmux session. When a model finishes training and posterior mean sampling, a file called lfads.done will be created If the task runner detects an lfads.done file, it will skip that run. Unless you pass 'rerun' , true to writeShellScriptRunQueue , in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run. If a run fails, the error will be printed by the task runner and lfads.done will not be created A running tally of how many runs are currently running, have finished, or have failed will be printed You can enter a run\u2019s tmux session directly to monitor it. The list of sessions can be obtained using tmux list-sessions . You can also abort it using Ctrl-C and it will be marked as failed by the task runner. If you Ctrl-C the run_lfadsqueue.py script itself, the already launched runs will continue running. If you want to abort them, you can pkill python although this will kill all python processes you\u2019ve created. In either case, you should be able to relaunch the run_lfadsqueue.py script and have it pick up where it left off as well. The run_lfadsqueue.py script will periodically output updates about how the runs are proceeding: ( tensorflow ) \u279c exampleRun python run_lfadsqueue.py Warning: tmux sessions will be nested inside the current session Queue: Launching TensorBoard on port 42561 in tmux session exampleRun_tensorboard_port42561 bash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port = 42561 Queue: Initializing with 2 GPUs and 12 CPUs, max 4 simultaneous tasks Task lfads_param_Qr2PeG__single_dataset001: launching on gpu 0 Task lfads_param_Qr2PeG__single_dataset001: started in tmux session lfads_param_Qr2PeG__single_dataset001 on GPU 0 with PID 19498 Task lfads_param_Qr2PeG__single_dataset002: launching on gpu 1 Task lfads_param_Qr2PeG__single_dataset002: started in tmux session lfads_param_Qr2PeG__single_dataset002 on GPU 1 with PID 19527 Task lfads_param_Qr2PeG__single_dataset003: launching on gpu 0 Task lfads_param_Qr2PeG__single_dataset003: started in tmux session lfads_param_Qr2PeG__single_dataset003 on GPU 0 with PID 19551 Task lfads_param_Qr2PeG__all: launching on gpu 1 Task lfads_param_Qr2PeG__all: started in tmux session lfads_param_Qr2PeG__all on GPU 1 with PID 19585 Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009800. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009800. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009604. Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009604. Task lfads_param_Qr2PeG__single_dataset003: Decreasing learning rate to 0 .009412. Task lfads_param_Qr2PeG__single_dataset001: Decreasing learning rate to 0 .009412. As the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits c_learning_rate_stop ). When a task fails or completes, the queue will print out a running tally. Note that TensorBoard has automatically been launched on an available port, here on 42561 . You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using tmux list-sessions . \u279c exampleRun tmux list-sessions matlab: 4 windows ( created Tue Oct 3 21 :51:49 2017 ) [ 201x114 ] ( attached ) exampleRun_tensorboard_port42561: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x113 ] lfads_param_Qr2PeG__all: 1 windows ( created Fri Oct 6 14 :43:17 2017 ) [ 201x113 ] lfads_param_Qr2PeG__single_dataset001: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x114 ] lfads_param_Qr2PeG__single_dataset002: 1 windows ( created Fri Oct 6 14 :43:16 2017 ) [ 201x113 ] lfads_param_Qr2PeG__single_dataset003: 1 windows ( created Fri Oct 6 14 :43:17 2017 ) [ 201x113 ] If you wish to abort ongoing runs, you can either attach to them directly and use Ctrl-C , or use tmux kill-session SESSIONNAME . When everything has completed, you\u2019ll see something like this: Task lfads_param_Qr2PeG__all: Stopping optimization based on learning rate criteria. Task lfads_param_Qr2PeG__all: completed successfully Queue: All tasks completed. Queue: 0 skipped, 4 finished, 0 failed, 0 running","title":"LFADS Queue: Automatically queueing many runs"},{"location":"running/#launching-each-run-individually-from-shell-scripts","text":"Follow these instructions to run each model individually, but you\u2019ll probably prefer to queue everything at once .","title":"Launching each run individually from shell scripts"},{"location":"running/#training-the-model","text":"The first is to manually generate shell scripts for each run and then run them yourself. First, for each run i , you will call: rc . runs ( i ). writeShellScriptLFADSTrain ( 'cuda_visible_devices' , 0 , 'display' , 0 ); Here, you should specify options that will be written into the shell script, the key ones being: cuda_visible_devices - which GPU index to run this model on, e.g. 0 . Use the nvidia-smi to enumerate the available GPUs on your system display - the X display to use, e.g. 0 , which will set DISPLAY to :0 . The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like tightvnc or vncserver . appendPosteriorMeanSample - true or false specifying whether to chain the posterior mean sampling operation after the training is finished. The default is false , but if you set this to true , you won\u2019t need to call writeShellScriptPosteriorMeanSample below. appendWriteModelParams - true or false specifying whether to chain the posterior mean sampling operation after the training is finished. The default is false , but if you set this to true , you won\u2019t need to call writeShellScriptWriteModelParams below. This will generate an lfads_train.sh in the corresponding run\u2019s folder. For the first run in our example, this is at ~/lorenz_example/runs/exampleRun/param_Qr2PeG/single_dataset001/lfads_train.sh The script essentially launches Python to run run_lfads.py with the specific parameters you\u2019ve indicated in RunParams and pointing at the corresponding datasets, which were saved earlier when we called rc.prepareForLFADS . #!/bin/bash path_to_run_lfads = $( which run_lfads.py ) if [ ! -n \" $path_to_run_lfads \" ] ; then echo \"Error: run_lfads.py not found on PATH. Ensure you add LFADS to your system PATH.\" exit 1 fi DISPLAY = :0 CUDA_VISIBLE_DEVICES = 0 python $( which run_lfads.py ) --data_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsInput --data_filename_stem = lfads --lfads_save_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsOutput --cell_clip_value = 5 .000000 --factors_dim = 8 --ic_enc_dim = 64 --ci_enc_dim = 128 --gen_dim = 64 --keep_prob = 0 .950000 --learning_rate_decay_factor = 0 .980000 --device = /gpu:0 --co_dim = 0 --do_causal_controller = false --do_feed_factors_to_controller = true --feedback_factors_or_rates = factors --controller_input_lag = 1 --do_train_readin = true --l2_gen_scale = 500 .000000 --l2_con_scale = 500 .000000 --batch_size = 150 --kl_increase_steps = 900 --l2_increase_steps = 900 --ic_dim = 64 --con_dim = 128 --learning_rate_stop = 0 .001000 --temporal_spike_jitter_width = 0 --allow_gpu_growth = true --kl_ic_weight = 1 .000000 --kl_co_weight = 1 .000000 --inject_ext_input_to_gen = false Running the lfads_train.sh script will launch the Tensorflow training which will take some time. You likely want to launch this in a tmux session if running remotely.","title":"Training the model"},{"location":"running/#sampling-the-posterior-means","text":"Next, generate the lfads_posterior_mean_sample.sh script to sample the posterior means, which can be launched after training has completed. If you set appendPosteriorMeanSample to true in writeShellScriptLFADSTrain , you can skip this step. rc . runs ( i ). writeShellScriptLFADSPosteriorMeanSample ( 'cuda_visible_devices' , 0 );","title":"Sampling the posterior means"},{"location":"running/#writing-the-model-parameters","text":"Lastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using rc . runs ( i ). writeShellScriptWriteModelParams ( 'cuda_visible_devices' , 0 ); If you set appendWriteModelParams to true in writeShellScriptLFADSTrain , you can skip this step. These results will be written to a file called lfadsOutput/model_params , though these results can be loaded into Matlab using run.loadModelTrainedParams() .","title":"Writing the model parameters"},{"location":"running/#launching-tensorboard","text":"You can monitor the progress of each run by generating a script that launches TensorBoard. rc . writeTensorboardShellScript (); This will create launch_tensorboard.sh which will launch Tensorboard which can then be visited at http://localhost:PORT .","title":"Launching Tensorboard"},{"location":"single-session/","text":"Setting up a single-session LFADS run \u00b6 Assuming you have finished adapting the LFADS run manager classes to your dataset , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a drive script that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling LFADS Run Manager to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as LorenzExperiment , but you should substitute this with your package name. Follow along with LorenzExperiment.drive_script A complete drive script is available as a starting point in +LorenzExperiment/drive_script.m for you to copy/paste from. Lorenz attractor example \u00b6 For this demo, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code: datasetPath = '~/lorenz_example/datasets' ; LFADS . Utils . generateDemoDatasets ( datasetPath , 'nDatasets' , 3 ); This will simulate a chaotic 3 dimensional Lorenz attractor as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories: From these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the conditions ) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition. Here are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor: Building a dataset collection and adding datasets \u00b6 First, create a dataset collection that points to a folder on disk where datasets are stored: dataPath = '~/lorenz_example/datasets' ; dc = LorenzExperiment . DatasetCollection ( dataPath ); dc . name = 'lorenz_example' ; Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the DatasetCollection and will replace any dataset that has the same name if present. LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); You can verify that the datasets have been added to the collection: >> dc LorenzExperiment . DatasetCollection \" lorenz_example \" 1 datasets in ~/ lorenz_example / datasets [ 1 ] LorenzExperiment . Dataset \" dataset001 \" name : 'lorenz_example' comment : '' path : '~/lorenz_example/datasetss' datasets : [ 1 x1 LorenzExperiment . Dataset ] nDatasets : 1 You can access individual datasets using dc . datasets ( 1 ) or by name with dc . matchDatasetsByName ( 'dataset001' ) . You can then load all of the metadata for the datasets using: dc . loadInfo (); How this metadata is determined for each dataset may be customized as described in Interfacing with your Datasets . You can view a summary of the metadata using: >> dc . getDatasetInfoTable subject date saveTags nTrials nChannels ________________ ______________________ ________ _______ _________ dataset001 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1820 35 Create a RunCollection \u00b6 We\u2019ll now setup a RunCollection that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders. runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'exampleSingleRun' , dc ); % replace with approximate date script authored as YYYYMMDD % to ensure forwards compatibility rc . version = 20180131 ; Versioning and backwards compatibility You can optionally set rc.version just after creating the RunCollection . Version should be set to the date the script was first used to generate the LFADS files on disk, in the format YYYYMMDD . Specifying this here allows for backwards compatibility in case we need to change aspects of where LFADS Run Manager organizes files on disk or how the RunParams hashes are generated. The default rc.version will be updated if significant changes are made in the code, so manually specifying it in the drive script can be useful to \u201cfreeze\u201d the LFADS Run Manager logic for this specific collection of runs. Specify the hyperparameters in RunParams \u00b6 We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. par = LorenzExperiment . RunParams ; par . name = 'first_attempt' ; % completely optional par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_factors_dim = 8 ; % and manually set it for multisession stitched models par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop training early for the demo Setting batch size The number of trials in your smallest dataset determines the largest batch size you can pick. If trainToTestRatio is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as c_batch_size . If you choose a batch size which is too large, LFADS Run Manager will generate an error to alert you. We then add this RunParams to the RunCollection : rc . addParams ( par ); You can access the parameter settings added to rc using rc.params , which will be an array of RunParams instances. The RunParams class will display all of the settings in an organized manner, as well as a summary of those values that differ from their defaults at the top: >> par par = LorenzExperiment . RunParams param_YOs74u data_4MaTKO \" first_attempt \" c_learning_rate_stop = 0.001 c_batch_size = 150 c_co_dim = 0 c_ic_enc_dim = 64 c_gen_dim = 64 c_factors_dim = 8 Computed hashes paramHash : 'YOs74u' paramHashString : 'param_YOs74u' dataHash : '4MaTKO' dataHashString : 'data_4MaTKO' Run Manager logistics and data processing name : 'first_attempt' version : 20171107 spikeBinMs : 2 TensorFlow Logistics c_allow_gpu_growth : 1 c_max_ckpt_to_keep : 5 c_max_ckpt_to_keep_lve : 5 c_device : '/gpu:0' Optimization c_learning_rate_init : 0.0100 c_learning_rate_decay_factor : 0.9800 c_learning_rate_n_to_compare : 6 c_learning_rate_stop : 1.0000e-03 c_max_grad_norm : 200 trainToTestRatio : 4 c_batch_size : 150 c_cell_clip_value : 5 Overfitting c_temporal_spike_jitter_width : 0 c_keep_prob : 0.9500 c_l2_gen_scale : 500 c_l2_con_scale : 500 c_co_mean_corr_scale : 0 Underfitting c_kl_ic_weight : 1 c_kl_co_weight : 1 c_kl_start_step : 0 c_kl_increase_steps : 900 c_l2_start_step : 0 c_l2_increase_steps : 900 scaleIncreaseStepsWithDatasets : 1 External inputs c_ext_input_dim : 0 c_inject_ext_input_to_gen : 0 Controller and inferred inputs c_co_dim : 0 c_prior_ar_atau : 10 c_do_train_prior_ar_atau : 1 c_prior_ar_nvar : 0.1000 c_do_train_prior_ar_nvar : 1 c_do_causal_controller : 0 c_do_feed_factors_to_controller : 1 c_feedback_factors_or_rates : 'factors' c_controller_input_lag : 1 c_ci_enc_dim : 128 c_con_dim : 128 c_co_prior_var_scale : 0.1000 Encoder and initial conditions for generator c_num_steps_for_gen_ic : 4294967295 c_ic_dim : 64 c_ic_enc_dim : 64 c_ic_prior_var_min : 0.1000 c_ic_prior_var_scale : 0.1000 c_ic_prior_var_max : 0.1000 c_ic_post_var_min : 1.0000e-04 Generator network , factors , rates c_cell_weight_scale : 1 c_gen_dim : 64 c_gen_cell_input_weight_scale : 1 c_gen_cell_rec_weight_scale : 1 c_factors_dim : 8 c_output_dist : 'poisson' Stitching multi - session models c_do_train_readin : 1 useAlignmentMatrix : 0 useSingleDatasetAlignmentMatrix : 0 Posterior sampling posterior_mean_kind : 'posterior_sample_and_average' num_samples_posterior : 512 RunParams data and param hashes \u00b6 If we look at the printed representation of the RunParams instance, we see two hash values: >> par par = LorenzExperiment . RunParams param_YOs74u data_4MaTKO c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 ... These six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. The first is the \u201cparam\u201d hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with param_ . The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by data_ . We use two separate hashes here to save space on disk; many parameters like c_co_dim only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like c_co_dim would otherwise require many copies of identical data to be saved on disk. Instead, we store the data in folders according to the data_ hash and symlink copies for each run. If you add additional parameters that do not affect the data used by LFADS, you should specify them in your RunParams class as described here . Below the hash values are the set of properties whose values differ from their specified defaults (as specified next to the property in the class definition). Properties which are equal to their default values are not included in the hash calculation. This allows you to add new properties to your RunParams class without altering the computed hashes for older runs. See this warning note for more details. RunParams is a value class Unlike all of the other classes, RunParams is not a handle but a value class, which acts similarly to a struct in that it is passed by value. This means that after adding the RunParams instance par to the RunCollection , we can modify par and then add it again to define a second set of parameters, like this: par . c_gen_dim = 96 ; rc . addParams ( par ); par . c_gen_dim = 128 ; rc . addParams ( par ); Generating hyperparameter value sweeps If you wish to sweep a specific property or set of properties, you can create a RunParams instance, set the other properties as needed, and then call generateSweep to build an array of RunParams instances: parSet = par . generateSweep ( 'c_gen_dim' , [ 32 64 96 128 ]); rc . addParams ( parSet ); Or along multiple parameters in a grid: parSet = par . generateSweep ( 'c_gen_dim' , [ 32 64 96 128 ], 'c_co_dim' , 0 : 2 : 4 ); rc . addParams ( parSet ); Specify the RunSpec \u00b6 Recall that RunSpec instances specify which datasets are included in a specific run. For this example, we\u2019ve only included a single dataset, so we don\u2019t have any choices to make. We\u2019ll run LFADS on first dataset by itself: ds_index = 1 ; runSpecName = dc . datasets ( ds_index ). getSingleRunName (); % generates a simple run name from this datasets name runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , ds_index ); rc . addRunSpec ( runSpec ); You can adjust the arguments to the constructor of LorenzExperiment.RunSpec , but in the example provided the inputs define: the unique name of the run. Here we use getSingleRunName , a convenience method of Dataset that generates a name like single_datasetName . the DatasetCollection from which datasets will be retrieved the indices or names of datasets (as a string or cell array of strings) to include Check the RunCollection \u00b6 The RunCollection will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total. >> rc LorenzExperiment . RunCollection \" exampleSingleSession \" ( 1 runs total ) Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleSingleSession 1 parameter settings [ 1 param_YOs74u data_4MaTKO ] LorenzExperiment . RunParams \" first_attempt \" c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) name : 'exampleSingleSession' comment : '' rootPath : '~/lorenz_example/runs' version : 20180131 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x1 LorenzExperiment . Run ] params : [ 1 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 1 nRunSpecs : 1 nRunsTotal : 1 nDatasets : 1 datasetNames : { 'dataset001' } path : '~/lorenz_example/runs/exampleSingleSession' pathsCommonDataForParams : { '~/lorenz_example/runs/exampleSingleSession/data_4MaTKO' } pathsForParams : { '~/lorenz_example/runs/exampleSingleSession/param_YOs74u' } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleSingleSession/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py' Prepare for LFADS \u00b6 Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS. rc . prepareForLFADS (); This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call prepareForLFADS again. Existing files won\u2019t be overwritten unless you call rc.prepareForLFADS(true) . After running prepareForLFADS , the run manager will create the following files on disk under rc.path : ~/lorenz_example/runs/exampleSingleSession \u251c\u2500\u2500 data_4MaTKO \u2502 \u2514\u2500\u2500 single_dataset001 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 \u251c\u2500\u2500 param_YOs74u \u2502 \u2514\u2500\u2500 single_dataset001 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/single_dataset001/inputInfo_dataset001.mat \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/single_dataset001/lfads_dataset001.h5 \u2514\u2500\u2500 summary.txt The organization of these files on disk is discussed in more detail here . Also, a summary.txt file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling rc.generateSummaryText() . LorenzExperiment . RunCollection \" exampleSingleSession \" ( 1 runs total ) Path : ~/ lorenz_example / runs / exampleSingleSession Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets ------------------------ 1 Run Specifications : [ runSpec 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) [ ds 1 ] LorenzExperiment . Dataset \" dataset001 \" ------------------------ 1 Parameter Settings : [ 1 param_YOs74u data_4MaTKO ] LorenzExperiment . RunParams \" first_attempt \" c_learning_rate_stop = 0.001 c_batch_size = 150 c_co_dim = 0 c_ic_enc_dim = 64 c_gen_dim = 64 c_factors_dim = 8 spikeBinMs : 2 c_allow_gpu_growth : true c_max_ckpt_to_keep : 5 c_max_ckpt_to_keep_lve : 5 c_device : / gpu : 0 c_learning_rate_init : 0.01 c_learning_rate_decay_factor : 0.98 c_learning_rate_n_to_compare : 6 c_learning_rate_stop : 0.001 c_max_grad_norm : 200 trainToTestRatio : 4 c_batch_size : 150 c_cell_clip_value : 5 c_temporal_spike_jitter_width : 0 c_keep_prob : 0.95 c_l2_gen_scale : 500 c_l2_con_scale : 500 c_co_mean_corr_scale : 0 c_kl_ic_weight : 1 c_kl_co_weight : 1 c_kl_start_step : 0 c_kl_increase_steps : 900 c_l2_start_step : 0 c_l2_increase_steps : 900 scaleIncreaseStepsWithDatasets : true c_ext_input_dim : 0 c_inject_ext_input_to_gen : false c_co_dim : 0 c_prior_ar_atau : 10 c_do_train_prior_ar_atau : true c_prior_ar_nvar : 0.1 c_do_train_prior_ar_nvar : true c_do_causal_controller : false c_do_feed_factors_to_controller : true c_feedback_factors_or_rates : factors c_controller_input_lag : 1 c_ci_enc_dim : 128 c_con_dim : 128 c_co_prior_var_scale : 0.1 c_num_steps_for_gen_ic : 4294967295 c_ic_dim : 64 c_ic_enc_dim : 64 c_ic_prior_var_min : 0.1 c_ic_prior_var_scale : 0.1 c_ic_prior_var_max : 0.1 c_ic_post_var_min : 0.0001 c_cell_weight_scale : 1 c_gen_dim : 64 c_gen_cell_input_weight_scale : 1 c_gen_cell_rec_weight_scale : 1 c_factors_dim : 8 c_output_dist : poisson c_do_train_readin : true useAlignmentMatrix : false useSingleDatasetAlignmentMatrix : false posterior_mean_kind : posterior_sample_and_average num_samples_posterior : 512","title":"Setting up a single-session run"},{"location":"single-session/#setting-up-a-single-session-lfads-run","text":"Assuming you have finished adapting the LFADS run manager classes to your dataset , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a drive script that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling LFADS Run Manager to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as LorenzExperiment , but you should substitute this with your package name. Follow along with LorenzExperiment.drive_script A complete drive script is available as a starting point in +LorenzExperiment/drive_script.m for you to copy/paste from.","title":"Setting up a single-session LFADS run"},{"location":"single-session/#lorenz-attractor-example","text":"For this demo, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code: datasetPath = '~/lorenz_example/datasets' ; LFADS . Utils . generateDemoDatasets ( datasetPath , 'nDatasets' , 3 ); This will simulate a chaotic 3 dimensional Lorenz attractor as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories: From these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the conditions ) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition. Here are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:","title":"Lorenz attractor example"},{"location":"single-session/#building-a-dataset-collection-and-adding-datasets","text":"First, create a dataset collection that points to a folder on disk where datasets are stored: dataPath = '~/lorenz_example/datasets' ; dc = LorenzExperiment . DatasetCollection ( dataPath ); dc . name = 'lorenz_example' ; Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the DatasetCollection and will replace any dataset that has the same name if present. LorenzExperiment . Dataset ( dc , 'dataset001.mat' ); You can verify that the datasets have been added to the collection: >> dc LorenzExperiment . DatasetCollection \" lorenz_example \" 1 datasets in ~/ lorenz_example / datasets [ 1 ] LorenzExperiment . Dataset \" dataset001 \" name : 'lorenz_example' comment : '' path : '~/lorenz_example/datasetss' datasets : [ 1 x1 LorenzExperiment . Dataset ] nDatasets : 1 You can access individual datasets using dc . datasets ( 1 ) or by name with dc . matchDatasetsByName ( 'dataset001' ) . You can then load all of the metadata for the datasets using: dc . loadInfo (); How this metadata is determined for each dataset may be customized as described in Interfacing with your Datasets . You can view a summary of the metadata using: >> dc . getDatasetInfoTable subject date saveTags nTrials nChannels ________________ ______________________ ________ _______ _________ dataset001 'lorenz_example' [ 31 - Jan - 2018 00 : 00 : 00 ] '1' 1820 35","title":"Building a dataset collection and adding datasets"},{"location":"single-session/#create-a-runcollection","text":"We\u2019ll now setup a RunCollection that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders. runRoot = '~/lorenz_example/runs' ; rc = LorenzExperiment . RunCollection ( runRoot , 'exampleSingleRun' , dc ); % replace with approximate date script authored as YYYYMMDD % to ensure forwards compatibility rc . version = 20180131 ; Versioning and backwards compatibility You can optionally set rc.version just after creating the RunCollection . Version should be set to the date the script was first used to generate the LFADS files on disk, in the format YYYYMMDD . Specifying this here allows for backwards compatibility in case we need to change aspects of where LFADS Run Manager organizes files on disk or how the RunParams hashes are generated. The default rc.version will be updated if significant changes are made in the code, so manually specifying it in the drive script can be useful to \u201cfreeze\u201d the LFADS Run Manager logic for this specific collection of runs.","title":"Create a RunCollection"},{"location":"single-session/#specify-the-hyperparameters-in-runparams","text":"We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. par = LorenzExperiment . RunParams ; par . name = 'first_attempt' ; % completely optional par . spikeBinMs = 2 ; % rebin the data at 2 ms par . c_co_dim = 0 ; % no controller --> no inputs to generator par . c_batch_size = 150 ; % must be < 1/5 of the min trial count par . c_factors_dim = 8 ; % and manually set it for multisession stitched models par . c_gen_dim = 64 ; % number of units in generator RNN par . c_ic_enc_dim = 64 ; % number of units in encoder RNN par . c_learning_rate_stop = 1e-3 ; % we can stop training early for the demo Setting batch size The number of trials in your smallest dataset determines the largest batch size you can pick. If trainToTestRatio is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as c_batch_size . If you choose a batch size which is too large, LFADS Run Manager will generate an error to alert you. We then add this RunParams to the RunCollection : rc . addParams ( par ); You can access the parameter settings added to rc using rc.params , which will be an array of RunParams instances. The RunParams class will display all of the settings in an organized manner, as well as a summary of those values that differ from their defaults at the top: >> par par = LorenzExperiment . RunParams param_YOs74u data_4MaTKO \" first_attempt \" c_learning_rate_stop = 0.001 c_batch_size = 150 c_co_dim = 0 c_ic_enc_dim = 64 c_gen_dim = 64 c_factors_dim = 8 Computed hashes paramHash : 'YOs74u' paramHashString : 'param_YOs74u' dataHash : '4MaTKO' dataHashString : 'data_4MaTKO' Run Manager logistics and data processing name : 'first_attempt' version : 20171107 spikeBinMs : 2 TensorFlow Logistics c_allow_gpu_growth : 1 c_max_ckpt_to_keep : 5 c_max_ckpt_to_keep_lve : 5 c_device : '/gpu:0' Optimization c_learning_rate_init : 0.0100 c_learning_rate_decay_factor : 0.9800 c_learning_rate_n_to_compare : 6 c_learning_rate_stop : 1.0000e-03 c_max_grad_norm : 200 trainToTestRatio : 4 c_batch_size : 150 c_cell_clip_value : 5 Overfitting c_temporal_spike_jitter_width : 0 c_keep_prob : 0.9500 c_l2_gen_scale : 500 c_l2_con_scale : 500 c_co_mean_corr_scale : 0 Underfitting c_kl_ic_weight : 1 c_kl_co_weight : 1 c_kl_start_step : 0 c_kl_increase_steps : 900 c_l2_start_step : 0 c_l2_increase_steps : 900 scaleIncreaseStepsWithDatasets : 1 External inputs c_ext_input_dim : 0 c_inject_ext_input_to_gen : 0 Controller and inferred inputs c_co_dim : 0 c_prior_ar_atau : 10 c_do_train_prior_ar_atau : 1 c_prior_ar_nvar : 0.1000 c_do_train_prior_ar_nvar : 1 c_do_causal_controller : 0 c_do_feed_factors_to_controller : 1 c_feedback_factors_or_rates : 'factors' c_controller_input_lag : 1 c_ci_enc_dim : 128 c_con_dim : 128 c_co_prior_var_scale : 0.1000 Encoder and initial conditions for generator c_num_steps_for_gen_ic : 4294967295 c_ic_dim : 64 c_ic_enc_dim : 64 c_ic_prior_var_min : 0.1000 c_ic_prior_var_scale : 0.1000 c_ic_prior_var_max : 0.1000 c_ic_post_var_min : 1.0000e-04 Generator network , factors , rates c_cell_weight_scale : 1 c_gen_dim : 64 c_gen_cell_input_weight_scale : 1 c_gen_cell_rec_weight_scale : 1 c_factors_dim : 8 c_output_dist : 'poisson' Stitching multi - session models c_do_train_readin : 1 useAlignmentMatrix : 0 useSingleDatasetAlignmentMatrix : 0 Posterior sampling posterior_mean_kind : 'posterior_sample_and_average' num_samples_posterior : 512","title":"Specify the hyperparameters in RunParams"},{"location":"single-session/#runparams-data-and-param-hashes","text":"If we look at the printed representation of the RunParams instance, we see two hash values: >> par par = LorenzExperiment . RunParams param_YOs74u data_4MaTKO c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 ... These six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. The first is the \u201cparam\u201d hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with param_ . The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by data_ . We use two separate hashes here to save space on disk; many parameters like c_co_dim only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like c_co_dim would otherwise require many copies of identical data to be saved on disk. Instead, we store the data in folders according to the data_ hash and symlink copies for each run. If you add additional parameters that do not affect the data used by LFADS, you should specify them in your RunParams class as described here . Below the hash values are the set of properties whose values differ from their specified defaults (as specified next to the property in the class definition). Properties which are equal to their default values are not included in the hash calculation. This allows you to add new properties to your RunParams class without altering the computed hashes for older runs. See this warning note for more details. RunParams is a value class Unlike all of the other classes, RunParams is not a handle but a value class, which acts similarly to a struct in that it is passed by value. This means that after adding the RunParams instance par to the RunCollection , we can modify par and then add it again to define a second set of parameters, like this: par . c_gen_dim = 96 ; rc . addParams ( par ); par . c_gen_dim = 128 ; rc . addParams ( par ); Generating hyperparameter value sweeps If you wish to sweep a specific property or set of properties, you can create a RunParams instance, set the other properties as needed, and then call generateSweep to build an array of RunParams instances: parSet = par . generateSweep ( 'c_gen_dim' , [ 32 64 96 128 ]); rc . addParams ( parSet ); Or along multiple parameters in a grid: parSet = par . generateSweep ( 'c_gen_dim' , [ 32 64 96 128 ], 'c_co_dim' , 0 : 2 : 4 ); rc . addParams ( parSet );","title":"RunParams data and param hashes"},{"location":"single-session/#specify-the-runspec","text":"Recall that RunSpec instances specify which datasets are included in a specific run. For this example, we\u2019ve only included a single dataset, so we don\u2019t have any choices to make. We\u2019ll run LFADS on first dataset by itself: ds_index = 1 ; runSpecName = dc . datasets ( ds_index ). getSingleRunName (); % generates a simple run name from this datasets name runSpec = LorenzExperiment . RunSpec ( runSpecName , dc , ds_index ); rc . addRunSpec ( runSpec ); You can adjust the arguments to the constructor of LorenzExperiment.RunSpec , but in the example provided the inputs define: the unique name of the run. Here we use getSingleRunName , a convenience method of Dataset that generates a name like single_datasetName . the DatasetCollection from which datasets will be retrieved the indices or names of datasets (as a string or cell array of strings) to include","title":"Specify the RunSpec"},{"location":"single-session/#check-the-runcollection","text":"The RunCollection will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total. >> rc LorenzExperiment . RunCollection \" exampleSingleSession \" ( 1 runs total ) Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets Path : ~/ lorenz_example / runs / exampleSingleSession 1 parameter settings [ 1 param_YOs74u data_4MaTKO ] LorenzExperiment . RunParams \" first_attempt \" c_factors_dim = 8 c_ic_enc_dim = 64 c_gen_dim = 64 c_co_dim = 0 c_batch_size = 150 c_learning_rate_stop = 0.001 1 run specifications [ 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) name : 'exampleSingleSession' comment : '' rootPath : '~/lorenz_example/runs' version : 20180131 datasetCollection : [ 1 x1 LorenzExperiment . DatasetCollection ] runs : [ 1 x1 LorenzExperiment . Run ] params : [ 1 x1 LorenzExperiment . RunParams ] runSpecs : [ 1 x1 LorenzExperiment . RunSpec ] nParams : 1 nRunSpecs : 1 nRunsTotal : 1 nDatasets : 1 datasetNames : { 'dataset001' } path : '~/lorenz_example/runs/exampleSingleSession' pathsCommonDataForParams : { '~/lorenz_example/runs/exampleSingleSession/data_4MaTKO' } pathsForParams : { '~/lorenz_example/runs/exampleSingleSession/param_YOs74u' } fileShellScriptTensorboard : '~/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh' fileSummaryText : '~/lorenz_example/runs/exampleSingleSession/summary.txt' fileShellScriptRunQueue : '~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py'","title":"Check the RunCollection"},{"location":"single-session/#prepare-for-lfads","text":"Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS. rc . prepareForLFADS (); This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call prepareForLFADS again. Existing files won\u2019t be overwritten unless you call rc.prepareForLFADS(true) . After running prepareForLFADS , the run manager will create the following files on disk under rc.path : ~/lorenz_example/runs/exampleSingleSession \u251c\u2500\u2500 data_4MaTKO \u2502 \u2514\u2500\u2500 single_dataset001 \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 \u251c\u2500\u2500 param_YOs74u \u2502 \u2514\u2500\u2500 single_dataset001 \u2502 \u2514\u2500\u2500 lfadsInput \u2502 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/single_dataset001/inputInfo_dataset001.mat \u2502 \u2514\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/single_dataset001/lfads_dataset001.h5 \u2514\u2500\u2500 summary.txt The organization of these files on disk is discussed in more detail here . Also, a summary.txt file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling rc.generateSummaryText() . LorenzExperiment . RunCollection \" exampleSingleSession \" ( 1 runs total ) Path : ~/ lorenz_example / runs / exampleSingleSession Dataset Collection \" lorenz_example \" ( 1 datasets ) in ~/ lorenz_example / datasets ------------------------ 1 Run Specifications : [ runSpec 1 ] LorenzExperiment . RunSpec \" single_dataset001 \" ( 1 datasets ) [ ds 1 ] LorenzExperiment . Dataset \" dataset001 \" ------------------------ 1 Parameter Settings : [ 1 param_YOs74u data_4MaTKO ] LorenzExperiment . RunParams \" first_attempt \" c_learning_rate_stop = 0.001 c_batch_size = 150 c_co_dim = 0 c_ic_enc_dim = 64 c_gen_dim = 64 c_factors_dim = 8 spikeBinMs : 2 c_allow_gpu_growth : true c_max_ckpt_to_keep : 5 c_max_ckpt_to_keep_lve : 5 c_device : / gpu : 0 c_learning_rate_init : 0.01 c_learning_rate_decay_factor : 0.98 c_learning_rate_n_to_compare : 6 c_learning_rate_stop : 0.001 c_max_grad_norm : 200 trainToTestRatio : 4 c_batch_size : 150 c_cell_clip_value : 5 c_temporal_spike_jitter_width : 0 c_keep_prob : 0.95 c_l2_gen_scale : 500 c_l2_con_scale : 500 c_co_mean_corr_scale : 0 c_kl_ic_weight : 1 c_kl_co_weight : 1 c_kl_start_step : 0 c_kl_increase_steps : 900 c_l2_start_step : 0 c_l2_increase_steps : 900 scaleIncreaseStepsWithDatasets : true c_ext_input_dim : 0 c_inject_ext_input_to_gen : false c_co_dim : 0 c_prior_ar_atau : 10 c_do_train_prior_ar_atau : true c_prior_ar_nvar : 0.1 c_do_train_prior_ar_nvar : true c_do_causal_controller : false c_do_feed_factors_to_controller : true c_feedback_factors_or_rates : factors c_controller_input_lag : 1 c_ci_enc_dim : 128 c_con_dim : 128 c_co_prior_var_scale : 0.1 c_num_steps_for_gen_ic : 4294967295 c_ic_dim : 64 c_ic_enc_dim : 64 c_ic_prior_var_min : 0.1 c_ic_prior_var_scale : 0.1 c_ic_prior_var_max : 0.1 c_ic_post_var_min : 0.0001 c_cell_weight_scale : 1 c_gen_dim : 64 c_gen_cell_input_weight_scale : 1 c_gen_cell_rec_weight_scale : 1 c_factors_dim : 8 c_output_dist : poisson c_do_train_readin : true useAlignmentMatrix : false useSingleDatasetAlignmentMatrix : false posterior_mean_kind : posterior_sample_and_average num_samples_posterior : 512","title":"Prepare for LFADS"},{"location":"trained-params/","text":"Loading the trained LFADS model parameters \u00b6 Loading the model_params \u00b6 After the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called lfadsOutput/model_params , as described here . If you used the run queue to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed. model_params is an HD5 file that contains all of the model parameters. To load these, each LFADS.Run provides a method run.loadModelTrainedParams() that will return an instance of LFADS.ModelTrainedParameters . This instance will have many fields, corresponding to the set of parameters learned by LFADS. List of model trained parameters \u00b6 Below is an annotated list of the properties found within the ModelTrainedParameters instance, along with the size of each parameter relative to hyperparameters specified in the corresponding RunParams . For reference, here is the schematic of an LFADS model: Read-in from spikes to input factors \u00b6 Name Description Size x_to_infac_W readin alignment weights, mapping from counts to input factors nDatasets x 1 cell of nNeuronsThisDataset x c_factors_dim x_to_infac_b readin alignment biases to input factors nDatasets x 1 cell of 1 x c_factors_dim Initial condition encoder (forward) \u00b6 Name Description Size ic_enc_fwd_t0 forward IC encoder prior on t0 1 x c_ic_enc_dim ic_enc_fwd_gru_xh_to_gates_ru_W forward IC encoder GRU, mapping input+hiddens to gates r and u, weights ( c_ic_enc_dim + factors_dim) x (2 * c_ic_enc_dim ) ic_enc_fwd_gru_xh_to_gates_ru_b forward IC encoder GRU bmapping input+hiddens to gates r and u, biases 1 x (2* c_ic_enc_dim ) ic_enc_fwd_gru_xrh_to_c_W forward IC encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ic_enc_dim + c_factors_dim ) x c_ic_enc_dim ic_enc_fwd_gru_xrh_to_c_b forward IC encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ic_enc_dim Initial condition encoder (reverse) \u00b6 Name Description Size ic_enc_rev_t0 reverse IC encoder prior on t0 1 x c_ic_enc_dim ic_enc_rev_gru_xh_to_gates_ru_W reverse IC encoder GRU, mapping input+hidden to gates r and u, weights ( c_factors_dim + c_ic_enc_dim ) x (2* c_ic_enc_dim ) ic_enc_rev_gru_xh_to_gates_ru_b reverse IC encoder GRU bmapping input+hidden to gates r and u, biases 1 x (2* c_ic_enc_dim ) ic_enc_rev_gru_xrh_to_c_W reverse IC encoder GRU mapping input+r+hidden to candidates (weights) ( c_ic_enc_dim + c_factors_dim ) x c_ic_enc_dim ic_enc_rev_gru_xrh_to_c_b reverse IC encoder GRU mapping input+r+hidden to candidates (bias) 1 x c_ic_enc_dim Initial condition g0 \u00b6 Name Description Size prior_g0_mean Mean parameter in prior on initial condition g0 1 x c_ic_dim prior_g0_logvar Logvar parameter in prior on initial condition g0 1 x c_ic_dim ic_enc_to_posterior_g0_mean_W Weights for mean parameter in posterior of the initial condition g0 (2* c_ic_enc_dim ) x c_ic_dim ic_enc_to_posterior_g0_mean_b Bias for mean parameter in posterior of the initial condition g0 1 x c_ic_dim ic_enc_to_posterior_g0_logvar_W Weights for logvar parameter in posterior of the initial condition g0 (2* c_ic_enc_dim ) x c_ic_dim ic_enc_to_posterior_g0_logvar_b Bias for logvar parameter in posterior of the initial condition g0 1 x c_ic_dim g0_to_gen_ic_W mapping from g0 to generator initial condition, weights c_ic_dim x c_gen_dim g0_to_gen_ic_b mapping from g0 to generator initial condition, bias 1 x c_gen_dim Controller encoder (forward) \u00b6 Name Description Size ci_enc_fwd_t0 forward controller prior on t0 1 x c_ci_enc_dim ci_enc_fwd_gru_xh_to_ru_W forward controller encoder GRU, mapping input+hidden to gates r and u, weights ( ci_enc_dim + c_factors_dim ) x (2* c_ci_enc_dim ) ci_enc_fwd_gru_xh_to_ru_b forward controller encoder GRU, mapping input+hidden to gates r and u, bias 1 x (2* c_ci_enc_dim ) ci_enc_fwd_gru_xrh_to_c_W forward controller encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ci_enc_dim + c_factors_dim ) x c_ci_enc_dim ) ci_enc_fwd_gru_xrh_to_c_b forward controller encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ci_enc_dim Controller encoder (reverse) \u00b6 Name Description Size ci_enc_rev_t0 reverse controller prior on t0 1 x c_ci_enc_dim ci_enc_rev_gru_xh_to_ru_W reverse controller encoder GRU, mapping input+hidden to gates r and u, weights (ci_enc_dim + factors_dim) x (2* c_ci_enc_dim ) ci_enc_rev_gru_xh_to_ru_b reverse controller encoder GRU, mapping input+hidden to gates r and u, bias 1 x (2* c_ci_enc_dim ) ci_enc_rev_gru_xrh_to_c_W reverse controller encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ci_enc_dim + c_factors_dim ) x c_ci_enc_dim ) ci_enc_rev_gru_xrh_to_c_b reverse controller encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ci_enc_dim Controlller RNN \u00b6 Name Description Size con_gengru_x_to_ru_W controller GenGRU, mapping input to gates r+u, weights ( c_ci_enc_dim * 2 + c_factors_dim ) x (2* c_con_dim ) con_gengru_h_to_ru_W controller GenGRU, mapping hidden to gates r+u, weights c_con_dim x (2* c_con_dim ) con_gengru_h_to_ru_b controller GenGRU, mapping hidden to gates r+u, weights 1 x (2* c_con_dim ) con_gengru_x_to_c_W controller GenGRU, mapping input to candidates, weights ( c_ci_enc_dim * 2 + c_factors_dim ) x c_con_dim con_gengru_rh_to_c_b controller GenGRU, mapping r+hidden to candidates, bias 1 x c_con_dim Controller output co \u00b6 Name Description Size prior_ar1_logevars autoregressive prior on controller outputs 1 x c_co_dim prior_ar1_logatau autoregressive time constant prior on controller outputs 1 x c_co_dim con_co prior on controller output 1 x c_con_dim con_to_posterior_co_mean_W mapping from controller to mean parameter of co, weights c_con_dim x c_co_dim con_to_posterior_co_mean_b mapping from controller to mean parameter of co, biases 1 x c_co_dim con_to_posterior_co_logvar_W mapping from controller to logvar parameter of co, weights c_con_dim x c_co_dim con_to_posterior_co_logvar_b mapping from controller to logvar parameter of co, biases 1 x c_co_dim Generator RNN \u00b6 Name Description Size gen_gengru_x_to_ru_W generator GRU, mapping from input to gates r+u, weights c_co_dim x (2* c_gen_dim ) gen_gengru_h_to_ru_W generator GRU, mapping from input to gates r+u, weights c_gen_dim x (2* c_gen_dim ) gen_gengru_h_to_ru_b generator GRU, mapping from input to gates r+u, biases 1 x (2* c_gen_dim ) gen_gengru_x_to_c_W generator GRU, mapping from input to candidates, weights c_co_dim x c_gen_dim gen_gengru_rh_to_c_W generator GRU, mapping from r+hidden to candidates, weights c_gen_dim x c_gen_dim gen_gengru_rh_to_c_b generator GRU, mapping from r+hidden to candidates, biases 1 x c_gen_dim Generator output \u00b6 Name Description Size gen_to_factors_W mapping from generator to factors, weights c_gen_dim x c_factors_dim factors_to_logrates_W readout alignment weights nDatasets x 1 cell of c_factors_dim x nNeuronsThisDataset factors_to_logrates_b readout alignment biases nDatasets x 1 cell of 1 x nNeuronsThisDataset Loading model_params for Lorenz example \u00b6 We can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with c_co_dim == 0 . >> mtp = rc . findRuns ( 'all' , 1 ). loadModelTrainedParams () ans = ModelTrainedParams with properties : Read - in from spikes to input factors x_to_infac_W : { 3 x1 cell } x_to_infac_b : { 3 x1 cell } Initial condition encoder ( forward ) ic_enc_fwd_t0 : [ 64 x1 single ] ic_enc_fwd_gru_xh_to_gates_ru_W : [ 128 x72 single ] ic_enc_fwd_gru_xh_to_gates_ru_b : [ 128 x1 single ] ic_enc_fwd_gru_xrh_to_c_W : [ 64 x72 single ] ic_enc_fwd_gru_xrh_to_c_b : [ 64 x1 single ] Initial condition encoder ( reverse ) ic_enc_rev_t0 : [ 64 x1 single ] ic_enc_rev_gru_xh_to_gates_ru_W : [ 128 x72 single ] ic_enc_rev_gru_xh_to_gates_ru_b : [ 128 x1 single ] ic_enc_rev_gru_xrh_to_c_W : [ 64 x72 single ] ic_enc_rev_gru_xrh_to_c_b : [ 64 x1 single ] Initial condition g0 prior_g0_mean : [ 64 x1 single ] prior_g0_logvar : [ 64 x1 single ] ic_enc_to_posterior_g0_mean_W : [ 64 x128 single ] ic_enc_to_posterior_g0_mean_b : [ 64 x1 single ] ic_enc_to_posterior_g0_logvar_W : [ 64 x128 single ] ic_enc_to_posterior_g0_logvar_b : [ 64 x1 single ] g0_to_gen_ic_W : [] g0_to_gen_ic_b : [] Controller encoder ( forward ) ci_enc_fwd_t0 : [] ci_enc_fwd_gru_xh_to_ru_W : [] ci_enc_fwd_gru_xh_to_ru_b : [] ci_enc_fwd_gru_xrh_to_c_W : [] ci_enc_fwd_gru_xrh_to_c_b : [] Controller encoder ( reverse ) ci_enc_rev_t0 : [] ci_enc_rev_gru_xh_to_ru_W : [] ci_enc_rev_gru_xh_to_ru_b : [] ci_enc_rev_gru_xrh_to_c_W : [] ci_enc_rev_gru_xrh_to_c_b : [] Controlller RNN con_gengru_x_to_ru_W : [] con_gengru_h_to_ru_W : [] con_gengru_h_to_ru_b : [] con_gengru_x_to_c_W : [] con_gengru_rh_to_c_W : [] con_gengru_rh_to_c_b : [] Controller output co prior_ar1_logevars : [] prior_ar1_logatau : [] con_co : [] con_to_posterior_co_mean_W : [] con_to_posterior_co_mean_b : [] con_to_posterior_co_logvar_W : [] con_to_posterior_co_logvar_b : [] Generator RNN gen_gengru_x_to_ru_W : [] gen_gengru_h_to_ru_W : [ 128 x64 single ] gen_gengru_h_to_ru_b : [ 128 x1 single ] gen_gengru_x_to_c_W : [] gen_gengru_rh_to_c_W : [ 64 x64 single ] gen_gengru_rh_to_c_b : [ 64 x1 single ] Generator output gen_to_factors_W : [ 8 x64 single ] factors_to_logrates_W : { 3 x1 cell } factors_to_logrates_b : { 3 x1 cell } The recurrent connectivity weight matrix of the c_gen_dim==64 GRU generator RNN is given by mtp.gen_gengru_rh_to_c_W : And the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by mtp.factors_to_logrates_W :","title":"Loading the Model Trained Parameters"},{"location":"trained-params/#loading-the-trained-lfads-model-parameters","text":"","title":"Loading the trained LFADS model parameters"},{"location":"trained-params/#loading-the-model_params","text":"After the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called lfadsOutput/model_params , as described here . If you used the run queue to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed. model_params is an HD5 file that contains all of the model parameters. To load these, each LFADS.Run provides a method run.loadModelTrainedParams() that will return an instance of LFADS.ModelTrainedParameters . This instance will have many fields, corresponding to the set of parameters learned by LFADS.","title":"Loading the model_params"},{"location":"trained-params/#list-of-model-trained-parameters","text":"Below is an annotated list of the properties found within the ModelTrainedParameters instance, along with the size of each parameter relative to hyperparameters specified in the corresponding RunParams . For reference, here is the schematic of an LFADS model:","title":"List of model trained parameters"},{"location":"trained-params/#read-in-from-spikes-to-input-factors","text":"Name Description Size x_to_infac_W readin alignment weights, mapping from counts to input factors nDatasets x 1 cell of nNeuronsThisDataset x c_factors_dim x_to_infac_b readin alignment biases to input factors nDatasets x 1 cell of 1 x c_factors_dim","title":"Read-in from spikes to input factors"},{"location":"trained-params/#initial-condition-encoder-forward","text":"Name Description Size ic_enc_fwd_t0 forward IC encoder prior on t0 1 x c_ic_enc_dim ic_enc_fwd_gru_xh_to_gates_ru_W forward IC encoder GRU, mapping input+hiddens to gates r and u, weights ( c_ic_enc_dim + factors_dim) x (2 * c_ic_enc_dim ) ic_enc_fwd_gru_xh_to_gates_ru_b forward IC encoder GRU bmapping input+hiddens to gates r and u, biases 1 x (2* c_ic_enc_dim ) ic_enc_fwd_gru_xrh_to_c_W forward IC encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ic_enc_dim + c_factors_dim ) x c_ic_enc_dim ic_enc_fwd_gru_xrh_to_c_b forward IC encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ic_enc_dim","title":"Initial condition encoder (forward)"},{"location":"trained-params/#initial-condition-encoder-reverse","text":"Name Description Size ic_enc_rev_t0 reverse IC encoder prior on t0 1 x c_ic_enc_dim ic_enc_rev_gru_xh_to_gates_ru_W reverse IC encoder GRU, mapping input+hidden to gates r and u, weights ( c_factors_dim + c_ic_enc_dim ) x (2* c_ic_enc_dim ) ic_enc_rev_gru_xh_to_gates_ru_b reverse IC encoder GRU bmapping input+hidden to gates r and u, biases 1 x (2* c_ic_enc_dim ) ic_enc_rev_gru_xrh_to_c_W reverse IC encoder GRU mapping input+r+hidden to candidates (weights) ( c_ic_enc_dim + c_factors_dim ) x c_ic_enc_dim ic_enc_rev_gru_xrh_to_c_b reverse IC encoder GRU mapping input+r+hidden to candidates (bias) 1 x c_ic_enc_dim","title":"Initial condition encoder (reverse)"},{"location":"trained-params/#initial-condition-g0","text":"Name Description Size prior_g0_mean Mean parameter in prior on initial condition g0 1 x c_ic_dim prior_g0_logvar Logvar parameter in prior on initial condition g0 1 x c_ic_dim ic_enc_to_posterior_g0_mean_W Weights for mean parameter in posterior of the initial condition g0 (2* c_ic_enc_dim ) x c_ic_dim ic_enc_to_posterior_g0_mean_b Bias for mean parameter in posterior of the initial condition g0 1 x c_ic_dim ic_enc_to_posterior_g0_logvar_W Weights for logvar parameter in posterior of the initial condition g0 (2* c_ic_enc_dim ) x c_ic_dim ic_enc_to_posterior_g0_logvar_b Bias for logvar parameter in posterior of the initial condition g0 1 x c_ic_dim g0_to_gen_ic_W mapping from g0 to generator initial condition, weights c_ic_dim x c_gen_dim g0_to_gen_ic_b mapping from g0 to generator initial condition, bias 1 x c_gen_dim","title":"Initial condition g0"},{"location":"trained-params/#controller-encoder-forward","text":"Name Description Size ci_enc_fwd_t0 forward controller prior on t0 1 x c_ci_enc_dim ci_enc_fwd_gru_xh_to_ru_W forward controller encoder GRU, mapping input+hidden to gates r and u, weights ( ci_enc_dim + c_factors_dim ) x (2* c_ci_enc_dim ) ci_enc_fwd_gru_xh_to_ru_b forward controller encoder GRU, mapping input+hidden to gates r and u, bias 1 x (2* c_ci_enc_dim ) ci_enc_fwd_gru_xrh_to_c_W forward controller encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ci_enc_dim + c_factors_dim ) x c_ci_enc_dim ) ci_enc_fwd_gru_xrh_to_c_b forward controller encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ci_enc_dim","title":"Controller encoder (forward)"},{"location":"trained-params/#controller-encoder-reverse","text":"Name Description Size ci_enc_rev_t0 reverse controller prior on t0 1 x c_ci_enc_dim ci_enc_rev_gru_xh_to_ru_W reverse controller encoder GRU, mapping input+hidden to gates r and u, weights (ci_enc_dim + factors_dim) x (2* c_ci_enc_dim ) ci_enc_rev_gru_xh_to_ru_b reverse controller encoder GRU, mapping input+hidden to gates r and u, bias 1 x (2* c_ci_enc_dim ) ci_enc_rev_gru_xrh_to_c_W reverse controller encoder GRU mapping input, r, and hidden to candidates (weights) ( c_ci_enc_dim + c_factors_dim ) x c_ci_enc_dim ) ci_enc_rev_gru_xrh_to_c_b reverse controller encoder GRU mapping input, r, and hidden to candidates (bias) 1 x c_ci_enc_dim","title":"Controller encoder (reverse)"},{"location":"trained-params/#controlller-rnn","text":"Name Description Size con_gengru_x_to_ru_W controller GenGRU, mapping input to gates r+u, weights ( c_ci_enc_dim * 2 + c_factors_dim ) x (2* c_con_dim ) con_gengru_h_to_ru_W controller GenGRU, mapping hidden to gates r+u, weights c_con_dim x (2* c_con_dim ) con_gengru_h_to_ru_b controller GenGRU, mapping hidden to gates r+u, weights 1 x (2* c_con_dim ) con_gengru_x_to_c_W controller GenGRU, mapping input to candidates, weights ( c_ci_enc_dim * 2 + c_factors_dim ) x c_con_dim con_gengru_rh_to_c_b controller GenGRU, mapping r+hidden to candidates, bias 1 x c_con_dim","title":"Controlller RNN"},{"location":"trained-params/#controller-output-co","text":"Name Description Size prior_ar1_logevars autoregressive prior on controller outputs 1 x c_co_dim prior_ar1_logatau autoregressive time constant prior on controller outputs 1 x c_co_dim con_co prior on controller output 1 x c_con_dim con_to_posterior_co_mean_W mapping from controller to mean parameter of co, weights c_con_dim x c_co_dim con_to_posterior_co_mean_b mapping from controller to mean parameter of co, biases 1 x c_co_dim con_to_posterior_co_logvar_W mapping from controller to logvar parameter of co, weights c_con_dim x c_co_dim con_to_posterior_co_logvar_b mapping from controller to logvar parameter of co, biases 1 x c_co_dim","title":"Controller output co"},{"location":"trained-params/#generator-rnn","text":"Name Description Size gen_gengru_x_to_ru_W generator GRU, mapping from input to gates r+u, weights c_co_dim x (2* c_gen_dim ) gen_gengru_h_to_ru_W generator GRU, mapping from input to gates r+u, weights c_gen_dim x (2* c_gen_dim ) gen_gengru_h_to_ru_b generator GRU, mapping from input to gates r+u, biases 1 x (2* c_gen_dim ) gen_gengru_x_to_c_W generator GRU, mapping from input to candidates, weights c_co_dim x c_gen_dim gen_gengru_rh_to_c_W generator GRU, mapping from r+hidden to candidates, weights c_gen_dim x c_gen_dim gen_gengru_rh_to_c_b generator GRU, mapping from r+hidden to candidates, biases 1 x c_gen_dim","title":"Generator RNN"},{"location":"trained-params/#generator-output","text":"Name Description Size gen_to_factors_W mapping from generator to factors, weights c_gen_dim x c_factors_dim factors_to_logrates_W readout alignment weights nDatasets x 1 cell of c_factors_dim x nNeuronsThisDataset factors_to_logrates_b readout alignment biases nDatasets x 1 cell of 1 x nNeuronsThisDataset","title":"Generator output"},{"location":"trained-params/#loading-model_params-for-lorenz-example","text":"We can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with c_co_dim == 0 . >> mtp = rc . findRuns ( 'all' , 1 ). loadModelTrainedParams () ans = ModelTrainedParams with properties : Read - in from spikes to input factors x_to_infac_W : { 3 x1 cell } x_to_infac_b : { 3 x1 cell } Initial condition encoder ( forward ) ic_enc_fwd_t0 : [ 64 x1 single ] ic_enc_fwd_gru_xh_to_gates_ru_W : [ 128 x72 single ] ic_enc_fwd_gru_xh_to_gates_ru_b : [ 128 x1 single ] ic_enc_fwd_gru_xrh_to_c_W : [ 64 x72 single ] ic_enc_fwd_gru_xrh_to_c_b : [ 64 x1 single ] Initial condition encoder ( reverse ) ic_enc_rev_t0 : [ 64 x1 single ] ic_enc_rev_gru_xh_to_gates_ru_W : [ 128 x72 single ] ic_enc_rev_gru_xh_to_gates_ru_b : [ 128 x1 single ] ic_enc_rev_gru_xrh_to_c_W : [ 64 x72 single ] ic_enc_rev_gru_xrh_to_c_b : [ 64 x1 single ] Initial condition g0 prior_g0_mean : [ 64 x1 single ] prior_g0_logvar : [ 64 x1 single ] ic_enc_to_posterior_g0_mean_W : [ 64 x128 single ] ic_enc_to_posterior_g0_mean_b : [ 64 x1 single ] ic_enc_to_posterior_g0_logvar_W : [ 64 x128 single ] ic_enc_to_posterior_g0_logvar_b : [ 64 x1 single ] g0_to_gen_ic_W : [] g0_to_gen_ic_b : [] Controller encoder ( forward ) ci_enc_fwd_t0 : [] ci_enc_fwd_gru_xh_to_ru_W : [] ci_enc_fwd_gru_xh_to_ru_b : [] ci_enc_fwd_gru_xrh_to_c_W : [] ci_enc_fwd_gru_xrh_to_c_b : [] Controller encoder ( reverse ) ci_enc_rev_t0 : [] ci_enc_rev_gru_xh_to_ru_W : [] ci_enc_rev_gru_xh_to_ru_b : [] ci_enc_rev_gru_xrh_to_c_W : [] ci_enc_rev_gru_xrh_to_c_b : [] Controlller RNN con_gengru_x_to_ru_W : [] con_gengru_h_to_ru_W : [] con_gengru_h_to_ru_b : [] con_gengru_x_to_c_W : [] con_gengru_rh_to_c_W : [] con_gengru_rh_to_c_b : [] Controller output co prior_ar1_logevars : [] prior_ar1_logatau : [] con_co : [] con_to_posterior_co_mean_W : [] con_to_posterior_co_mean_b : [] con_to_posterior_co_logvar_W : [] con_to_posterior_co_logvar_b : [] Generator RNN gen_gengru_x_to_ru_W : [] gen_gengru_h_to_ru_W : [ 128 x64 single ] gen_gengru_h_to_ru_b : [ 128 x1 single ] gen_gengru_x_to_c_W : [] gen_gengru_rh_to_c_W : [ 64 x64 single ] gen_gengru_rh_to_c_b : [ 64 x1 single ] Generator output gen_to_factors_W : [ 8 x64 single ] factors_to_logrates_W : { 3 x1 cell } factors_to_logrates_b : { 3 x1 cell } The recurrent connectivity weight matrix of the c_gen_dim==64 GRU generator RNN is given by mtp.gen_gengru_rh_to_c_W : And the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by mtp.factors_to_logrates_W :","title":"Loading model_params for Lorenz example"}]}