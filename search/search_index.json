{
    "docs": [
        {
            "location": "/",
            "text": "LFADS Run Manager for Matlab Documentation\n\u00b6\n\n\nLFADS Run Manager is a set of tools, written in Matlab with some accompanying Python code, that help organize, train, and analyze LFADS models using the \nPython+Tensorflow LFADS code\n. LFADS, or \nLatent Factor Analysis via Dynamical Systems\n, is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018de-noised\u2019 single-trial firing rates from neural spiking data.\n\n\nLFADS Run Manager was authored by \nDaniel O\u2019Shea\n with contributions from \nChethan Pandarinath\n, \nDavid Sussillo\n, and Reza Keshtkaran.\n\n\nRead the \nLFADS pre-print\n for more details.\n\n\nLFADS Run Manager helps you to:\n\n\n\n\nOrganize your spiking neural datasets that will be used to train LFADS models.\n\n\nSetup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating \nstitched\n multisession LFADS models.\n\n\nGenerate shell scripts that will launch individual LFADS training runs \nor\n generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs.\n\n\nLoad the posterior means and parameters of individual LFADS models after each has finished training.\n\n\nFacilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc.\n\n\n\n\nThe code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on \nGithub\n.\n\n\nTo use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. The goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk.\n\n\nQuick example\n\u00b6\n\n\nWe\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs.\n\n\n% Identify the datasets you'll be using\n\n\n% Here we'll add one at ~/lorenz_example/datasets/dataset001.mat\n\n\ndc\n \n=\n \nLorenzExperiment\n.\nDatasetCollection\n(\n'~/lorenz_example/datasets'\n);\n\n\ndc\n.\nname\n \n=\n \n'lorenz_example'\n;\n\n\nds\n \n=\n \nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n \n% adds this dataset to the collection\n\n\ndc\n.\nloadInfo\n;\n \n% loads dataset metadata\n\n\n\n% Run a single model for each dataset, and one stitched run with all datasets\n\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nLorenzExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'example'\n,\n \ndc\n);\n\n\n\n% run files will live at ~/lorenz_example/runs/example/\n\n\n\n% Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8\n\n\npar\n \n=\n \nLorenzExperiment\n.\nRunParams\n;\n\n\npar\n.\nspikeBinMs\n \n=\n \n2\n;\n \n% rebin the data at 2 ms\n\n\npar\n.\nc_co_dim\n \n=\n \n0\n;\n \n% no controller outputs --> no inputs to generator\n\n\npar\n.\nc_batch_size\n \n=\n \n150\n;\n \n% must be < 1/5 of the min trial count\n\n\npar\n.\nc_gen_dim\n \n=\n \n64\n;\n \n% number of units in generator RNN\n\n\npar\n.\nc_ic_enc_dim\n \n=\n \n64\n;\n \n% number of units in encoder RNN\n\n\npar\n.\nc_learning_rate_stop\n \n=\n \n1e-3\n;\n \n% we can stop really early for the demo\n\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_factors_dim'\n,\n \n[\n2\n \n4\n \n6\n \n8\n]);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n% Setup which datasets are included in each run, here just the one\n\n\nrunName\n \n=\n \ndc\n.\ndatasets\n(\n1\n).\ngetSingleRunName\n();\n \n% == 'single_dataset001'\n\n\nrc\n.\naddRunSpec\n(\nLorenzExperiment\n.\nRunSpec\n(\nrunName\n,\n \ndc\n,\n \n1\n));\n\n\n\n% Generate files needed for LFADS input on disk\n\n\nrc\n.\nprepareForLFADS\n();\n\n\n\n% Write a python script that will train all of the LFADS runs using a\n\n\n% load-balancer against the available CPUs and GPUs\n\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'display'\n,\n \n0\n,\n \n'virtualenv'\n,\n \n'tensorflow'\n);\n\n\n\n\n\nYou\u2019ve now setup a 1x 4 grid of LFADS runs, spanning 4 different hyperparameter settings all on the same individual dataset\n\n\n>>\n \nrc\n\n\n\nLorenzExperiment\n.\nRunCollection\n \"\nexampleRun\n\" \n(\n16\n \nruns\n \ntotal\n)\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n1\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleRun\n\n\n  \n4\n \nparameter\n \nsettings\n\n    \n[\n1\n \nparam_7I6XSW\n \ndata_cgrfui\n]\n \nLorenzExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n2\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n    \n[\n2\n \nparam_O4V73g\n \ndata_2_zdvC\n]\n \nLorenzExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n4\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n    \n[\n3\n \nparam_ngqEhM\n \ndata_GeiefE\n]\n \nLorenzExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n6\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n    \n[\n4\n \nparam_Qr2PeG\n \ndata_RE1kuL\n]\n \nLorenzExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n  \n1\n \nrun\n \nspecifications\n\n  \n[\n \n1\n]\n \nLorenzExperiment\n.\nRunSpec\n \"\nsingle_dataset001\n\" \n(\n1\n \ndatasets\n)\n\n\n                          \nname\n:\n \n'exampleRun'\n\n                       \ncomment\n:\n \n''\n\n                      \nrootPath\n:\n \n'~/lorenz_example/runs'\n\n                       \nversion\n:\n \n20171107\n\n             \ndatasetCollection\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nDatasetCollection\n]\n\n                          \nruns\n:\n \n[\n1\nx4\n \nLorenzExperiment\n.\nRun\n]\n\n                        \nparams\n:\n \n[\n4\nx1\n \nLorenzExperiment\n.\nRunParams\n]\n\n                      \nrunSpecs\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRunSpec\n]\n\n                       \nnParams\n:\n \n4\n\n                     \nnRunSpecs\n:\n \n1\n\n                    \nnRunsTotal\n:\n \n4\n\n                     \nnDatasets\n:\n \n1\n\n                  \ndatasetNames\n:\n \n{\n1\nx1\n \ncell\n}\n\n                          \npath\n:\n \n'~/lorenz_example/runs/exampleRun'\n\n      \npathsCommonDataForParams\n:\n \n{\n4\nx1\n \ncell\n}\n\n                \npathsForParams\n:\n \n{\n4\nx1\n \ncell\n}\n\n    \nfileShellScriptTensorboard\n:\n \n'~/lorenz_example/runs/exampleRun/launch_tensorboard.sh'\n\n               \nfileSummaryText\n:\n \n'~/lorenz_example/runs/exampleRun/summary.txt'\n\n       \nfileShellScriptRunQueue\n:\n \n'~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'\n\n\n\n\n\nThen you can simply run \npython run_lfadsqueue.py\n, a script which was automatically generated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026\n\n\nAs they finish, you can load and visualize the results easily in Matlab. Here we plot the inferred, single-trial firing rates of the first neuron:\n\n\nrun\n \n=\n \nrc\n.\nruns\n(\n'single_dataset001'\n,\n \n1\n);\n\n\npm\n \n=\n \nrun\n.\nloadPosteriorMeans\n();\n\n\nrates1\n \n=\n \nsqueeze\n(\npm\n.\nrates\n(\n1\n,\n \n:,\n \n:));\n \n% time x trials\n\n\n...\n\n\n\n\n\nThe single-trial smoothed rates, colored by condition then look like:",
            "title": "Overview"
        },
        {
            "location": "/#lfads-run-manager-for-matlab-documentation",
            "text": "LFADS Run Manager is a set of tools, written in Matlab with some accompanying Python code, that help organize, train, and analyze LFADS models using the  Python+Tensorflow LFADS code . LFADS, or  Latent Factor Analysis via Dynamical Systems , is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018de-noised\u2019 single-trial firing rates from neural spiking data.  LFADS Run Manager was authored by  Daniel O\u2019Shea  with contributions from  Chethan Pandarinath ,  David Sussillo , and Reza Keshtkaran.  Read the  LFADS pre-print  for more details.  LFADS Run Manager helps you to:   Organize your spiking neural datasets that will be used to train LFADS models.  Setup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating  stitched  multisession LFADS models.  Generate shell scripts that will launch individual LFADS training runs  or  generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs.  Load the posterior means and parameters of individual LFADS models after each has finished training.  Facilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc.   The code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on  Github .  To use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. The goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk.",
            "title": "LFADS Run Manager for Matlab Documentation"
        },
        {
            "location": "/#quick-example",
            "text": "We\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs.  % Identify the datasets you'll be using  % Here we'll add one at ~/lorenz_example/datasets/dataset001.mat  dc   =   LorenzExperiment . DatasetCollection ( '~/lorenz_example/datasets' );  dc . name   =   'lorenz_example' ;  ds   =   LorenzExperiment . Dataset ( dc ,   'dataset001.mat' );   % adds this dataset to the collection  dc . loadInfo ;   % loads dataset metadata  % Run a single model for each dataset, and one stitched run with all datasets  runRoot   =   '~/lorenz_example/runs' ;  rc   =   LorenzExperiment . RunCollection ( runRoot ,   'example' ,   dc );  % run files will live at ~/lorenz_example/runs/example/  % Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8  par   =   LorenzExperiment . RunParams ;  par . spikeBinMs   =   2 ;   % rebin the data at 2 ms  par . c_co_dim   =   0 ;   % no controller outputs --> no inputs to generator  par . c_batch_size   =   150 ;   % must be < 1/5 of the min trial count  par . c_gen_dim   =   64 ;   % number of units in generator RNN  par . c_ic_enc_dim   =   64 ;   % number of units in encoder RNN  par . c_learning_rate_stop   =   1e-3 ;   % we can stop really early for the demo  parSet   =   par . generateSweep ( 'c_factors_dim' ,   [ 2   4   6   8 ]);  rc . addParams ( parSet );  % Setup which datasets are included in each run, here just the one  runName   =   dc . datasets ( 1 ). getSingleRunName ();   % == 'single_dataset001'  rc . addRunSpec ( LorenzExperiment . RunSpec ( runName ,   dc ,   1 ));  % Generate files needed for LFADS input on disk  rc . prepareForLFADS ();  % Write a python script that will train all of the LFADS runs using a  % load-balancer against the available CPUs and GPUs  rc . writeShellScriptRunQueue ( 'display' ,   0 ,   'virtualenv' ,   'tensorflow' );   You\u2019ve now setup a 1x 4 grid of LFADS runs, spanning 4 different hyperparameter settings all on the same individual dataset  >>   rc  LorenzExperiment . RunCollection  \" exampleRun \"  ( 16   runs   total ) \n   Dataset   Collection  \" lorenz_example \"  ( 1   datasets )   in   ~/ lorenz_example / datasets \n   Path :   ~/ lorenz_example / runs / exampleRun \n\n   4   parameter   settings \n     [ 1   param_7I6XSW   data_cgrfui ]   LorenzExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 2   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n     [ 2   param_O4V73g   data_2_zdvC ]   LorenzExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 4   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n     [ 3   param_ngqEhM   data_GeiefE ]   LorenzExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 6   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n     [ 4   param_Qr2PeG   data_RE1kuL ]   LorenzExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n   1   run   specifications \n   [   1 ]   LorenzExperiment . RunSpec  \" single_dataset001 \"  ( 1   datasets ) \n\n                           name :   'exampleRun' \n                        comment :   '' \n                       rootPath :   '~/lorenz_example/runs' \n                        version :   20171107 \n              datasetCollection :   [ 1 x1   LorenzExperiment . DatasetCollection ] \n                           runs :   [ 1 x4   LorenzExperiment . Run ] \n                         params :   [ 4 x1   LorenzExperiment . RunParams ] \n                       runSpecs :   [ 1 x1   LorenzExperiment . RunSpec ] \n                        nParams :   4 \n                      nRunSpecs :   1 \n                     nRunsTotal :   4 \n                      nDatasets :   1 \n                   datasetNames :   { 1 x1   cell } \n                           path :   '~/lorenz_example/runs/exampleRun' \n       pathsCommonDataForParams :   { 4 x1   cell } \n                 pathsForParams :   { 4 x1   cell } \n     fileShellScriptTensorboard :   '~/lorenz_example/runs/exampleRun/launch_tensorboard.sh' \n                fileSummaryText :   '~/lorenz_example/runs/exampleRun/summary.txt' \n        fileShellScriptRunQueue :   '~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'   Then you can simply run  python run_lfadsqueue.py , a script which was automatically generated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026  As they finish, you can load and visualize the results easily in Matlab. Here we plot the inferred, single-trial firing rates of the first neuron:  run   =   rc . runs ( 'single_dataset001' ,   1 );  pm   =   run . loadPosteriorMeans ();  rates1   =   squeeze ( pm . rates ( 1 ,   :,   :));   % time x trials  ...   The single-trial smoothed rates, colored by condition then look like:",
            "title": "Quick example"
        },
        {
            "location": "/install/",
            "text": "Installation\n\u00b6\n\n\nThese instructions will walk you through the basic setup process to get you up and running with LFADS.\n\n\n\n\nUse Python 2.7\n\n\nWhile TensorFlow fully supports Python 3, the LFADS code itself does not yet. We expect to fix the few incompatibilities soon, but for now, use Python 2.7. If you\u2019re using \nAnaconda\n, you can create a \nconda\n environment like this:\n\n\nconda create --name tensorflow \npython\n=\n2\n.7\n\n\n\n\n\n\nInstall TensorFlow\n\u00b6\n\n\nYou\u2019ll need to install TensorFlow to run LFADS. Follow the \ndocumentation for installing Tensorflow\n and be sure to install the version for GPUs if you wish to take advantage of the LFADS run queue. You may wish to install everything in a Python \nvirtualenv\n or inside a \nconda\n environment, both of which are supported by \nlfads-run-manager\n. Be sure to test that you can \nimport\n \ntensorflow\n in Python correctly:\n\n\n# Python\n\n\nimport\n \ntensorflow\n \nas\n \ntf\n\n\nhello\n \n=\n \ntf\n.\nconstant\n(\n'Hello, TensorFlow!'\n)\n\n\nsess\n \n=\n \ntf\n.\nSession\n()\n\n\nprint\n(\nsess\n.\nrun\n(\nhello\n))\n\n\n\n\n\nWhich should output:\n\nHello, TensorFlow!\n\n\n\nInstall LFADS\n\u00b6\n\n\nYou\u2019ll then need to clone the \nTensorflow models repo containing LFADS\n somewhere convenient on your system.\n\n\ngit clone https://github.com/lfads/models.git\n\n\n\n\nThen add this LFADS folder both to your \nPYTHONPATH\n and system \nPATH\n. Add the following to your \n.bashrc\n:\n\nexport\n \nPYTHONPATH\n=\n$PYTHONPATH\n:/path/to/models/research/lfads/\n\nexport\n \nPATH\n=\n$PATH\n:/path/to/models/research/lfads/\n\n\n\nEnsure that typing \nwhich run_lfads.py\n at your terminal prompt shows the path to \nrun_lfads.py\n.\n\n\nLFADS depends on the Python libraries \nh5py\n and \nmatplotlib\n being installed as well:\n\n\npip install h5py matplotlib\n\n\n\n\nInstall tmux\n\u00b6\n\n\nLFADS Run Manager uses tmux to run LFADS within to enable queuing many runs across the available GPUs and to facilitate online monitoring. Fortunately, installing tmux is pretty straightforward on most distributions.\n\n\n\n\nUbuntu: \nsudo apt-get install tmux\n\n\nMac: \nbrew install tmux\n using \nHomebrew\n.\n\n\n\n\nThere are many nice guides to using \ntmux\n:\n\n\n\n\nA Quick and Easy Guide to tmux - Ham Vocke\n\n\nA tmux Crash Course - Josh Clayton\n\n\n\n\nInstall LFADS Run Manager\n\u00b6\n\n\nFinally, clone the lfads-run-manager repository somewhere convenient on your system.\n\n\ngit clone https://github.com/djoshea/lfads-run-manager.git\n\n\n\n\nYou\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using \npathtool\n or by running:\n\n\naddpath\n(\n'/path/to/lfads-run-manager/src'\n)\n\n\n\n\n\nNo need to add the subfolders to the path recursively.",
            "title": "Installation"
        },
        {
            "location": "/install/#installation",
            "text": "These instructions will walk you through the basic setup process to get you up and running with LFADS.   Use Python 2.7  While TensorFlow fully supports Python 3, the LFADS code itself does not yet. We expect to fix the few incompatibilities soon, but for now, use Python 2.7. If you\u2019re using  Anaconda , you can create a  conda  environment like this:  conda create --name tensorflow  python = 2 .7",
            "title": "Installation"
        },
        {
            "location": "/install/#install-tensorflow",
            "text": "You\u2019ll need to install TensorFlow to run LFADS. Follow the  documentation for installing Tensorflow  and be sure to install the version for GPUs if you wish to take advantage of the LFADS run queue. You may wish to install everything in a Python  virtualenv  or inside a  conda  environment, both of which are supported by  lfads-run-manager . Be sure to test that you can  import   tensorflow  in Python correctly:  # Python  import   tensorflow   as   tf  hello   =   tf . constant ( 'Hello, TensorFlow!' )  sess   =   tf . Session ()  print ( sess . run ( hello ))   Which should output: Hello, TensorFlow!",
            "title": "Install TensorFlow"
        },
        {
            "location": "/install/#install-lfads",
            "text": "You\u2019ll then need to clone the  Tensorflow models repo containing LFADS  somewhere convenient on your system.  git clone https://github.com/lfads/models.git  Then add this LFADS folder both to your  PYTHONPATH  and system  PATH . Add the following to your  .bashrc : export   PYTHONPATH = $PYTHONPATH :/path/to/models/research/lfads/ export   PATH = $PATH :/path/to/models/research/lfads/  Ensure that typing  which run_lfads.py  at your terminal prompt shows the path to  run_lfads.py .  LFADS depends on the Python libraries  h5py  and  matplotlib  being installed as well:  pip install h5py matplotlib",
            "title": "Install LFADS"
        },
        {
            "location": "/install/#install-tmux",
            "text": "LFADS Run Manager uses tmux to run LFADS within to enable queuing many runs across the available GPUs and to facilitate online monitoring. Fortunately, installing tmux is pretty straightforward on most distributions.   Ubuntu:  sudo apt-get install tmux  Mac:  brew install tmux  using  Homebrew .   There are many nice guides to using  tmux :   A Quick and Easy Guide to tmux - Ham Vocke  A tmux Crash Course - Josh Clayton",
            "title": "Install tmux"
        },
        {
            "location": "/install/#install-lfads-run-manager",
            "text": "Finally, clone the lfads-run-manager repository somewhere convenient on your system.  git clone https://github.com/djoshea/lfads-run-manager.git  You\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using  pathtool  or by running:  addpath ( '/path/to/lfads-run-manager/src' )   No need to add the subfolders to the path recursively.",
            "title": "Install LFADS Run Manager"
        },
        {
            "location": "/matlab/",
            "text": "Matlab language features used\n\u00b6\n\n\nThe run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. The run manager code also makes use of packages, which helps you organize your code so that names don\u2019t collide in the Matlab path. If you are familiar with these aspects of Matlab programming, skip ahead to \nKey Concepts\n.\n\n\nMatlab Classes\n\u00b6\n\n\nWhile there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks:\n\n\n\n\nRole of Classes in Matlab\n\n\nClass Syntax Guide\n\n\n\n\nIn writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though \nit is not necessary to deeply understand classes in Matlab in order to get up and running\n.\n\n\nIf you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a \nstruct\n type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term \nclass\n refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an \ninstance\n, and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class.\n\n\ny\n \n=\n \n3.0\n;\n\n\nmyInstance\n \n=\n \nMyClass\n();\n\n\n\n\n\nIn this code, \ny\n is a normal Matlab variable whose type is \ndouble\n (double-precision floating point). \nmyInstance\n is an instance whose type is the class \nMyClass\n.\n\n\nFor illustration of a complete class definition, consider a class \nMultiplier\n whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file \nMulitplier.m\n as follows:\n\n\nclassdef\n \nMultiplier\n \n<\n \nhandle\n\n    \nproperties\n\n        \ngain\n \n=\n \n1\n;\n \n% constant by which inputs are multiplied\n\n    \nend\n\n\n    \nmethods\n\n        \n% this method is called a constructor, and will be called when creating\n\n        \n% new instances of this class. Here we provide a way to specify the gain\n\n        \n% when creating the instance\n\n\n        function\n \nobj \n=\n \nMultiplier\n(\ntheGain\n)\n\n\n            \nif\n \nnargin\n \n>\n \n1\n\n                \nobj\n.\ngain\n \n=\n \ntheGain\n;\n\n            \nend\n\n        \nend\n\n\n        \n% this method does the actual multiplication. The first argument always refers\n\n        \n% to the instance variable itself, enabling you to refer to properties and other\n\n        \n% methods in that instance. Otherwise, the code acts like a normal Matlab function\n\n\n        function\n \nout \n=\n \nmutliply\n(\nobj, in\n)\n\n\n            \nout\n \n=\n \nin\n \n*\n \nobj\n.\ngain\n;\n\n        \nend\n\n    \nend\n\n\nend\n\n\n\n\n\nWith this definition complete, we can then use the class at the command line as follows:\n\n\n>>\n \nmyMult\n \n=\n \nMultiplier\n(\n5\n);\n\n\n>>\n \nmyMult\n.\nmultiply\n(\n10\n)\n\n\n50\n\n\n>>\n \nmyOtherMult\n \n=\n \nMultiplier\n(\n2\n);\n\n\n>>\n \nmyOtherMult\n.\nmultiply\n(\n10\n)\n\n\n20\n\n\n>>\n \nmyMult\n.\ngain\n \n=\n \n3\n;\n \n% only affects myMult, not myOtherMult\n\n\n>>\n \nmyMult\n.\nmultiply\n(\n10\n)\n\n\n30\n\n\n>>\n \nmyOtherMult\n.\nmultiply\n(\n10\n)\n\n\n20\n\n\n\n\n\nHere, note that \nmyMult\n is a Matlab variable which holds an instance of the class \nMutliplier\n. We then assign a value to the property \ngain\n of this instance, and then call the method \nmultiply\n.\n\n\nMatlab Packages\n\u00b6\n\n\nThe run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a \n+\n. Within Matlab, you will then refer to these classes by prefixing the class names with the package name. So within Matlab, \nLFADS.Run\n refers to the class located on the file system at \n+LFADS/Run.m\n.\n\n\nThe main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called \n+ReachingTask\n, and within it copy the starter code provided from \n+LorenzExperiment\n. Then you can refer to \nReachingTask.Dataset\n and \nReachingTask.Run\n from within Matlab.",
            "title": "Matlab Classes and Packages"
        },
        {
            "location": "/matlab/#matlab-language-features-used",
            "text": "The run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. The run manager code also makes use of packages, which helps you organize your code so that names don\u2019t collide in the Matlab path. If you are familiar with these aspects of Matlab programming, skip ahead to  Key Concepts .",
            "title": "Matlab language features used"
        },
        {
            "location": "/matlab/#matlab-classes",
            "text": "While there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks:   Role of Classes in Matlab  Class Syntax Guide   In writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though  it is not necessary to deeply understand classes in Matlab in order to get up and running .  If you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a  struct  type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term  class  refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an  instance , and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class.  y   =   3.0 ;  myInstance   =   MyClass ();   In this code,  y  is a normal Matlab variable whose type is  double  (double-precision floating point).  myInstance  is an instance whose type is the class  MyClass .  For illustration of a complete class definition, consider a class  Multiplier  whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file  Mulitplier.m  as follows:  classdef   Multiplier   <   handle \n     properties \n         gain   =   1 ;   % constant by which inputs are multiplied \n     end \n\n     methods \n         % this method is called a constructor, and will be called when creating \n         % new instances of this class. Here we provide a way to specify the gain \n         % when creating the instance          function   obj  =   Multiplier ( theGain )               if   nargin   >   1 \n                 obj . gain   =   theGain ; \n             end \n         end \n\n         % this method does the actual multiplication. The first argument always refers \n         % to the instance variable itself, enabling you to refer to properties and other \n         % methods in that instance. Otherwise, the code acts like a normal Matlab function          function   out  =   mutliply ( obj, in )               out   =   in   *   obj . gain ; \n         end \n     end  end   With this definition complete, we can then use the class at the command line as follows:  >>   myMult   =   Multiplier ( 5 );  >>   myMult . multiply ( 10 )  50  >>   myOtherMult   =   Multiplier ( 2 );  >>   myOtherMult . multiply ( 10 )  20  >>   myMult . gain   =   3 ;   % only affects myMult, not myOtherMult  >>   myMult . multiply ( 10 )  30  >>   myOtherMult . multiply ( 10 )  20   Here, note that  myMult  is a Matlab variable which holds an instance of the class  Mutliplier . We then assign a value to the property  gain  of this instance, and then call the method  multiply .",
            "title": "Matlab Classes"
        },
        {
            "location": "/matlab/#matlab-packages",
            "text": "The run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a  + . Within Matlab, you will then refer to these classes by prefixing the class names with the package name. So within Matlab,  LFADS.Run  refers to the class located on the file system at  +LFADS/Run.m .  The main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called  +ReachingTask , and within it copy the starter code provided from  +LorenzExperiment . Then you can refer to  ReachingTask.Dataset  and  ReachingTask.Run  from within Matlab.",
            "title": "Matlab Packages"
        },
        {
            "location": "/concepts/",
            "text": "Key Concepts\n\u00b6\n\n\nThe run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab.\n\n\nLFADS.Dataset\n\u00b6\n\n\nA \nDataset\n instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session.\n\n\nLFADS.DatasetCollection\n\u00b6\n\n\nA \nDatasetCollection\n is a set or array of one or more datasets.\n\n\nLFADS.RunSpec\n\u00b6\n\n\nA \nRunSpec\n, short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a \nstitched\n model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models.\n\n\nLFADS.RunParams\n\u00b6\n\n\nA \nRunParams\n encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates.\n\n\nWhen adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a \ntimeWindowPre\n and \ntimeWindowPost\n that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g. \nkeepSuccessTrialsOnly\n or \nincludePerturbationTrials\n.\n\n\nThe advantage of including your dataset-specific hyperparameters in your \nRunParams\n subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters.\n\n\nLFADS.Run\n\u00b6\n\n\nA \nRun\n encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An \nRun\n is defined by the combination of an \nRunSpec\n instance (which specifies the datasets included) and an \nRunParams\n instance (which specifies the hyperparameters). Each \nRun\n will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model.\n\n\nLFADS.RunCollection\n\u00b6\n\n\nA \nRunCollection\n is a set of one or more \nLFADS.Run\ns. This collection is organized as a two-dimensional matrix of runs.\n\n\nThe first dimension of this matrix is specified by an array of \nLFADS.RunSpec\n instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10 \nLFADS.RunSpec\ns, each specifying an individual dataset to be included.\n\n\nThe second dimension of this matrix is specified by an array of \nLFADS.RunParams\n instances. This enables you to vary hyperparameter settings across the runs.\n\n\nEach cell of this matrix, defined by a particular \nRunSpec\n and \nRunParams\n combination defines a specific \nRun\n which can then be generated and trained using Tensorflow.",
            "title": "Key Concepts"
        },
        {
            "location": "/concepts/#key-concepts",
            "text": "The run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab.",
            "title": "Key Concepts"
        },
        {
            "location": "/concepts/#lfadsdataset",
            "text": "A  Dataset  instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session.",
            "title": "LFADS.Dataset"
        },
        {
            "location": "/concepts/#lfadsdatasetcollection",
            "text": "A  DatasetCollection  is a set or array of one or more datasets.",
            "title": "LFADS.DatasetCollection"
        },
        {
            "location": "/concepts/#lfadsrunspec",
            "text": "A  RunSpec , short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a  stitched  model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models.",
            "title": "LFADS.RunSpec"
        },
        {
            "location": "/concepts/#lfadsrunparams",
            "text": "A  RunParams  encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates.  When adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a  timeWindowPre  and  timeWindowPost  that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g.  keepSuccessTrialsOnly  or  includePerturbationTrials .  The advantage of including your dataset-specific hyperparameters in your  RunParams  subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters.",
            "title": "LFADS.RunParams"
        },
        {
            "location": "/concepts/#lfadsrun",
            "text": "A  Run  encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An  Run  is defined by the combination of an  RunSpec  instance (which specifies the datasets included) and an  RunParams  instance (which specifies the hyperparameters). Each  Run  will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model.",
            "title": "LFADS.Run"
        },
        {
            "location": "/concepts/#lfadsruncollection",
            "text": "A  RunCollection  is a set of one or more  LFADS.Run s. This collection is organized as a two-dimensional matrix of runs.  The first dimension of this matrix is specified by an array of  LFADS.RunSpec  instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10  LFADS.RunSpec s, each specifying an individual dataset to be included.  The second dimension of this matrix is specified by an array of  LFADS.RunParams  instances. This enables you to vary hyperparameter settings across the runs.  Each cell of this matrix, defined by a particular  RunSpec  and  RunParams  combination defines a specific  Run  which can then be generated and trained using Tensorflow.",
            "title": "LFADS.RunCollection"
        },
        {
            "location": "/interfacing/",
            "text": "Using LFADS Run Manager with your datasets\n\u00b6\n\n\nCopying the \nLorenzExperiment\n working example code\n\u00b6\n\n\nBelow we describe how to use the run manager code with datasets from your specific experiment. The recommended way to begin this process is to copy the folder \n+LorenzExperiment\n inside the\nlfads-run-manager\n repository to some other folder on your Matlab path, and then to rename it to something related to the experiment, keeping the \n+\n in the folder name to keep it in a \nMatlab package\n. Below, we\u2019ll stick with the name \nLorenzExperiment\n.\n\n\nEach of the classes you have just created are defined to inherit from the corresponding \nLFADS.ClassName\n inside the \nlfads-run-manager\n repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the \n+LFADS\n folder in the repo.\n\n\nEditing the core classes\n\u00b6\n\n\nHere we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are:\n\n\n\n\nloadData\n in \nDataset.m\n - specify how to load a dataset from disk. The default implementation assumes that the data live in a \n.mat\n file that can be loaded using \nload\n.\n\n\ngenerateCountsForDataset\n in \nRun.m\n  - preprocess data and perform spike binning\n\n\n\n\nEditing \nDatasetCollection.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+LorenzExperiment/DatasetCollection.m\n. Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor:\n\n\nfunction\n \nds \n=\n \nDatasetCollection\n(\npath\n)\n\n\n    \nds\n \n=\n \nds\n@\nLFADS\n.\nDatasetCollection\n(\npath\n);\n\n\nend\n\n\n\n\n\nYou may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run:\n\n\ndc\n \n=\n \nLorenzExperiment\n.\nDatasetCollection\n(\n'/path/to/experimentData'\n);\n\n\n\n\n\nThis path will then be used as the parent folder by all of the datasets that are added to this collection.\n\n\nBelow is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function \nfilterDatasets\n to specify the indices or mask over datasets to keep.\n\n\nfunction\n \nfilterHavingMinimumTrials\n(\ndc, minTrials\n)\n\n\n    \n% example of a function that will filter down datasets based on\n\n    \n% their metadata.\n\n    \nnTrials\n \n=\n \ncat\n(\n1\n,\n \ndc\n.\ndatasets\n.\nnTrials\n);\n\n\n    \n% filterDatasets is provided by DatasetCollection\n\n    \ndc\n.\nfilterDatasets\n(\nnTrials\n \n>\n=\n \nminTrials\n);\n\n\nend\n\n\n\n\n\nNo edits are necessary to \nDatasetCollection.m\n to get up and running\n, but feel free to add any additional methods or properties as needed for your application.\n\n\n\n\nAuto-detecting datasets\n\n\nYou might consider adding a method to your \nDatasetCollection\n class which can automatically detect all of the datasets in a specific folder. An example, which would add every \n.mat\n file detected in the folder might look like this:\n\n\nfunction\n \nautoDetectDatasets\n(\ndc\n)\n\n\n    \ndc\n.\nclearDatasets\n();\n \n% in case there are existing datasets already added\n\n\n    \n% automatically find all .mat files within dc.path and build datasets for each\n\n    \nfiles\n \n=\n \ndir\n(\ndc\n.\npath\n);\n\n    \nfor\n \niF\n \n=\n \n1\n:\nnumel\n(\nfiles\n)\n\n        \nif\n \nstrncmp\n(\nfiles\n(\niF\n).\nname\n,\n \n'.'\n,\n \n1\n),\n \ncontinue\n,\n \nend\n\n        \ninfo\n \n=\n \nfiles\n(\niF\n);\n\n        \n[\n~\n,\n \n~\n,\n \next\n]\n \n=\n \nfileparts\n(\ninfo\n.\nname\n);\n\n        \nif\n \n~\nstrcmp\n(\next\n,\n \n'.mat'\n),\n \ncontinue\n;\n \nend\n\n\n        \n% get YourPackage.Dataset constructor\n\n        \ndatasetFn\n \n=\n \nstr2func\n(\nstrrep\n(\nclass\n(\nr\n),\n \n'DatasetCollection'\n,\n \n'Dataset'\n));\n\n        \nds\n \n=\n \ndatasetFn\n(\ndc\n,\n \ninfo\n.\nname\n);\n\n    \nend\n\n\nend\n\n\n\n\n\n\n\nEditing \nDataset.m\n \n(Required)\n\u00b6\n\n\nEdit the file \n+LorenzExperiment/Dataset.m\n. Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset.\n\n\nFirst, look at the constructor.\n\n\nfunction\n \nds \n=\n \nDataset\n(\ncollection, relPath\n)\n\n\n    \nds\n \n=\n \nds\n@\nLFADS\n.\nDataset\n(\ncollection\n,\n \nrelPath\n);\n\n\nend\n\n\n\n\n\nIn order to encapsulate a particular dataset on disk, you will create a new \nLorenzExperiment.Dataset\n instance in Matlab. The first argument \ncollection\n is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument \nrelPath\n specifies the path to this dataset relative to the collection. For example, if the dataset were stored in \n/path/to/experimentalData/dataset001.mat\n, you might run:\n\n\nds1\n \n=\n \nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\n\n\n\nYou may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s \nload\n method and assumes that \nds.path\n points to a \n.mat\n file. \nds.path\n will be equal to the dataset collection path joined to \nrelPath\n. If your data is stored differently, you will need to replace the implementation of \nloadData\n:\n\n\nfunction\n \ndata \n=\n \nloadData\n(\nds\n)\n\n\n    \n% load this dataset's data file from .path\n\n    \nin\n \n=\n \nload\n(\nds\n.\npath\n);\n\n    \ndata\n \n=\n \nin\n.\ndata\n;\n\n\nend\n\n\n\n\n\nYou can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the \nDataset\n class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property \ninfoLoaded\n can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed.\n\n\nfunction\n \nloadInfo\n(\nds\n)\n\n\n    \n% Load this Dataset's metadata if not already loaded\n\n\n    \nif\n \nds\n.\ninfoLoaded\n,\n \nreturn\n;\n \nend\n\n\n    \n% modify this to extract the metadata loaded from the data file\n\n    \ndata\n \n=\n \nds\n.\nloadData\n();\n\n    \nds\n.\nsubject\n \n=\n \ndata\n.\nsubject\n;\n\n    \nds\n.\nsaveTags\n \n=\n \ndata\n.\nsaveTags\n;\n\n    \nds\n.\ndatenum\n  \n=\n \ndata\n.\ndatenum\n;\n\n    \nds\n.\nnChannels\n \n=\n \ndata\n.\nnChannels\n;\n\n    \nds\n.\nnTrials\n \n=\n \nnumel\n(\ndata\n.\ntrials\n);\n\n\n    \nds\n.\ninfoLoaded\n \n=\n \ntrue\n;\n\n\nend\n\n\n\n\n\nThe metadata fields you might assign are as follows:\n\n\n\n\nsubject\n - dataset subject or participant name\n\n\ndatenum\n - a Matlab datenum identifying the collection time of the dataset\n\n\nnChannels\n - the number of unique spiking channels recorded in this dataset\n\n\nnTrials\n - the number of trials included in this dataset\n\n\nsaveTags\n - a vector of numbers indicating within-day blocks of trials included\n\n\n\n\n\n\nMetadata are optional\n\n\nWe note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your \nDataset\n class.\n\n\n\n\nEditing \nRunParams.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+LorenzExperiment/RunParams.m\n. Recall that \nRunParams\n encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add.\n\n\nYou can add these additional properties anywhere in the file:\n\nclassdef\n \nRunParams\n \n<\n \nLFADS\n.\nRunParams\n\n   \nproperties\n\n       \n% Add additional custom parameters here. The default you assign to\n\n       \n% them will be used when computing the hash value. Any params whose value\n\n       \n% differs from the default will be included in the hash value, to allow new\n\n       \n% parameters to be added without invalidating old hashes. So choose\n\n       \n% the default once and don't change it. If you decide to use another\n\n       \n% value later by default, override it in the constructor instead.\n\n   \nend\n\n\n\n\n\n\nPick default values carefully\n\n\nThe default values you assign next to each property should be chosen carefully and never changed once added.\n The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the \nRunParams\n constructor without affecting the hash. However, you will then want to manually assign this property to its \nold value\n in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values.\n\n\n\n\n\n\nSpecifying data-hash affecting parameters\n\n\nAs described \nhere\n, the parameter values inside \nRunParams\n will be used to generate two different hashes, a \nparam_\n hash that includes all properties that affect LFADS whose values differ from their defaults, and a \ndata_\n hash that includes the subset of those properties that affect the raw data input to LFADS. This design allows us to reuse data on disk when sweeping parameters that only affect LFADS internal architecture, e.g. the size of the generator RNN.\n\n\nBy default, the \ndata_\n hash includes all properties that do not begin with \nc_\n as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to \nRunParams\n. If you need to adjust this behavior, override the method \ngetListPropertiesNotAffectingInputData\n in your \nRunParams\n instance. You should probably take a union of your custom properties with the properties returned by the superclass method \nLFADS\n.\nRun\n/\ngetListPropertiesNotAffectingInputData\n.\n\n\n\n\nNo changes are required to \nRunParams.m\n to get up and running.\n\n\nEditing \nRunCollection.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+LorenzExperiment/RunCollection.m\n. Recall that a \nRunCollection\n specifies a set of individual LFADS runs defined by an array of \nRunSpec\ns crossed with an array of \nRunParams\n.\n\n\nclassdef\n \nRunCollection\n \n<\n \nLFADS\n.\nRunCollection\n\n    \n% no need to modify anything here, but feel free to add useful methods\n\n    \n% and properties as useful\n\n\n    \nmethods\n\n\n        function\n \nrc \n=\n \nRunCollection\n(\nvarargin\n)\n\n\n            \nrc\n@\nLFADS\n.\nRunCollection\n(\nvarargin\n{:});\n\n        \nend\n\n    \nend\n\n\nend\n\n\n\n\n\nNo changes are required to \nRunCollection.m\n to get up and running\n, but you can add any utility methods to facilitate analysis for your specific application.\n\n\nEditing \nRun.m\n \n(Required)\n\u00b6\n\n\nEdit the file \n+LorenzExperiment/Run.m\n. Recall that a \nRun\n represents a specific LFADS model training run. The main function you will need to provide a definition for is \ngenerateCountsForDataset\n. This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this:\n\n\nfunction\n \nout \n=\n \ngenerateCountsForDataset\n(\nr, dataset, mode, varargin\n)\n\n\n\n\n\nHere, \nr\n refers to the \nLorenzExperiment.Run\n instance. It may be particularly helpful to refer to the \nRunParams\n instance assigned to this run via \nr.params\n, especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included.\n\n\nInputs to \ngenerateCountsForDataset\n:\n\u00b6\n\n\n\n\nr\n:\n\n\nThe \nRun\n instance. The current \nRunParams\n instance can be accessed through \nr.params\n.\n\n\ndataset\n:\n\n\nLorenzExperiment.Dataset\n instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run, \ngenerateCountsForDataset\n will be called once for each dataset, one at a time. You might use \ndataset.loadData()\n to load the actual data, as you defined above.\n\n\nmode\n:\n\n\n\n\nString that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined:\n\n\n\n\nexport\n - indicates that the sequence data will be exported as the actual input to the Python+Tensorflow LFADS run\n\n\nalignment\n - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run.\n\n\n\n\nIf you decide you do wish to handle the \nalignment\n case differently, you will need to override the \nusesDifferentDataForAlignment\n method in your \nRun\n class to return \ntrue\n, by adding:\n\n\nfunction\n \ntf \n=\n \nusesDifferentDataForAlignment\n(\nr\n)\n\n\n    \ntf\n \n=\n \ntrue\n;\n\n\nend\n\n\n\n\n\n\n\nvarargin\n:\n\n\nCurrently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g. \n'paramName'\n,\n \nparamValue\n,\n \n...\n) in the future without breaking existing implementations.\n\n\n\n\nOutputs to \ngenerateCountsForDataset\n:\n\u00b6\n\n\n\n\nout\n:\n\n\n\n\nA scalar struct which holds the following fields:\n\n\n\n\n.\ncounts\n (Required):\n\n\nA tensor of binned spike counts (not rates) with size \nnTrials\n x \nnChannels\n x \nnTime\n. These should be total counts, not normalized rates, as they will be added together during re-binning.\n\n\n.\ntimeVecMs\n (Optional):\n\n\nA vector of timepoints with length \nnTime\n in milliseconds associated with each time bin in \ncounts\n. You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the \nraw\n spike bin width used when the data are later rebinned to match \nr.params.spikeBinMs\n. Default is \n1\n:\nsize\n(\ncounts\n,\n \n3\n)\n.\n\n\n.\nconditionId\n (Optional):\n\n\nVector with length \nnTrials\n identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector. Default is \n[]\n.\n\n\n.\ntruth\n (Optional):\n\n\nFor synthetic datasets, provides the ground-truth counts for each trial. Same size as \n.counts\n. Default is \n[]\n.\n\n\n.\nexternalInputs\n (Optional):\n\n\nSpecifies the observed, external inputs which will be passed either to the generator directly or to the encoder. Default is \n[]\n.\n\n\n\n\n\n\nA note on bin widths\n\n\nThere are two different bin widths in \nlfads-run-manager\n. First is this \nbinWidthMs\n within \nseq\n, which is the spike binning that you will do to the data inside \ngenerateCountsForDataset\n. \nWe recommend binning here at 1 ms or the smallest bin width you might wish to use.\n Second is the field \nspikeBinMs\n inside the \nRunParams\n class. The expectation is that you will bin using a small bin width inside \ngenerateCountsForDataset\n, and then \nthe run manager code will automatically re-bin the data at the larger bin width set by \nr.params.spikeBinMs\n for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.",
            "title": "Interfacing with your Datasets"
        },
        {
            "location": "/interfacing/#using-lfads-run-manager-with-your-datasets",
            "text": "",
            "title": "Using LFADS Run Manager with your datasets"
        },
        {
            "location": "/interfacing/#copying-the-lorenzexperiment-working-example-code",
            "text": "Below we describe how to use the run manager code with datasets from your specific experiment. The recommended way to begin this process is to copy the folder  +LorenzExperiment  inside the lfads-run-manager  repository to some other folder on your Matlab path, and then to rename it to something related to the experiment, keeping the  +  in the folder name to keep it in a  Matlab package . Below, we\u2019ll stick with the name  LorenzExperiment .  Each of the classes you have just created are defined to inherit from the corresponding  LFADS.ClassName  inside the  lfads-run-manager  repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the  +LFADS  folder in the repo.",
            "title": "Copying the LorenzExperiment working example code"
        },
        {
            "location": "/interfacing/#editing-the-core-classes",
            "text": "Here we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are:   loadData  in  Dataset.m  - specify how to load a dataset from disk. The default implementation assumes that the data live in a  .mat  file that can be loaded using  load .  generateCountsForDataset  in  Run.m   - preprocess data and perform spike binning",
            "title": "Editing the core classes"
        },
        {
            "location": "/interfacing/#editing-datasetcollectionm-optional",
            "text": "Edit the file  +LorenzExperiment/DatasetCollection.m . Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor:  function   ds  =   DatasetCollection ( path )       ds   =   ds @ LFADS . DatasetCollection ( path );  end   You may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run:  dc   =   LorenzExperiment . DatasetCollection ( '/path/to/experimentData' );   This path will then be used as the parent folder by all of the datasets that are added to this collection.  Below is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function  filterDatasets  to specify the indices or mask over datasets to keep.  function   filterHavingMinimumTrials ( dc, minTrials )       % example of a function that will filter down datasets based on \n     % their metadata. \n     nTrials   =   cat ( 1 ,   dc . datasets . nTrials ); \n\n     % filterDatasets is provided by DatasetCollection \n     dc . filterDatasets ( nTrials   > =   minTrials );  end   No edits are necessary to  DatasetCollection.m  to get up and running , but feel free to add any additional methods or properties as needed for your application.   Auto-detecting datasets  You might consider adding a method to your  DatasetCollection  class which can automatically detect all of the datasets in a specific folder. An example, which would add every  .mat  file detected in the folder might look like this:  function   autoDetectDatasets ( dc )       dc . clearDatasets ();   % in case there are existing datasets already added \n\n     % automatically find all .mat files within dc.path and build datasets for each \n     files   =   dir ( dc . path ); \n     for   iF   =   1 : numel ( files ) \n         if   strncmp ( files ( iF ). name ,   '.' ,   1 ),   continue ,   end \n         info   =   files ( iF ); \n         [ ~ ,   ~ ,   ext ]   =   fileparts ( info . name ); \n         if   ~ strcmp ( ext ,   '.mat' ),   continue ;   end \n\n         % get YourPackage.Dataset constructor \n         datasetFn   =   str2func ( strrep ( class ( r ),   'DatasetCollection' ,   'Dataset' )); \n         ds   =   datasetFn ( dc ,   info . name ); \n     end  end",
            "title": "Editing DatasetCollection.m (Optional)"
        },
        {
            "location": "/interfacing/#editing-datasetm-required",
            "text": "Edit the file  +LorenzExperiment/Dataset.m . Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset.  First, look at the constructor.  function   ds  =   Dataset ( collection, relPath )       ds   =   ds @ LFADS . Dataset ( collection ,   relPath );  end   In order to encapsulate a particular dataset on disk, you will create a new  LorenzExperiment.Dataset  instance in Matlab. The first argument  collection  is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument  relPath  specifies the path to this dataset relative to the collection. For example, if the dataset were stored in  /path/to/experimentalData/dataset001.mat , you might run:  ds1   =   LorenzExperiment . Dataset ( dc ,   'dataset001.mat' );   You may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s  load  method and assumes that  ds.path  points to a  .mat  file.  ds.path  will be equal to the dataset collection path joined to  relPath . If your data is stored differently, you will need to replace the implementation of  loadData :  function   data  =   loadData ( ds )       % load this dataset's data file from .path \n     in   =   load ( ds . path ); \n     data   =   in . data ;  end   You can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the  Dataset  class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property  infoLoaded  can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed.  function   loadInfo ( ds )       % Load this Dataset's metadata if not already loaded \n\n     if   ds . infoLoaded ,   return ;   end \n\n     % modify this to extract the metadata loaded from the data file \n     data   =   ds . loadData (); \n     ds . subject   =   data . subject ; \n     ds . saveTags   =   data . saveTags ; \n     ds . datenum    =   data . datenum ; \n     ds . nChannels   =   data . nChannels ; \n     ds . nTrials   =   numel ( data . trials ); \n\n     ds . infoLoaded   =   true ;  end   The metadata fields you might assign are as follows:   subject  - dataset subject or participant name  datenum  - a Matlab datenum identifying the collection time of the dataset  nChannels  - the number of unique spiking channels recorded in this dataset  nTrials  - the number of trials included in this dataset  saveTags  - a vector of numbers indicating within-day blocks of trials included    Metadata are optional  We note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your  Dataset  class.",
            "title": "Editing Dataset.m (Required)"
        },
        {
            "location": "/interfacing/#editing-runparamsm-optional",
            "text": "Edit the file  +LorenzExperiment/RunParams.m . Recall that  RunParams  encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add.  You can add these additional properties anywhere in the file: classdef   RunParams   <   LFADS . RunParams \n    properties \n        % Add additional custom parameters here. The default you assign to \n        % them will be used when computing the hash value. Any params whose value \n        % differs from the default will be included in the hash value, to allow new \n        % parameters to be added without invalidating old hashes. So choose \n        % the default once and don't change it. If you decide to use another \n        % value later by default, override it in the constructor instead. \n    end    Pick default values carefully  The default values you assign next to each property should be chosen carefully and never changed once added.  The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the  RunParams  constructor without affecting the hash. However, you will then want to manually assign this property to its  old value  in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values.    Specifying data-hash affecting parameters  As described  here , the parameter values inside  RunParams  will be used to generate two different hashes, a  param_  hash that includes all properties that affect LFADS whose values differ from their defaults, and a  data_  hash that includes the subset of those properties that affect the raw data input to LFADS. This design allows us to reuse data on disk when sweeping parameters that only affect LFADS internal architecture, e.g. the size of the generator RNN.  By default, the  data_  hash includes all properties that do not begin with  c_  as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to  RunParams . If you need to adjust this behavior, override the method  getListPropertiesNotAffectingInputData  in your  RunParams  instance. You should probably take a union of your custom properties with the properties returned by the superclass method  LFADS . Run / getListPropertiesNotAffectingInputData .   No changes are required to  RunParams.m  to get up and running.",
            "title": "Editing RunParams.m (Optional)"
        },
        {
            "location": "/interfacing/#editing-runcollectionm-optional",
            "text": "Edit the file  +LorenzExperiment/RunCollection.m . Recall that a  RunCollection  specifies a set of individual LFADS runs defined by an array of  RunSpec s crossed with an array of  RunParams .  classdef   RunCollection   <   LFADS . RunCollection \n     % no need to modify anything here, but feel free to add useful methods \n     % and properties as useful \n\n     methods          function   rc  =   RunCollection ( varargin )               rc @ LFADS . RunCollection ( varargin {:}); \n         end \n     end  end   No changes are required to  RunCollection.m  to get up and running , but you can add any utility methods to facilitate analysis for your specific application.",
            "title": "Editing RunCollection.m (Optional)"
        },
        {
            "location": "/interfacing/#editing-runm-required",
            "text": "Edit the file  +LorenzExperiment/Run.m . Recall that a  Run  represents a specific LFADS model training run. The main function you will need to provide a definition for is  generateCountsForDataset . This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this:  function   out  =   generateCountsForDataset ( r, dataset, mode, varargin )   Here,  r  refers to the  LorenzExperiment.Run  instance. It may be particularly helpful to refer to the  RunParams  instance assigned to this run via  r.params , especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included.",
            "title": "Editing Run.m (Required)"
        },
        {
            "location": "/interfacing/#inputs-to-generatecountsfordataset",
            "text": "r :  The  Run  instance. The current  RunParams  instance can be accessed through  r.params .  dataset :  LorenzExperiment.Dataset  instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run,  generateCountsForDataset  will be called once for each dataset, one at a time. You might use  dataset.loadData()  to load the actual data, as you defined above.  mode :   String that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined:   export  - indicates that the sequence data will be exported as the actual input to the Python+Tensorflow LFADS run  alignment  - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run.   If you decide you do wish to handle the  alignment  case differently, you will need to override the  usesDifferentDataForAlignment  method in your  Run  class to return  true , by adding:  function   tf  =   usesDifferentDataForAlignment ( r )       tf   =   true ;  end    varargin :  Currently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g.  'paramName' ,   paramValue ,   ... ) in the future without breaking existing implementations.",
            "title": "Inputs to generateCountsForDataset:"
        },
        {
            "location": "/interfacing/#outputs-to-generatecountsfordataset",
            "text": "out :   A scalar struct which holds the following fields:   . counts  (Required):  A tensor of binned spike counts (not rates) with size  nTrials  x  nChannels  x  nTime . These should be total counts, not normalized rates, as they will be added together during re-binning.  . timeVecMs  (Optional):  A vector of timepoints with length  nTime  in milliseconds associated with each time bin in  counts . You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the  raw  spike bin width used when the data are later rebinned to match  r.params.spikeBinMs . Default is  1 : size ( counts ,   3 ) .  . conditionId  (Optional):  Vector with length  nTrials  identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector. Default is  [] .  . truth  (Optional):  For synthetic datasets, provides the ground-truth counts for each trial. Same size as  .counts . Default is  [] .  . externalInputs  (Optional):  Specifies the observed, external inputs which will be passed either to the generator directly or to the encoder. Default is  [] .    A note on bin widths  There are two different bin widths in  lfads-run-manager . First is this  binWidthMs  within  seq , which is the spike binning that you will do to the data inside  generateCountsForDataset .  We recommend binning here at 1 ms or the smallest bin width you might wish to use.  Second is the field  spikeBinMs  inside the  RunParams  class. The expectation is that you will bin using a small bin width inside  generateCountsForDataset , and then  the run manager code will automatically re-bin the data at the larger bin width set by  r.params.spikeBinMs  for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.",
            "title": "Outputs to generateCountsForDataset:"
        },
        {
            "location": "/single-session/",
            "text": "Setting up a single-session LFADS run\n\u00b6\n\n\nAssuming you have finished \nadapting the LFADS run manager classes to your dataset\n, you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a \ndrive script\n that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling \nLFADS Run Manager\n to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as \nLorenzExperiment\n, but you should substitute this with your package name.\n\n\n\n\nFollow along with \nLorenzExperiment.drive_script\n\n\nA complete drive script is available as a starting point in \n+LorenzExperiment/drive_script.m\n for you to copy/paste from.\n\n\n\n\nLorenz attractor example\n\u00b6\n\n\nFor this demo, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code:\n\n\ndatasetPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\nLFADS\n.\nUtils\n.\ngenerateDemoDatasets\n(\ndatasetPath\n,\n \n'nDatasets'\n,\n \n3\n);\n\n\n\n\n\nThis will simulate a chaotic 3 dimensional \nLorenz attractor\n as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories:\n\n\n\n\nFrom these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the \nconditions\n) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition.\n\n\nHere are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:\n\n\n\n\nBuilding a dataset collection and adding datasets\n\u00b6\n\n\nFirst, create a dataset collection that points to a folder on disk where datasets are stored:\n\n\ndataPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\ndc\n \n=\n \nLorenzExperiment\n.\nDatasetCollection\n(\ndataPath\n);\n\n\ndc\n.\nname\n \n=\n \n'lorenz_example'\n;\n\n\n\n\n\nThen, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the \nDatasetCollection\n and will replace any dataset that has the same name if present.\n\n\nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\n\n\n\nYou can verify that the datasets have been added to the collection:\n\n\n>>\n \ndc\n\n\nLorenzExperiment\n.\nDatasetCollection\n \"\nlorenz_example\n\"\n  \n1\n \ndatasets\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \n[\n \n1\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset001\n\"\n\n         \nname\n:\n \n'lorenz_example'\n\n      \ncomment\n:\n \n''\n\n         \npath\n:\n \n'~/lorenz_example/datasetss'\n\n     \ndatasets\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nDataset\n]\n\n    \nnDatasets\n:\n \n1\n\n\n\n\n\nYou can access individual datasets using \ndc\n.\ndatasets\n(\n1\n)\n or by name with \ndc\n.\nmatchDatasetsByName\n(\n'dataset001'\n)\n.\n\n\nYou can then load all of the metadata for the datasets using:\n\ndc\n.\nloadInfo\n();\n\n\n\n\nHow this metadata is determined for each dataset may be customized as described in \nInterfacing with your Datasets\n. You can view a summary of the metadata using:\n\n\n>>\n \ndc\n.\ngetDatasetInfoTable\n          \n\n                  \nsubject\n                  \ndate\n             \nsaveTags\n    \nnTrials\n    \nnChannels\n\n              \n________________\n    \n______________________\n    \n________\n    \n_______\n    \n_________\n\n\n\ndataset001\n    \n'lorenz_example'\n    \n[\n31\n-\nJan\n-\n2018\n \n00\n:\n00\n:\n00\n]\n    \n'1'\n         \n1820\n       \n35\n\n\n\n\n\nCreate a \nRunCollection\n\u00b6\n\n\nWe\u2019ll now setup a \nRunCollection\n that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.\n\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nLorenzExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleSingleRun'\n,\n \ndc\n);\n\n\n\n% replace with approximate date script authored as YYYYMMDD\n\n\n% to ensure forwards compatibility\n\n\nrc\n.\nversion\n \n=\n \n20180131\n;\n\n\n\n\n\n\n\nVersioning and backwards compatibility\n\n\nYou can optionally set \nrc.version\n just after creating the \nRunCollection\n. Version should be set to the date the script was first used to generate the LFADS files on disk, in the format \nYYYYMMDD\n. Specifying this here allows for backwards compatibility in case we need to change aspects of where LFADS Run Manager organizes files on disk or how the \nRunParams\n hashes are generated. The default \nrc.version\n will be updated if significant changes are made in the code, so manually specifying it in the drive script can be useful to \u201cfreeze\u201d the LFADS Run Manager logic for this specific collection of runs.\n\n\n\n\nSpecify the hyperparameters in \nRunParams\n\u00b6\n\n\nWe\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8.\n\n\npar\n \n=\n \nLorenzExperiment\n.\nRunParams\n;\n\n\npar\n.\nname\n \n=\n \n'first_attempt'\n;\n \n% completely optional\n\n\npar\n.\nspikeBinMs\n \n=\n \n2\n;\n \n% rebin the data at 2 ms\n\n\npar\n.\nc_co_dim\n \n=\n \n0\n;\n \n% no controller --> no inputs to generator\n\n\npar\n.\nc_batch_size\n \n=\n \n150\n;\n \n% must be < 1/5 of the min trial count\n\n\npar\n.\nc_factors_dim\n \n=\n \n8\n;\n \n% and manually set it for multisession stitched models\n\n\npar\n.\nc_gen_dim\n \n=\n \n64\n;\n \n% number of units in generator RNN\n\n\npar\n.\nc_ic_enc_dim\n \n=\n \n64\n;\n \n% number of units in encoder RNN\n\n\npar\n.\nc_learning_rate_stop\n \n=\n \n1e-3\n;\n \n% we can stop training early for the demo\n\n\n\n\n\n\n\nSetting batch size\n\n\nThe number of trials in your smallest dataset determines the largest batch size you can pick. If \ntrainToTestRatio\n is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as \nc_batch_size\n. If you choose a batch size which is too large, LFADS Run Manager will generate an error to alert you.\n\n\n\n\nWe then add this \nRunParams\n to the \nRunCollection\n:\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\n\n\n\nYou can access the parameter settings added to \nrc\n using \nrc.params\n, which will be an array of \nRunParams\n instances.\n\n\nRunParams\n data and param hashes\n\u00b6\n\n\nIf we look at the printed representation of the \nRunParams\n instance, we see two hash values:\n\n\n>>\n \npar\n\n\n\npar\n \n=\n\n\n\nLorenzExperiment\n.\nRunParams\n \nparam_YOs74u\n \ndata_4MaTKO\n\n\nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n...\n\n\n\n\n\nThese six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. The first is the \u201cparam\u201d hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with \nparam_\n.  The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by \ndata_\n. We use two separate hashes here to save space on disk; many parameters like \nc_co_dim\n only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like \nc_co_dim\n would otherwise require many copies of identical data to be saved on disk. Instead, we store the data in folders according to the \ndata_\n hash and symlink copies for each run. If you add additional parameters that do not affect the data used by LFADS, you should specify them in your \nRunParams\n class as described \nhere\n.\n\n\nBelow the hash values are the set of properties whose values differ from their specified defaults (as specified next to the property in the class definition). Properties which are equal to their default values are not included in the hash calculation. This allows you to add new properties to your \nRunParams\n class without altering the computed hashes for older runs. See this \nwarning note\n for more details.\n\n\n\n\nRunParams\n is a value class\n\n\nUnlike all of the other classes, \nRunParams\n is not a handle but a value class, which acts similarly to a \nstruct\n in that it is passed by value. This means that after adding the \nRunParams\n instance \npar\n to the \nRunCollection\n, we can modify \npar\n and then add it again to define a second set of parameters, like this:\n\npar\n.\nc_gen_dim\n \n=\n \n96\n;\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\npar\n.\nc_gen_dim\n \n=\n \n128\n;\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\n\n\n\n\n\n\nGenerating hyperparameter value sweeps\n\n\nIf you wish to sweep a specific property or set of properties, you can create a \nRunParams\n instance, set the other properties as needed, and then call \ngenerateSweep\n to build an array of \nRunParams\n instances:\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_gen_dim'\n,\n \n[\n32\n \n64\n \n96\n \n128\n]);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n\nOr along multiple parameters in a grid:\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_gen_dim'\n,\n \n[\n32\n \n64\n \n96\n \n128\n],\n \n'c_co_dim'\n,\n \n0\n:\n2\n:\n4\n);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n\n\n\nSpecify the \nRunSpec\n\u00b6\n\n\nRecall that \nRunSpec\n instances specify which datasets are included in a specific run. For this example, we\u2019ve only included a single dataset, so we don\u2019t have any choices to make. We\u2019ll run LFADS on first dataset by itself:\n\n\nds_index\n \n=\n \n1\n;\n\n\nrunSpecName\n \n=\n \ndc\n.\ndatasets\n(\nds_index\n).\ngetSingleRunName\n();\n \n% generates a simple run name from this datasets name\n\n\nrunSpec\n \n=\n \nLorenzExperiment\n.\nRunSpec\n(\nrunSpecName\n,\n \ndc\n,\n \nds_index\n);\n\n\nrc\n.\naddRunSpec\n(\nrunSpec\n);\n\n\n\n\n\nYou can adjust the arguments to the constructor of \nLorenzExperiment.RunSpec\n, but in the example provided the inputs define:\n\n\n\n\nthe unique name of the run. Here we use \ngetSingleRunName\n, a convenience method of \nDataset\n that generates a name like \nsingle_datasetName\n.\n\n\nthe \nDatasetCollection\n from which datasets will be retrieved\n\n\nthe indices or names of datasets (as a string or cell array of strings) to include\n\n\n\n\nCheck the \nRunCollection\n\u00b6\n\n\nThe \nRunCollection\n will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total.\n\n\n>>\n \nrc\n\n\n\nLorenzExperiment\n.\nRunCollection\n \"\nexampleSingleSession\n\" \n(\n1\n \nruns\n \ntotal\n)\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n1\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleSingleSession\n\n\n  \n1\n \nparameter\n \nsettings\n\n  \n[\n1\n \nparam_YOs74u\n \ndata_4MaTKO\n]\n \nLorenzExperiment\n.\nRunParams\n \"\nfirst_attempt\n\" \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n  \n1\n \nrun\n \nspecifications\n\n  \n[\n \n1\n]\n \nLorenzExperiment\n.\nRunSpec\n \"\nsingle_dataset001\n\" \n(\n1\n \ndatasets\n)\n\n\n                          \nname\n:\n \n'exampleSingleSession'\n\n                       \ncomment\n:\n \n''\n\n                      \nrootPath\n:\n \n'~/lorenz_example/runs'\n\n                       \nversion\n:\n \n20180131\n\n             \ndatasetCollection\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nDatasetCollection\n]\n\n                          \nruns\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRun\n]\n\n                        \nparams\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRunParams\n]\n\n                      \nrunSpecs\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRunSpec\n]\n\n                       \nnParams\n:\n \n1\n\n                     \nnRunSpecs\n:\n \n1\n\n                    \nnRunsTotal\n:\n \n1\n\n                     \nnDatasets\n:\n \n1\n\n                  \ndatasetNames\n:\n \n{\n'dataset001'\n}\n\n                          \npath\n:\n \n'~/lorenz_example/runs/exampleSingleSession'\n\n      \npathsCommonDataForParams\n:\n \n{\n'~/lorenz_example/runs/exampleSingleSession/data_4MaTKO'\n}\n\n                \npathsForParams\n:\n \n{\n'~/lorenz_example/runs/exampleSingleSession/param_YOs74u'\n}\n\n    \nfileShellScriptTensorboard\n:\n \n'~/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh'\n\n               \nfileSummaryText\n:\n \n'~/lorenz_example/runs/exampleSingleSession/summary.txt'\n\n       \nfileShellScriptRunQueue\n:\n \n'~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py'\n\n\n\n\n\nPrepare for LFADS\n\u00b6\n\n\nNow that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.\n\n\nrc\n.\nprepareForLFADS\n();\n\n\n\n\n\nThis will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call \nprepareForLFADS\n again. Existing files won\u2019t be overwritten unless you call \nrc.prepareForLFADS(true)\n.\n\n\nAfter running \nprepareForLFADS\n, the run manager will create the following files on disk under \nrc.path\n:\n\n\n~/lorenz_example/runs/exampleSingleSession\n\u251c\u2500\u2500 data_4MaTKO\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset001\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 inputInfo_dataset001.mat\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfads_dataset001.h5\n\u251c\u2500\u2500 param_YOs74u\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset001\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/single_dataset001/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/single_dataset001/lfads_dataset001.h5\n\u2514\u2500\u2500 summary.txt\n\n\n\n\nThe organization of these files on disk is discussed in more detail \nhere\n. Also, a \nsummary.txt\n file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling \nrc.generateSummaryText()\n.\n\n\nLorenzExperiment\n.\nRunCollection\n \"\nexampleSingleSession\n\" \n(\n1\n \nruns\n \ntotal\n)\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleSingleSession\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n1\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n\n  \n------------------------\n\n\n  \n1\n \nRun\n \nSpecifications\n:\n\n\n    \n[\nrunSpec\n \n1\n]\n \nLorenzExperiment\n.\nRunSpec\n \"\nsingle_dataset001\n\" \n(\n1\n \ndatasets\n)\n\n      \n[\nds\n \n1\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset001\n\"\n\n  \n------------------------\n\n\n  \n1\n \nParameter\n \nSettings\n:\n\n\n    \n[\n1\n \nparam_YOs74u\n \ndata_4MaTKO\n]\n \nLorenzExperiment\n.\nRunParams\n \"\nfirst_attempt\n\"\n      \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n      \nspikeBinMs\n:\n \n2\n\n      \ntrainToTestRatio\n:\n \n4\n\n      \nuseAlignmentMatrix\n:\n \nfalse\n\n      \nuseSingleDatasetAlignmentMatrix\n:\n \nfalse\n\n      \nscaleIncreaseStepsWithDatasets\n:\n \ntrue\n\n      \nc_cell_clip_value\n:\n \n5\n\n      \nc_factors_dim\n:\n \n8\n\n      \nc_ic_enc_dim\n:\n \n64\n\n      \nc_ci_enc_dim\n:\n \n128\n\n      \nc_gen_dim\n:\n \n64\n\n      \nc_keep_prob\n:\n \n0.95\n\n      \nc_learning_rate_decay_factor\n:\n \n0.98\n\n      \nc_device\n:\n \n/\ngpu\n:\n0\n\n      \nc_co_dim\n:\n \n0\n\n      \nc_do_causal_controller\n:\n \nfalse\n\n      \nc_do_feed_factors_to_controller\n:\n \ntrue\n\n      \nc_feedback_factors_or_rates\n:\n \nfactors\n\n      \nc_controller_input_lag\n:\n \n1\n\n      \nc_do_train_readin\n:\n \ntrue\n\n      \nc_l2_gen_scale\n:\n \n500\n\n      \nc_l2_con_scale\n:\n \n500\n\n      \nc_batch_size\n:\n \n150\n\n      \nc_kl_increase_steps\n:\n \n900\n\n      \nc_l2_increase_steps\n:\n \n900\n\n      \nc_ic_dim\n:\n \n64\n\n      \nc_con_dim\n:\n \n128\n\n      \nc_learning_rate_stop\n:\n \n0.001\n\n      \nc_temporal_spike_jitter_width\n:\n \n0\n\n      \nc_allow_gpu_growth\n:\n \ntrue\n\n      \nc_kl_ic_weight\n:\n \n1\n\n      \nc_kl_co_weight\n:\n \n1\n\n      \nc_inject_ext_input_to_gen\n:\n \nfalse\n\n      \nc_prior_ar_atau\n:\n \n10\n\n      \nc_do_train_prior_ar_atau\n:\n \ntrue\n\n      \nc_prior_ar_nvar\n:\n \n0.1\n\n      \nc_do_train_prior_ar_nvar\n:\n \ntrue\n\n      \nnum_samples_posterior\n:\n \n512\n\n      \nposterior_mean_kind\n:\n \nposterior_sample_and_average",
            "title": "Setting up a single-session run"
        },
        {
            "location": "/single-session/#setting-up-a-single-session-lfads-run",
            "text": "Assuming you have finished  adapting the LFADS run manager classes to your dataset , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a  drive script  that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling  LFADS Run Manager  to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as  LorenzExperiment , but you should substitute this with your package name.   Follow along with  LorenzExperiment.drive_script  A complete drive script is available as a starting point in  +LorenzExperiment/drive_script.m  for you to copy/paste from.",
            "title": "Setting up a single-session LFADS run"
        },
        {
            "location": "/single-session/#lorenz-attractor-example",
            "text": "For this demo, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code:  datasetPath   =   '~/lorenz_example/datasets' ;  LFADS . Utils . generateDemoDatasets ( datasetPath ,   'nDatasets' ,   3 );   This will simulate a chaotic 3 dimensional  Lorenz attractor  as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories:   From these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the  conditions ) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition.  Here are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:",
            "title": "Lorenz attractor example"
        },
        {
            "location": "/single-session/#building-a-dataset-collection-and-adding-datasets",
            "text": "First, create a dataset collection that points to a folder on disk where datasets are stored:  dataPath   =   '~/lorenz_example/datasets' ;  dc   =   LorenzExperiment . DatasetCollection ( dataPath );  dc . name   =   'lorenz_example' ;   Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the  DatasetCollection  and will replace any dataset that has the same name if present.  LorenzExperiment . Dataset ( dc ,   'dataset001.mat' );   You can verify that the datasets have been added to the collection:  >>   dc  LorenzExperiment . DatasetCollection  \" lorenz_example \"\n   1   datasets   in   ~/ lorenz_example / datasets \n   [   1 ]   LorenzExperiment . Dataset  \" dataset001 \"\n\n          name :   'lorenz_example' \n       comment :   '' \n          path :   '~/lorenz_example/datasetss' \n      datasets :   [ 1 x1   LorenzExperiment . Dataset ] \n     nDatasets :   1   You can access individual datasets using  dc . datasets ( 1 )  or by name with  dc . matchDatasetsByName ( 'dataset001' ) .  You can then load all of the metadata for the datasets using: dc . loadInfo ();   How this metadata is determined for each dataset may be customized as described in  Interfacing with your Datasets . You can view a summary of the metadata using:  >>   dc . getDatasetInfoTable           \n\n                   subject                    date               saveTags      nTrials      nChannels \n               ________________      ______________________      ________      _______      _________  dataset001      'lorenz_example'      [ 31 - Jan - 2018   00 : 00 : 00 ]      '1'           1820         35",
            "title": "Building a dataset collection and adding datasets"
        },
        {
            "location": "/single-session/#create-a-runcollection",
            "text": "We\u2019ll now setup a  RunCollection  that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.  runRoot   =   '~/lorenz_example/runs' ;  rc   =   LorenzExperiment . RunCollection ( runRoot ,   'exampleSingleRun' ,   dc );  % replace with approximate date script authored as YYYYMMDD  % to ensure forwards compatibility  rc . version   =   20180131 ;    Versioning and backwards compatibility  You can optionally set  rc.version  just after creating the  RunCollection . Version should be set to the date the script was first used to generate the LFADS files on disk, in the format  YYYYMMDD . Specifying this here allows for backwards compatibility in case we need to change aspects of where LFADS Run Manager organizes files on disk or how the  RunParams  hashes are generated. The default  rc.version  will be updated if significant changes are made in the code, so manually specifying it in the drive script can be useful to \u201cfreeze\u201d the LFADS Run Manager logic for this specific collection of runs.",
            "title": "Create a RunCollection"
        },
        {
            "location": "/single-session/#specify-the-hyperparameters-in-runparams",
            "text": "We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8.  par   =   LorenzExperiment . RunParams ;  par . name   =   'first_attempt' ;   % completely optional  par . spikeBinMs   =   2 ;   % rebin the data at 2 ms  par . c_co_dim   =   0 ;   % no controller --> no inputs to generator  par . c_batch_size   =   150 ;   % must be < 1/5 of the min trial count  par . c_factors_dim   =   8 ;   % and manually set it for multisession stitched models  par . c_gen_dim   =   64 ;   % number of units in generator RNN  par . c_ic_enc_dim   =   64 ;   % number of units in encoder RNN  par . c_learning_rate_stop   =   1e-3 ;   % we can stop training early for the demo    Setting batch size  The number of trials in your smallest dataset determines the largest batch size you can pick. If  trainToTestRatio  is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as  c_batch_size . If you choose a batch size which is too large, LFADS Run Manager will generate an error to alert you.   We then add this  RunParams  to the  RunCollection :  rc . addParams ( par );   You can access the parameter settings added to  rc  using  rc.params , which will be an array of  RunParams  instances.",
            "title": "Specify the hyperparameters in RunParams"
        },
        {
            "location": "/single-session/#runparams-data-and-param-hashes",
            "text": "If we look at the printed representation of the  RunParams  instance, we see two hash values:  >>   par  par   =  LorenzExperiment . RunParams   param_YOs74u   data_4MaTKO  c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001  ...   These six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. The first is the \u201cparam\u201d hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with  param_ .  The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by  data_ . We use two separate hashes here to save space on disk; many parameters like  c_co_dim  only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like  c_co_dim  would otherwise require many copies of identical data to be saved on disk. Instead, we store the data in folders according to the  data_  hash and symlink copies for each run. If you add additional parameters that do not affect the data used by LFADS, you should specify them in your  RunParams  class as described  here .  Below the hash values are the set of properties whose values differ from their specified defaults (as specified next to the property in the class definition). Properties which are equal to their default values are not included in the hash calculation. This allows you to add new properties to your  RunParams  class without altering the computed hashes for older runs. See this  warning note  for more details.   RunParams  is a value class  Unlike all of the other classes,  RunParams  is not a handle but a value class, which acts similarly to a  struct  in that it is passed by value. This means that after adding the  RunParams  instance  par  to the  RunCollection , we can modify  par  and then add it again to define a second set of parameters, like this: par . c_gen_dim   =   96 ;  rc . addParams ( par );  par . c_gen_dim   =   128 ;  rc . addParams ( par );     Generating hyperparameter value sweeps  If you wish to sweep a specific property or set of properties, you can create a  RunParams  instance, set the other properties as needed, and then call  generateSweep  to build an array of  RunParams  instances: parSet   =   par . generateSweep ( 'c_gen_dim' ,   [ 32   64   96   128 ]);  rc . addParams ( parSet );   Or along multiple parameters in a grid: parSet   =   par . generateSweep ( 'c_gen_dim' ,   [ 32   64   96   128 ],   'c_co_dim' ,   0 : 2 : 4 );  rc . addParams ( parSet );",
            "title": "RunParams data and param hashes"
        },
        {
            "location": "/single-session/#specify-the-runspec",
            "text": "Recall that  RunSpec  instances specify which datasets are included in a specific run. For this example, we\u2019ve only included a single dataset, so we don\u2019t have any choices to make. We\u2019ll run LFADS on first dataset by itself:  ds_index   =   1 ;  runSpecName   =   dc . datasets ( ds_index ). getSingleRunName ();   % generates a simple run name from this datasets name  runSpec   =   LorenzExperiment . RunSpec ( runSpecName ,   dc ,   ds_index );  rc . addRunSpec ( runSpec );   You can adjust the arguments to the constructor of  LorenzExperiment.RunSpec , but in the example provided the inputs define:   the unique name of the run. Here we use  getSingleRunName , a convenience method of  Dataset  that generates a name like  single_datasetName .  the  DatasetCollection  from which datasets will be retrieved  the indices or names of datasets (as a string or cell array of strings) to include",
            "title": "Specify the RunSpec"
        },
        {
            "location": "/single-session/#check-the-runcollection",
            "text": "The  RunCollection  will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total.  >>   rc  LorenzExperiment . RunCollection  \" exampleSingleSession \"  ( 1   runs   total ) \n   Dataset   Collection  \" lorenz_example \"  ( 1   datasets )   in   ~/ lorenz_example / datasets \n   Path :   ~/ lorenz_example / runs / exampleSingleSession \n\n   1   parameter   settings \n   [ 1   param_YOs74u   data_4MaTKO ]   LorenzExperiment . RunParams  \" first_attempt \"  c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n   1   run   specifications \n   [   1 ]   LorenzExperiment . RunSpec  \" single_dataset001 \"  ( 1   datasets ) \n\n                           name :   'exampleSingleSession' \n                        comment :   '' \n                       rootPath :   '~/lorenz_example/runs' \n                        version :   20180131 \n              datasetCollection :   [ 1 x1   LorenzExperiment . DatasetCollection ] \n                           runs :   [ 1 x1   LorenzExperiment . Run ] \n                         params :   [ 1 x1   LorenzExperiment . RunParams ] \n                       runSpecs :   [ 1 x1   LorenzExperiment . RunSpec ] \n                        nParams :   1 \n                      nRunSpecs :   1 \n                     nRunsTotal :   1 \n                      nDatasets :   1 \n                   datasetNames :   { 'dataset001' } \n                           path :   '~/lorenz_example/runs/exampleSingleSession' \n       pathsCommonDataForParams :   { '~/lorenz_example/runs/exampleSingleSession/data_4MaTKO' } \n                 pathsForParams :   { '~/lorenz_example/runs/exampleSingleSession/param_YOs74u' } \n     fileShellScriptTensorboard :   '~/lorenz_example/runs/exampleSingleSession/launch_tensorboard.sh' \n                fileSummaryText :   '~/lorenz_example/runs/exampleSingleSession/summary.txt' \n        fileShellScriptRunQueue :   '~/lorenz_example/runs/exampleSingleSession/run_lfadsqueue.py'",
            "title": "Check the RunCollection"
        },
        {
            "location": "/single-session/#prepare-for-lfads",
            "text": "Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.  rc . prepareForLFADS ();   This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call  prepareForLFADS  again. Existing files won\u2019t be overwritten unless you call  rc.prepareForLFADS(true) .  After running  prepareForLFADS , the run manager will create the following files on disk under  rc.path :  ~/lorenz_example/runs/exampleSingleSession\n\u251c\u2500\u2500 data_4MaTKO\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset001\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 inputInfo_dataset001.mat\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfads_dataset001.h5\n\u251c\u2500\u2500 param_YOs74u\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset001\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/single_dataset001/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/single_dataset001/lfads_dataset001.h5\n\u2514\u2500\u2500 summary.txt  The organization of these files on disk is discussed in more detail  here . Also, a  summary.txt  file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling  rc.generateSummaryText() .  LorenzExperiment . RunCollection  \" exampleSingleSession \"  ( 1   runs   total ) \n   Path :   ~/ lorenz_example / runs / exampleSingleSession \n   Dataset   Collection  \" lorenz_example \"  ( 1   datasets )   in   ~/ lorenz_example / datasets \n\n   ------------------------ \n\n   1   Run   Specifications : \n\n     [ runSpec   1 ]   LorenzExperiment . RunSpec  \" single_dataset001 \"  ( 1   datasets ) \n       [ ds   1 ]   LorenzExperiment . Dataset  \" dataset001 \"\n\n   ------------------------ \n\n   1   Parameter   Settings : \n\n     [ 1   param_YOs74u   data_4MaTKO ]   LorenzExperiment . RunParams  \" first_attempt \"\n       c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n       spikeBinMs :   2 \n       trainToTestRatio :   4 \n       useAlignmentMatrix :   false \n       useSingleDatasetAlignmentMatrix :   false \n       scaleIncreaseStepsWithDatasets :   true \n       c_cell_clip_value :   5 \n       c_factors_dim :   8 \n       c_ic_enc_dim :   64 \n       c_ci_enc_dim :   128 \n       c_gen_dim :   64 \n       c_keep_prob :   0.95 \n       c_learning_rate_decay_factor :   0.98 \n       c_device :   / gpu : 0 \n       c_co_dim :   0 \n       c_do_causal_controller :   false \n       c_do_feed_factors_to_controller :   true \n       c_feedback_factors_or_rates :   factors \n       c_controller_input_lag :   1 \n       c_do_train_readin :   true \n       c_l2_gen_scale :   500 \n       c_l2_con_scale :   500 \n       c_batch_size :   150 \n       c_kl_increase_steps :   900 \n       c_l2_increase_steps :   900 \n       c_ic_dim :   64 \n       c_con_dim :   128 \n       c_learning_rate_stop :   0.001 \n       c_temporal_spike_jitter_width :   0 \n       c_allow_gpu_growth :   true \n       c_kl_ic_weight :   1 \n       c_kl_co_weight :   1 \n       c_inject_ext_input_to_gen :   false \n       c_prior_ar_atau :   10 \n       c_do_train_prior_ar_atau :   true \n       c_prior_ar_nvar :   0.1 \n       c_do_train_prior_ar_nvar :   true \n       num_samples_posterior :   512 \n       posterior_mean_kind :   posterior_sample_and_average",
            "title": "Prepare for LFADS"
        },
        {
            "location": "/running/",
            "text": "Running LFADS\n\u00b6\n\n\nTo train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call \nrun_lfads.py\n and do the work of training the model. \nlfads-run-manager\n provides two ways to go about this.\n\n\n\n\nAdd the \nrun_lfads.py\n folder to your shell PATH\n\n\nBe sure that the LFADS python source folder is on your shell path, such that running \nwhich run_lfads.py\n prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like \nexport PATH=$PATH:/path/to/models/research/lfads\n and consider adding this to your \n.bashrc\n file.\n\n\nIf Matlab is able to determine the location of \nrun_lfads.py\n (meaning that it\u2019s own inherited \nPATH\n was set correctly), it will prepend an \nexport PATH=...\n statement to each generated shell script for you. If not, you can try calling \nsetenv('PATH', '...')\n from within Matlab to add \nrun_lfads.py\n to the path. before generating the shell scripts.\n\n\nAlternatively, you can hard-code the location to \nrun_lfads.py\n by passing along the fully specified path to each of the \nwriteShellScript...\n methods as \n'path_run_lfads_py', '/path/to/run_lfads.py'\n\n\n\n\n\n\nVirtualenv support\n\n\nEach of the methods below supports a \n'virtualenv'\n,\n \n'environmentName'\n parameter-value argument. If specified, a \nsource activate environmentName\n will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment (or a conda virtual environment).\n\n\n\n\nLFADS Queue: Automatically queueing many runs\n\u00b6\n\n\nIf you wish to run each LFADS model manually at the command line, \nskip ahead\n. However, manually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the LFADS Queue model queueing system which will take care of training all the LFADS models for you.\n\n\n\n\nOnly supported on Linux\n\n\nUnfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on \nnvidia-smi\n, though it\u2019s theoretically possible with \ncuda-smi\n with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get \ntmux\n working.\n\n\n\n\nFirst, we\u2019ll generate the Python script from Matlab that enumerates all of the runs:\n\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'display'\n,\n \n0\n,\n \n'virtualenv'\n,\n \n'tensorflow'\n);\n\n\n\n\n\nOptional parameters include:\n\n\n\n\ndisplay\n:\n\n\nThe numeric value of the X display to target. \n0\n means target display \nDISPLAY=:0\n. A display is needed to draw plots using \nmatplotlib\n. If you\u2019re running on a VM, you may want to launch a VNC Server and point at that display. By default the display will be set according to the \nDISPLAY\n environment variable as it is seen inside \ntmux\n.\n\n\ngpuList\n:\n\n\nList of GPU indices to include in the queue. By default, this will include all GPUs detected by \nnvidia-smi\n.\n\n\nrunIdx\n:\n\n\nScalar indices of all runs to include in the queue. By default this will include all runs in \n.runs\n.\n\n\nvirtualenv\n:\n\n\nString indicating the virtual environment to source before launching the Python LFADS task, where TensorFlow must be installed.\n\n\nrerun\n:\n\n\nBy default, any run which already has an \nlfads.done\n file in the directory will be skipped, allowing you to regenerate and rerun the queue script whenever new runs are added. If \nrerun\n is \ntrue\n, all runs will be executed, although the old LFADS output checkpoint will be used during training. If you want to re-train from scratch, you\u2019ll need to delete the \nlfadsOutput\n directories, or call \nrc.deleteLFADSOutput()\n.\n\n\noneTaskPerGPU\n:\n\n\nBy default, only one LFADS model will be trained per GPU, as empirically we\u2019ve found that the switching costs outweigh any benefit from running multiple models simultaneously on each GPU. If you set this to \nfalse\n, ensure that you\u2019ve set \nc_allow_gpu_growth\n to \ntrue\n in the \nRunParams\n.\n\n\ngpuMemoryRequired\n\n\nEstimated maximum MB of GPU RAM needed per model, used to schedule models onto GPUs when \noneTaskPerGPU\n is \nfalse\n.\n\n\nmaxTasksSimultaneously\n\n\nA manual cap on the number of models to train simultaneously. This is only relevant when \noneTaskPerGPU\n is false, and will default to the number of CPUs minus one.\n\n\nprependPathToLFADSQueue\n\n\nIf true, automatically appends the path to \nlfadsqueue.py\n to the \nPYTHONPATH\n inside the generated script. Defaults to \nfalse\n to avoid confusion.\n\n\n\n\nThis will generate a Python script \nrun_lfads.py\n, which for our example can be launched via:\n\n\npython ~/lorenz_example/runs/exampleRun/run_lfadsqueue.py\n\n\n\n\n\n\nRun Manager \nsrc\n folder should be added to your \nPYTHONPATH\n\n\nThe \nrun_lfadsqueue.py\n script depends on \nlfadsqueue.py\n, which lives in \nlfads-run-manager/src\n. You should add this to your \nPYTHONPATH\n or request that it be added to your PYTHONPATH environment variable in the \nrun_lfadsqueue.py\n script by setting \nprependPathToLFADSQueue\n to \ntrue\n.\n\n\n\n\n\n\nInstall and configure \ntmux\n\n\nThe LFADS queue launches each LFADS run inside its own \ntmux\n session to make it easy to monitor the runs as they are running. You\u2019ll need to install \ntmux\n.\n\n\nAlso, \ntmux\n is finnicky about environment variables, which are only loaded when the \ntmux\n server first launches, not when a new session is started. The main one you need is that \nrun_lfads.py\n must be on your \nPATH\n somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited \nPATH\n was set correctly), it will prepend an \nexport PATH=...\n statement to each \nlfads_train.sh\n script for you. If not, you can try calling \nsetenv('PATH', '...')\n from within Matlab to add \nrun_lfads.py\n to the path. before generating the shell scripts.\n\n\nIf you\u2019re having trouble, you might want to launch a new \ntmux\n session using:\n\n\ntmux new-session\n\n\n\n\nThen from inside \ntmux\n, test that \nwhich run_lfads.py\n prints a location and that you are able to launch python and run \nimport\n \ntensorflow\n \nas\n \ntf\n without any issues.\n\n\n\n\nYou can then kick everything off by running \npython run_lfadsqueue.py\n at the command line. It\u2019s recommended to do this from inside your own \ntmux\n session if you\u2019re running on a remote server, so you can monitor the task runner.\n\n\n\n\nPython virtual environments\n\n\nIf tensorflow is installed in a Python virtual environment, you can have this environment be automatically activated via \nsource activate\n within the training scripts using:\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'virtualenv'\n,\n \n'tensorflow'\n);\n\n\n\n\n\n\nA few notes on how the system works:\n\n\n\n\nOutput from Python will be \ntee\n\u2018d into \nlfads.out\n, so you can check the output during or afterwards either there or in the \ntmux\n session.\n\n\nWhen a model finishes training and posterior mean sampling, a file called \nlfads.done\n will be created\n\n\nIf the task runner detects an \nlfads.done\n file, it will skip that run. Unless you pass \n'rerun'\n,\n \ntrue\n to \nwriteShellScriptRunQueue\n, in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run.\n\n\nIf a run fails, the error will be printed by the task runner and \nlfads.done\n will not be created\n\n\nA running tally of how many runs are currently running, have finished, or have failed will be printed\n\n\nYou can enter a run\u2019s \ntmux\n session directly to monitor it. The list of sessions can be obtained using \ntmux list-sessions\n. You can also abort it using \nCtrl-C\n and it will be marked as failed by the task runner.\n\n\nIf you \nCtrl-C\n the \nrun_lfadsqueue.py\n script itself, the already launched runs will continue running. If you want to abort them, you can \npkill python\n although this will kill all python processes you\u2019ve created. In either case, you should be able to relaunch the \nrun_lfadsqueue.py\n script and have it pick up where it left off as well.\n\n\n\n\nThe \nrun_lfadsqueue.py\n script will periodically output updates about how the runs are proceeding:\n\n\n(\ntensorflow\n)\n \u279c  exampleRun python run_lfadsqueue.py\nWarning: tmux sessions will be nested inside the current session\nQueue: Launching TensorBoard on port \n42561\n in tmux session exampleRun_tensorboard_port42561\nbash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port\n=\n42561\n\nQueue: Initializing with \n2\n GPUs and \n12\n CPUs, max \n4\n simultaneous tasks\nTask lfads_param_Qr2PeG__single_dataset001: launching on gpu \n0\n\nTask lfads_param_Qr2PeG__single_dataset001: started in tmux session lfads_param_Qr2PeG__single_dataset001 on GPU \n0\n with PID \n19498\n\nTask lfads_param_Qr2PeG__single_dataset002: launching on gpu \n1\n\nTask lfads_param_Qr2PeG__single_dataset002: started in tmux session lfads_param_Qr2PeG__single_dataset002 on GPU \n1\n with PID \n19527\n\nTask lfads_param_Qr2PeG__single_dataset003: launching on gpu \n0\n\nTask lfads_param_Qr2PeG__single_dataset003: started in tmux session lfads_param_Qr2PeG__single_dataset003 on GPU \n0\n with PID \n19551\n\nTask lfads_param_Qr2PeG__all: launching on gpu \n1\n\nTask lfads_param_Qr2PeG__all: started in tmux session lfads_param_Qr2PeG__all on GPU \n1\n with PID \n19585\n\nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to \n0\n.009800.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to \n0\n.009800.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to \n0\n.009604.\nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to \n0\n.009604.\nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to \n0\n.009412.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to \n0\n.009412.\n\n\n\n\nAs the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits \nc_learning_rate_stop\n). When a task fails or completes, the queue will print out a running tally.\n\n\nNote that TensorBoard has automatically been launched on an available port, here on \n42561\n. You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using \ntmux list-sessions\n.\n\n\n\u279c  exampleRun tmux list-sessions\nmatlab: \n4\n windows \n(\ncreated Tue Oct  \n3\n \n21\n:51:49 \n2017\n)\n \n[\n201x114\n]\n \n(\nattached\n)\n\nexampleRun_tensorboard_port42561: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_Qr2PeG__all: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:17 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_Qr2PeG__single_dataset001: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x114\n]\n\nlfads_param_Qr2PeG__single_dataset002: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_Qr2PeG__single_dataset003: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:17 \n2017\n)\n \n[\n201x113\n]\n\n\n\n\n\nIf you wish to abort ongoing runs, you can either attach to them directly and use \nCtrl-C\n, or use \ntmux kill-session SESSIONNAME\n. When everything has completed, you\u2019ll see something like this:\n\n\nTask lfads_param_Qr2PeG__all: Stopping optimization based on learning rate criteria.\nTask lfads_param_Qr2PeG__all: completed successfully\nQueue: All tasks completed.\nQueue: \n0\n skipped, \n4\n finished, \n0\n failed, \n0\n running\n\n\n\n\nLaunching each run individually from shell scripts\n\u00b6\n\n\nFollow these instructions to run each model individually, but you\u2019ll probably prefer to \nqueue everything at once\n.\n\n\nTraining the model\n\u00b6\n\n\nThe first is to manually generate shell scripts for each run and then run them yourself. First, for each run \ni\n, you will call:\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptLFADSTrain\n(\n'cuda_visible_devices'\n,\n \n0\n,\n \n'display'\n,\n \n0\n);\n\n\n\n\n\nHere, you should specify options that will be written into the shell script, the key ones being:\n\n\n\n\ncuda_visible_devices\n - which GPU index to run this model on, e.g. \n0\n. Use the \nnvidia-smi\n to enumerate the available GPUs on your system\n\n\ndisplay\n - the X display to use, e.g. \n0\n, which will set \nDISPLAY\n to \n:0\n. The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like \ntightvnc\n or \nvncserver\n.\n\n\nappendPosteriorMeanSample\n - \ntrue\n or \nfalse\n specifying whether to chain the posterior mean sampling operation after the training is finished. The default is \nfalse\n, but if you set this to \ntrue\n, you won\u2019t need to call \nwriteShellScriptPosteriorMeanSample\n below.\n\n\nappendWriteModelParams\n - \ntrue\n or \nfalse\n specifying whether to chain the posterior mean sampling operation after the training is finished. The default is \nfalse\n, but if you set this to \ntrue\n, you won\u2019t need to call \nwriteShellScriptWriteModelParams\n below.\n\n\n\n\nThis will generate an \nlfads_train.sh\n in the corresponding run\u2019s folder. For the first run in our example, this is at\n\n~/lorenz_example/runs/exampleRun/param_Qr2PeG/single_dataset001/lfads_train.sh\n\n\n\nThe script essentially launches Python to run \nrun_lfads.py\n with the specific parameters you\u2019ve indicated in \nRunParams\n and pointing at the corresponding datasets, which were saved earlier when we called \nrc.prepareForLFADS\n.\n\n\n#!/bin/bash\n\n\n\npath_to_run_lfads\n=\n$(\nwhich run_lfads.py\n)\n\n\nif\n \n[\n ! -n \n\"\n$path_to_run_lfads\n\"\n \n]\n;\n \nthen\n\n    \necho\n \n\"Error: run_lfads.py not found on PATH. Ensure you add LFADS to your system PATH.\"\n\n    \nexit\n \n1\n\n\nfi\n\n\n\nDISPLAY\n=\n:0 \nCUDA_VISIBLE_DEVICES\n=\n0\n python \n$(\nwhich run_lfads.py\n)\n --data_dir\n=\n/home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsInput --data_filename_stem\n=\nlfads --lfads_save_dir\n=\n/home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsOutput --cell_clip_value\n=\n5\n.000000 --factors_dim\n=\n8\n --ic_enc_dim\n=\n64\n --ci_enc_dim\n=\n128\n --gen_dim\n=\n64\n --keep_prob\n=\n0\n.950000 --learning_rate_decay_factor\n=\n0\n.980000 --device\n=\n/gpu:0 --co_dim\n=\n0\n --do_causal_controller\n=\nfalse\n --do_feed_factors_to_controller\n=\ntrue\n --feedback_factors_or_rates\n=\nfactors --controller_input_lag\n=\n1\n --do_train_readin\n=\ntrue\n --l2_gen_scale\n=\n500\n.000000 --l2_con_scale\n=\n500\n.000000 --batch_size\n=\n150\n --kl_increase_steps\n=\n900\n --l2_increase_steps\n=\n900\n --ic_dim\n=\n64\n --con_dim\n=\n128\n --learning_rate_stop\n=\n0\n.001000 --temporal_spike_jitter_width\n=\n0\n --allow_gpu_growth\n=\ntrue\n --kl_ic_weight\n=\n1\n.000000 --kl_co_weight\n=\n1\n.000000 --inject_ext_input_to_gen\n=\nfalse\n\n\n\n\n\nRunning the \nlfads_train.sh\n script will launch the Tensorflow training which will take some time. You likely want to launch this in a \ntmux\n session if running remotely.\n\n\nSampling the posterior means\n\u00b6\n\n\nNext, generate the \nlfads_posterior_mean_sample.sh\n script to sample the posterior means, which can be launched after training has completed. If you set \nappendPosteriorMeanSample\n to \ntrue\n in \nwriteShellScriptLFADSTrain\n, you can skip this step.\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptLFADSPosteriorMeanSample\n(\n'cuda_visible_devices'\n,\n \n0\n);\n\n\n\n\n\nWriting the model parameters\n\u00b6\n\n\nLastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptWriteModelParams\n(\n'cuda_visible_devices'\n,\n \n0\n);\n\n\n\n\n\nIf you set \nappendWriteModelParams\n to \ntrue\n in \nwriteShellScriptLFADSTrain\n, you can skip this step. These results will be written to a file called \nlfadsOutput/model_params\n, though these results can be loaded into Matlab using \nrun.loadModelTrainedParams()\n.\n\n\nLaunching Tensorboard\n\u00b6\n\n\nYou can monitor the progress of each run by generating a script that launches TensorBoard.\n\nrc\n.\nwriteTensorboardShellScript\n();\n\n\n\n\nThis will create \nlaunch_tensorboard.sh\n which will launch Tensorboard which can then be visited at \nhttp://localhost:PORT\n.",
            "title": "Running LFADS"
        },
        {
            "location": "/running/#running-lfads",
            "text": "To train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call  run_lfads.py  and do the work of training the model.  lfads-run-manager  provides two ways to go about this.   Add the  run_lfads.py  folder to your shell PATH  Be sure that the LFADS python source folder is on your shell path, such that running  which run_lfads.py  prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like  export PATH=$PATH:/path/to/models/research/lfads  and consider adding this to your  .bashrc  file.  If Matlab is able to determine the location of  run_lfads.py  (meaning that it\u2019s own inherited  PATH  was set correctly), it will prepend an  export PATH=...  statement to each generated shell script for you. If not, you can try calling  setenv('PATH', '...')  from within Matlab to add  run_lfads.py  to the path. before generating the shell scripts.  Alternatively, you can hard-code the location to  run_lfads.py  by passing along the fully specified path to each of the  writeShellScript...  methods as  'path_run_lfads_py', '/path/to/run_lfads.py'    Virtualenv support  Each of the methods below supports a  'virtualenv' ,   'environmentName'  parameter-value argument. If specified, a  source activate environmentName  will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment (or a conda virtual environment).",
            "title": "Running LFADS"
        },
        {
            "location": "/running/#lfads-queue-automatically-queueing-many-runs",
            "text": "If you wish to run each LFADS model manually at the command line,  skip ahead . However, manually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the LFADS Queue model queueing system which will take care of training all the LFADS models for you.   Only supported on Linux  Unfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on  nvidia-smi , though it\u2019s theoretically possible with  cuda-smi  with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get  tmux  working.   First, we\u2019ll generate the Python script from Matlab that enumerates all of the runs:  rc . writeShellScriptRunQueue ( 'display' ,   0 ,   'virtualenv' ,   'tensorflow' );   Optional parameters include:   display :  The numeric value of the X display to target.  0  means target display  DISPLAY=:0 . A display is needed to draw plots using  matplotlib . If you\u2019re running on a VM, you may want to launch a VNC Server and point at that display. By default the display will be set according to the  DISPLAY  environment variable as it is seen inside  tmux .  gpuList :  List of GPU indices to include in the queue. By default, this will include all GPUs detected by  nvidia-smi .  runIdx :  Scalar indices of all runs to include in the queue. By default this will include all runs in  .runs .  virtualenv :  String indicating the virtual environment to source before launching the Python LFADS task, where TensorFlow must be installed.  rerun :  By default, any run which already has an  lfads.done  file in the directory will be skipped, allowing you to regenerate and rerun the queue script whenever new runs are added. If  rerun  is  true , all runs will be executed, although the old LFADS output checkpoint will be used during training. If you want to re-train from scratch, you\u2019ll need to delete the  lfadsOutput  directories, or call  rc.deleteLFADSOutput() .  oneTaskPerGPU :  By default, only one LFADS model will be trained per GPU, as empirically we\u2019ve found that the switching costs outweigh any benefit from running multiple models simultaneously on each GPU. If you set this to  false , ensure that you\u2019ve set  c_allow_gpu_growth  to  true  in the  RunParams .  gpuMemoryRequired  Estimated maximum MB of GPU RAM needed per model, used to schedule models onto GPUs when  oneTaskPerGPU  is  false .  maxTasksSimultaneously  A manual cap on the number of models to train simultaneously. This is only relevant when  oneTaskPerGPU  is false, and will default to the number of CPUs minus one.  prependPathToLFADSQueue  If true, automatically appends the path to  lfadsqueue.py  to the  PYTHONPATH  inside the generated script. Defaults to  false  to avoid confusion.   This will generate a Python script  run_lfads.py , which for our example can be launched via:  python ~/lorenz_example/runs/exampleRun/run_lfadsqueue.py   Run Manager  src  folder should be added to your  PYTHONPATH  The  run_lfadsqueue.py  script depends on  lfadsqueue.py , which lives in  lfads-run-manager/src . You should add this to your  PYTHONPATH  or request that it be added to your PYTHONPATH environment variable in the  run_lfadsqueue.py  script by setting  prependPathToLFADSQueue  to  true .    Install and configure  tmux  The LFADS queue launches each LFADS run inside its own  tmux  session to make it easy to monitor the runs as they are running. You\u2019ll need to install  tmux .  Also,  tmux  is finnicky about environment variables, which are only loaded when the  tmux  server first launches, not when a new session is started. The main one you need is that  run_lfads.py  must be on your  PATH  somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited  PATH  was set correctly), it will prepend an  export PATH=...  statement to each  lfads_train.sh  script for you. If not, you can try calling  setenv('PATH', '...')  from within Matlab to add  run_lfads.py  to the path. before generating the shell scripts.  If you\u2019re having trouble, you might want to launch a new  tmux  session using:  tmux new-session  Then from inside  tmux , test that  which run_lfads.py  prints a location and that you are able to launch python and run  import   tensorflow   as   tf  without any issues.   You can then kick everything off by running  python run_lfadsqueue.py  at the command line. It\u2019s recommended to do this from inside your own  tmux  session if you\u2019re running on a remote server, so you can monitor the task runner.   Python virtual environments  If tensorflow is installed in a Python virtual environment, you can have this environment be automatically activated via  source activate  within the training scripts using: rc . writeShellScriptRunQueue ( 'virtualenv' ,   'tensorflow' );    A few notes on how the system works:   Output from Python will be  tee \u2018d into  lfads.out , so you can check the output during or afterwards either there or in the  tmux  session.  When a model finishes training and posterior mean sampling, a file called  lfads.done  will be created  If the task runner detects an  lfads.done  file, it will skip that run. Unless you pass  'rerun' ,   true  to  writeShellScriptRunQueue , in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run.  If a run fails, the error will be printed by the task runner and  lfads.done  will not be created  A running tally of how many runs are currently running, have finished, or have failed will be printed  You can enter a run\u2019s  tmux  session directly to monitor it. The list of sessions can be obtained using  tmux list-sessions . You can also abort it using  Ctrl-C  and it will be marked as failed by the task runner.  If you  Ctrl-C  the  run_lfadsqueue.py  script itself, the already launched runs will continue running. If you want to abort them, you can  pkill python  although this will kill all python processes you\u2019ve created. In either case, you should be able to relaunch the  run_lfadsqueue.py  script and have it pick up where it left off as well.   The  run_lfadsqueue.py  script will periodically output updates about how the runs are proceeding:  ( tensorflow )  \u279c  exampleRun python run_lfadsqueue.py\nWarning: tmux sessions will be nested inside the current session\nQueue: Launching TensorBoard on port  42561  in tmux session exampleRun_tensorboard_port42561\nbash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port = 42561 \nQueue: Initializing with  2  GPUs and  12  CPUs, max  4  simultaneous tasks\nTask lfads_param_Qr2PeG__single_dataset001: launching on gpu  0 \nTask lfads_param_Qr2PeG__single_dataset001: started in tmux session lfads_param_Qr2PeG__single_dataset001 on GPU  0  with PID  19498 \nTask lfads_param_Qr2PeG__single_dataset002: launching on gpu  1 \nTask lfads_param_Qr2PeG__single_dataset002: started in tmux session lfads_param_Qr2PeG__single_dataset002 on GPU  1  with PID  19527 \nTask lfads_param_Qr2PeG__single_dataset003: launching on gpu  0 \nTask lfads_param_Qr2PeG__single_dataset003: started in tmux session lfads_param_Qr2PeG__single_dataset003 on GPU  0  with PID  19551 \nTask lfads_param_Qr2PeG__all: launching on gpu  1 \nTask lfads_param_Qr2PeG__all: started in tmux session lfads_param_Qr2PeG__all on GPU  1  with PID  19585 \nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to  0 .009800.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to  0 .009800.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to  0 .009604.\nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to  0 .009604.\nTask lfads_param_Qr2PeG__single_dataset003:      Decreasing learning rate to  0 .009412.\nTask lfads_param_Qr2PeG__single_dataset001:      Decreasing learning rate to  0 .009412.  As the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits  c_learning_rate_stop ). When a task fails or completes, the queue will print out a running tally.  Note that TensorBoard has automatically been launched on an available port, here on  42561 . You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using  tmux list-sessions .  \u279c  exampleRun tmux list-sessions\nmatlab:  4  windows  ( created Tue Oct   3   21 :51:49  2017 )   [ 201x114 ]   ( attached ) \nexampleRun_tensorboard_port42561:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x113 ] \nlfads_param_Qr2PeG__all:  1  windows  ( created Fri Oct   6   14 :43:17  2017 )   [ 201x113 ] \nlfads_param_Qr2PeG__single_dataset001:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x114 ] \nlfads_param_Qr2PeG__single_dataset002:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x113 ] \nlfads_param_Qr2PeG__single_dataset003:  1  windows  ( created Fri Oct   6   14 :43:17  2017 )   [ 201x113 ]   If you wish to abort ongoing runs, you can either attach to them directly and use  Ctrl-C , or use  tmux kill-session SESSIONNAME . When everything has completed, you\u2019ll see something like this:  Task lfads_param_Qr2PeG__all: Stopping optimization based on learning rate criteria.\nTask lfads_param_Qr2PeG__all: completed successfully\nQueue: All tasks completed.\nQueue:  0  skipped,  4  finished,  0  failed,  0  running",
            "title": "LFADS Queue: Automatically queueing many runs"
        },
        {
            "location": "/running/#launching-each-run-individually-from-shell-scripts",
            "text": "Follow these instructions to run each model individually, but you\u2019ll probably prefer to  queue everything at once .",
            "title": "Launching each run individually from shell scripts"
        },
        {
            "location": "/running/#training-the-model",
            "text": "The first is to manually generate shell scripts for each run and then run them yourself. First, for each run  i , you will call:  rc . runs ( i ). writeShellScriptLFADSTrain ( 'cuda_visible_devices' ,   0 ,   'display' ,   0 );   Here, you should specify options that will be written into the shell script, the key ones being:   cuda_visible_devices  - which GPU index to run this model on, e.g.  0 . Use the  nvidia-smi  to enumerate the available GPUs on your system  display  - the X display to use, e.g.  0 , which will set  DISPLAY  to  :0 . The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like  tightvnc  or  vncserver .  appendPosteriorMeanSample  -  true  or  false  specifying whether to chain the posterior mean sampling operation after the training is finished. The default is  false , but if you set this to  true , you won\u2019t need to call  writeShellScriptPosteriorMeanSample  below.  appendWriteModelParams  -  true  or  false  specifying whether to chain the posterior mean sampling operation after the training is finished. The default is  false , but if you set this to  true , you won\u2019t need to call  writeShellScriptWriteModelParams  below.   This will generate an  lfads_train.sh  in the corresponding run\u2019s folder. For the first run in our example, this is at ~/lorenz_example/runs/exampleRun/param_Qr2PeG/single_dataset001/lfads_train.sh  The script essentially launches Python to run  run_lfads.py  with the specific parameters you\u2019ve indicated in  RunParams  and pointing at the corresponding datasets, which were saved earlier when we called  rc.prepareForLFADS .  #!/bin/bash  path_to_run_lfads = $( which run_lfads.py )  if   [  ! -n  \" $path_to_run_lfads \"   ] ;   then \n     echo   \"Error: run_lfads.py not found on PATH. Ensure you add LFADS to your system PATH.\" \n     exit   1  fi  DISPLAY = :0  CUDA_VISIBLE_DEVICES = 0  python  $( which run_lfads.py )  --data_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsInput --data_filename_stem = lfads --lfads_save_dir = /home/djoshea/lorenz_example/runs/exampleSingleSession/param_YOs74u/single_dataset001/lfadsOutput --cell_clip_value = 5 .000000 --factors_dim = 8  --ic_enc_dim = 64  --ci_enc_dim = 128  --gen_dim = 64  --keep_prob = 0 .950000 --learning_rate_decay_factor = 0 .980000 --device = /gpu:0 --co_dim = 0  --do_causal_controller = false  --do_feed_factors_to_controller = true  --feedback_factors_or_rates = factors --controller_input_lag = 1  --do_train_readin = true  --l2_gen_scale = 500 .000000 --l2_con_scale = 500 .000000 --batch_size = 150  --kl_increase_steps = 900  --l2_increase_steps = 900  --ic_dim = 64  --con_dim = 128  --learning_rate_stop = 0 .001000 --temporal_spike_jitter_width = 0  --allow_gpu_growth = true  --kl_ic_weight = 1 .000000 --kl_co_weight = 1 .000000 --inject_ext_input_to_gen = false   Running the  lfads_train.sh  script will launch the Tensorflow training which will take some time. You likely want to launch this in a  tmux  session if running remotely.",
            "title": "Training the model"
        },
        {
            "location": "/running/#sampling-the-posterior-means",
            "text": "Next, generate the  lfads_posterior_mean_sample.sh  script to sample the posterior means, which can be launched after training has completed. If you set  appendPosteriorMeanSample  to  true  in  writeShellScriptLFADSTrain , you can skip this step.  rc . runs ( i ). writeShellScriptLFADSPosteriorMeanSample ( 'cuda_visible_devices' ,   0 );",
            "title": "Sampling the posterior means"
        },
        {
            "location": "/running/#writing-the-model-parameters",
            "text": "Lastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using  rc . runs ( i ). writeShellScriptWriteModelParams ( 'cuda_visible_devices' ,   0 );   If you set  appendWriteModelParams  to  true  in  writeShellScriptLFADSTrain , you can skip this step. These results will be written to a file called  lfadsOutput/model_params , though these results can be loaded into Matlab using  run.loadModelTrainedParams() .",
            "title": "Writing the model parameters"
        },
        {
            "location": "/running/#launching-tensorboard",
            "text": "You can monitor the progress of each run by generating a script that launches TensorBoard. rc . writeTensorboardShellScript ();   This will create  launch_tensorboard.sh  which will launch Tensorboard which can then be visited at  http://localhost:PORT .",
            "title": "Launching Tensorboard"
        },
        {
            "location": "/hyperparameters/",
            "text": "LFADS Hyperparameters\n\u00b6\n\n\nThe following is an nearly exhaustive list of hyperparameters that affect the training and posterior mean sampling of the model. If the parameter name begins with \nc_\n, this parameter will be passed to the LFADS Python code directly, without the \nc_\n prefix. All of these values are specified in the \nRunParams\n instance that accompanies each \nRun\n.\n\n\nWhile there are many parameters, you will likely care about only a small subset of them. We have color-coded the hyperparameters below according to how often they require tuning:\n\n\n\nth { font-weight: bold; }\ntr.hp-common td:first-child { background: #F44336; font-weight: bold; color: #ffffff; }\ntr.hp-medium td:first-child { background: #FFCDD2; }\ntr.hp-rare td:first-child { background: #ffffff; color: #455A64; }\n\ntbody.hp tr td:first-child { font-family: \"Roboto Mono\",\"Courier New\",Courier,monospace; }\n\n\n\n\n\n\n\n\n\nTuning Frequency\n\n\nDescription\n\n\n\n\n\n\n\n\nCommon\n\n\nTypically requires tuning on a per-project basis and/or is important to set appropriately upfront.\n\n\n\n\n\n\nOccasional\n\n\nMight be adjusted for fine tuning.\n\n\n\n\n\n\nRare\n\n\nInfrequently requires tuning and/r primarily intended for advanced users.\n\n\n\n\n\n\n\nRun Manager logistics and data Processing\n\u00b6\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\nname\n\n\n''\n\n\nName of this set of parameters, used for convenience only. \nNote that this parameter does not affect either the param or data hash.\n\n\n\n\n\n\n\nversion\n\n\nn/a\n\n\nThis value you should not assign directly\n, as it will automatically be set to match the version of the \nRunCollection\n to which it is added. This is used for graceful backwards compatibility. \nNote that this parameter does not affect either the param or data hash.\n\n\n\n\n\n\n\nspikeBinMs\n\n\n2\n\n\nSpike bin width in milliseconds. This must be an integer multiple of the original bin width provided by the `Run` class by `generateCountsForDataset`.\n\n\n\n\n\n\n\n\n\nTensorFlow logistics\n\u00b6\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\nc_allow_gpu_growth\n\n\ntrue\n\n\nAllow the GPU to dynamically allocate memory instead of allocating all the GPU's memory at the start\n\n\n\n\n\n\n\nc_max_ckpt_to_keep\n\n\n5\n\n\nMax number of checkpoints to keep (rolling)\n\n\n\n\n\n\n\nc_max_ckpt_to_keep_lve\n\n\n5\n\n\nMax number of checkpoints to keep for lowest validation error models (rolling)\n\n\n\n\n\n\n\nc_device\n\n\n'gpu:0'\n\n\nWhich visible GPU or CPU to use. Note that GPUs are typically scheduled by setting `CUDA_VISIBLE_DEVICES` rather than using this parameter.\n\n\n\n\n\n\n\n\n\nOptimization\n\u00b6\n\n\nRather put the learning rate on an exponentially decreasiong schedule,\nthe current algorithm pays attention to the learning rate, and if it\nisn\u2019t regularly decreasing, it will decrease the learning rate.  So far,\nit works fine, though it is not perfect.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_learning_rate_init\n\n\n0.01\n\n\nInitial learning rate\n\n\n\n\n\n\n\nc_learning_rate_decay_factor\n\n\n0.95\n\n\nFactor by which to decrease the learning rate if progress isn't being made.\n\n\n\n\n\n\n\nc_learning_rate_n_to_compare\n\n\n6\n\n\nNumber of previous costs current cost has to be worse than, in order to lower learning rate.\n\n\n\n\n\n\n\nc_learning_rate_stop\n\n\n0.00001\n\n\nStop training when the learning rate reaches this threshold.\n\n\n\n\n\n\n\nc_max_grad_norm\n\n\n200\n\n\nMax norm of gradient before clipping. This sets a value, above which, the gradients will be clipped.  This hp\nis extremely useful to avoid an infrequent, but highly pathological\nproblem whereby the gradient is so large that it destroys the\noptimization by setting parameters too large, leading to a vicious cycle\nthat ends in NaNs.  If it's too large, it's useless, if it's too small,\nit essentially becomes the learning rate. It's pretty insensitive, though.\n\n\n\n\n\n\n\ntrainToTestRatio\n\n\n4\n\n\nRatio of training vs testing trials used.\n\n\n\n\n\n\n\nc_batch_size\n\n\n256\n\n\nNumber of trials to use during each training pass. The total trial count must be \u2265 \nc_batch_size * (trainToTestRatio + 1)\n.\n\n\n\n\n\n\n\nc_cell_clip_value\n\n\n5\n\n\nMax value recurrent cell can take before being clipped. If your optimizations start \"NaN-ing out\", reduce this value so that the values of the network don't grow out of control.  Typically, once this parameter is set to a reasonable value, one stops having numerical problems.\n\n\n\n\n\n\n\n\n\n\nOverfitting\n\u00b6\n\n\nIf controller is heavily penalized, then it won\u2019t have any output. If dynamics are heavily penalized, then generator won\u2019t make dynamics.  Note this l2 penalty is only on the recurrent portion of the RNNs, as dropout is also available, penalizing the feed-forward connections.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_temporal_spike_jitter_width\n\n\n0\n\n\nEnables jittering spike times during training. It appears that the system will happily fit spikes (blessing or curse, depending).  You may not want this.  Jittering the spikes a bit may help (-/+ bin size, as specified here). The idea is to prevent LFADS from trying to learn very fine temporal structure in the data if you believe this to be noise.\n\n\n\n\n\n\n\nc_keep_prob\n\n\n0.95\n\n\nFraction of units to randomly drop during each training pass. Dropout is done on the input data, on controller inputs (from encoder), and on outputs from generator to factors.\n\n\n\n\n\n\n\nc_l2_gen_scale\n\n\n500\n\n\nL2 regularization cost for the generator only.\n\n\n\n\n\n\n\nc_l2_con_scale\n\n\n500\n\n\nL2 regularization cost for the controller only.\n\n\n\n\n\n\n\nc_co_mean_corr_scale\n\n\n0\n\n\nCost of correlation (through time) in the means of controller output.\n\n\n\n\n\n\n\n\n\n\nUnderfitting\n\u00b6\n\n\nIf the primary task of LFADS is \u201cfiltering\u201d of data and not\ngeneration, then it is possible that the KL penalty is too strong.\nEmpirically, we have found this to be the case.  So we add a\nhyperparameter in front of the the two KL terms (one for the initial\nconditions to the generator, the other for the controller outputs).\nYou should always think of the the default values as 1.0, and that\nleads to a standard VAE formulation whereby the numbers that are\noptimized are a lower-bound on the log-likelihood of the data. When\nthese 2 HPs deviate from 1.0, one cannot make any statement about\nwhat those LL lower bounds mean anymore, and they cannot be compared\n(AFAIK).\n\n\nSometimes the task can be sufficiently hard to learn that the\noptimizer takes the \u2018easy route\u2019, and simply minimizes the KL\ndivergence, setting it to near zero, and the optimization gets\nstuck. The same possibility is true for the L2 regularizer. One wants a simple generator, for scientific\nreasons, but not at the expense of hosing the optimization. The last 5 parameters help avoid that by by getting the\noptimization to \u2018latch\u2019 on to the main optimization, and only turning on the regularizers gradually by increasing their weighting in the overall cost functions later.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_kl_ic_weight\n\n\n1\n\n\nStrength of KL weight on initial conditions KL penalty.\n\n\n\n\n\n\n\nc_kl_co_weight\n\n\n1\n\n\nStrength of KL weight on controller output KL penalty.\n\n\n\n\n\n\n\nc_kl_start_step\n\n\n0\n\n\nStart increasing KL weight after this many steps.\n\n\n\n\n\n\n\nc_kl_increase_steps\n\n\n900\n\n\nNumber of steps over which the KL weight increases.\n\n\n\n\n\n\n\nc_l2_start_step\n\n\n0\n\n\nStart increasing L2 weight after this many steps.\n\n\n\n\n\n\n\nc_l2_increase_steps\n\n\n900\n\n\nNumber of steps over which the L2 weight increases.\n\n\n\n\n\n\n\nc_l2_start_step\n\n\n0\n\n\nStart increasing L2 weight after this many steps\n\n\n\n\n\n\n\nscaleIncreaseStepsWithDatasets\n\n\ntrue\n\n\nIf true, \nc_kl_increase_steps\n and \nc_l2_increase_steps\n will be multiplied by the number of datasets in a stitching run.\n\n\n\n\n\n\n\n\n\n\nExternal inputs\n\u00b6\n\n\nIf there are observed inputs, there are two ways to add that observed\ninput to the model.  The first is by treating as something to be\ninferred, and thus encoding the observed input via the encoders, and then\ninput to the generator via the \u201cinferred inputs\u201d channel.  Second, one\ncan input the input directly into the generator.  This has the downside\nof making the generation process strictly dependent on knowing the\nobserved input for any generated trial.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_ext_input_dim\n\n\n0\n\n\nNumber of external, known (or observed) inputs.\n\n\n\n\n\n\n\nc_inject_ext_input_to_gen\n\n\nfalse\n\n\nShould the known inputs be input to model via encoders (false) or injected directly into generator (true)?\n\n\n\n\n\n\n\n\n\n\nController and inferred inputs\n\u00b6\n\n\nThe controller will be more powerful if it can see the encoding of the entire\ntrial.  However, this allows the controller to create inferred inputs that are\nacausal with respect to the actual data generation process.  For example, the data\ngenerator could have an input at time \nt\n, but the controller, after seeing the\nentirety of the trial could infer that the input is coming a little before\ntime \nt\n, because there are no restrictions on the data the controller sees.\nOne can force the controller to be causal (with respect to perturbations in\nthe data generator) so that it only sees forward encodings of the data at time\n\nt\n that originate at times before or at time \nt\n.  One can also control the data\nthe controller sees by using an input lag (forward encoding at time \nt-tlag\n\nfor controller input at time \nt\n.  The same can be done in the reverse direction\n(controller input at time \nt\n from reverse encoding at time \nt+tlag\n, in the\ncase of an acausal controller).  Setting this lag > 0 (even lag=1) can be a\npowerful way of avoiding very spiky decodes. Finally, one can manually control\nwhether the factors at time \nt-1\n are fed to the controller at time \nt\n.\n\n\nIf you don\u2019t care about any of this, and just want to smooth your data, set\n\ndo_causal_controller = False\n, \ndo_feed_factors_to_controller = True\n, \ncontroller_input_lag = 0\n.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_co_dim\n\n\n4\n\n\nNumber of inferred inputs (controller outputs). This parameter critically controls whether or not there is a controller (along with controller encoders placed into the LFADS graph. If equal to 0, no controller will be added.\n\n\n\n\n\n\n\nc_prior_ar_atau\n\n\n10\n\n\nInitial autocorrelation of AR(1) priors (in time bins)\n\n\n\n\n\n\n\nc_do_train_prior_ar_atau\n\n\ntrue\n\n\nIs the value for atau an initial value (true) or the constant value (false)?\n\n\n\n\n\n\n\nc_prior_ar_nvar\n\n\n0.1\n\n\nInitial noise variance for AR(1) priors\n\n\n\n\n\n\n\nc_do_train_prior_ar_nvar\n\n\ntrue\n\n\nIs the value for the noise var an initial value (true) or the constant value (false)?\n\n\n\n\n\n\n\nc_do_causal_controller\n\n\nfalse\n\n\nRestrict input encoder from seeing the future?\n\n\n\n\n\n\n\nc_do_feed_factors_to_controller\n\n\ntrue\n\n\nShould \nfactors[t-1]\n be input to controller at time t? Strictly speaking, feeding either the factors or the rates to the controller violates causality, since the g0 gets to see all the data. This may or may not be only a theoretical concern.\n\n\n\n\n\n\n\nc_feedback_factors_or_rates\n\n\n'factors'\n\n\nFeedback the factors or the rates to the controller? Set to either \n'factors'\n or \n'rates'\n\n\n\n\n\n\n\nc_controller_input_lag\n\n\n1\n\n\nTime lag on the encoding to controller \nt-lag\n for forward, \nt+lag\n for reverse.\n\n\n\n\n\n\n\nc_ci_enc_dim\n\n\n128\n\n\nNetwork size for controller input encoder.\n\n\n\n\n\n\n\nc_con_dim\n\n\n128\n\n\nController dimensionality.\n\n\n\n\n\n\n\nc_co_prior_var_scale\n\n\n0.1\n\n\nVariance of control input prior distribution.\n\n\n\n\n\n\n\n\n\n\nEncoder and initial conditions for generator\n\u00b6\n\n\nNote that the dimension of the initial conditions is separated from the\ndimensions of the generator initial conditions (and a linear matrix will\nadapt the shapes if necessary).  This is just another way to control\ncomplexity.  In all likelihood, setting the IC dims to the size of the\ngenerator hidden state is just fine.\n\n\nFor the initial condition prior variance parameters, it\u2019s best to leave them alone.\nIThe defaults should be fine for most cases, irregardless of other parameters.\nIf you don\u2019t want the prior variance to be learned, set the\nfollowing values to the same thing: \nic_prior_var_min\n, \nic_prior_var_scale\n, \nic_prior_var_max\n.\nThe prior mean will still be learned. If you really want to limit the information from encoder to decoder,\nincrease \nic_post_var_min\n above 0.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_num_steps_for_gen_ic\n\n\nMAXINT\n\n\nNumber of steps to train the generator initial condition.\n\n\n\n\n\n\n\nc_ic_dim\n\n\n64\n\n\nDimensionality of the initial conditions.\n\n\n\n\n\n\n\nc_ic_enc_dim\n\n\n128\n\n\nNetwork size for IC encoder.\n\n\n\n\n\n\n\nc_ic_prior_var_min\n\n\n0.1\n\n\nMinimum variance of IC prior distribution\n\n\n\n\n\n\n\nc_ic_prior_var_scale\n\n\n0.1\n\n\nVariance of IC prior distribution\n\n\n\n\n\n\n\nc_ic_prior_var_max\n\n\n0.1\n\n\nMaximum variance of IC prior distribution\n\n\n\n\n\n\n\nc_ic_post_var_min\n\n\n0.0001\n\n\nMinimum variance of IC posterior distribution\n\n\n\n\n\n\n\n\n\n\nGenerator network, factors, rates\n\u00b6\n\n\nControlling the size of the generator is one way to control complexity of\nthe dynamics (there is also l2, which will squeeze out unnecessary\ndynamics also).  The modern deep learning approach is to make these cells\nas large as tolerable (from a waiting perspective), and then regularize\nthem to death with drop out or whatever. It is not clear if this is correct\nfor the LFADS application or not.\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_cell_weight_scale\n\n\n1.0\n\n\nInput scaling for input weights in generator. The combined recurrent and input weights of the encoder and controller cells are by default set to scale at ws/sqrt(#inputs) with ws=1.0.  You can change this scaling with this parameter.\n\n\n\n\n\n\n\nc_gen_dim\n\n\n100\n\n\nGenerator network size/td>\n\n\n\n\n\n\nc_gen_cell_input_weight_scale\n\n\n1.0\n\n\nInput scaling for input weights in generator, which will be divided by sqrt(#inputs)\n\n\n\n\n\n\n\nc_gen_cell_rec_weight_scale\n\n\n1.0\n\n\nInput scaling for recurrent weights in generator.\n\n\n\n\n\n\n\nc_factors_dim\n\n\n50\n\n\nDimensionality of factors read out from generator network. This provides dimensionality reduction from generator dimensionality down to factors and then back out to the neural rates. \nNote that this property does affect the data and param hashes, unlikely the other \nc_\n prefixed parameters, which only affect the param hash.\n\n\n\n\n\n\n\nc_output_dist\n\n\n'poisson'\n\n\nType of output distribution for rates, either \n'poisson'\n or \n'gaussian'\n\n\n\n\n\n\n\n\n\n\nStitching multi-session models\n\u00b6\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nc_do_train_readin\n\n\ntrue\n\n\nFor stitching models, make the readin matrices trainable (true) or fix them to equal the alignment matrices (false). The per-session readin matrices map from neurons to input factors which are fed into the shared encoder. These are initialized by the alignment matrices and can subsequently be fixed or made trainable.\n\n\n\n\n\n\n\nuseAlignmentMatrix\n\n\nfalse\n\n\nWhether to use an alignment matrix when stitching datasets together./td>\n\n\n\n\n\n\nuseSingleDatasetAlignmentMatrix\n\n\nfalse\n\n\nWhen only using a single dataset, it is also possible to use a readin matrix that reduces the dimensionality of the spikes before inputting these input factors to the encoder networks. If set true, this will set up this readin matrix and seed it with an alignment matrix computed using PCA.\n\n\n\n\n\n\n\n\n\n\nPosterior sampling\n\u00b6\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\nposterior_mean_kind\n\n\n'posterior_sample_and_average'\n\n\nMechanism to obtain the posterior mean. Either \n'posterior_sample_and_average'\n to take a specified number of samples from the posterior distribution, run them through the model, and average the results. Or \n'posterior_push_mean'\n to use the posterior mean of the ICs and inputs and push those through the model directly. Since there are nonlinearities in the network, this need not be equivalent to the mean of the samples, but in practice it's usually pretty close, and is much faster to compute. \nNote that this parameter does not affect either the param or data hash.\n\n\n\n\n\n\n\nnum_samples_posterior\n\n\n512\n\n\nNumber of samples of the posterior to use when using \n'posterior_sample_and_average'\n. \nNote that this parameter does not affect either the param or data hash.",
            "title": "Hyperparameters"
        },
        {
            "location": "/hyperparameters/#lfads-hyperparameters",
            "text": "The following is an nearly exhaustive list of hyperparameters that affect the training and posterior mean sampling of the model. If the parameter name begins with  c_ , this parameter will be passed to the LFADS Python code directly, without the  c_  prefix. All of these values are specified in the  RunParams  instance that accompanies each  Run .  While there are many parameters, you will likely care about only a small subset of them. We have color-coded the hyperparameters below according to how often they require tuning:  \nth { font-weight: bold; }\ntr.hp-common td:first-child { background: #F44336; font-weight: bold; color: #ffffff; }\ntr.hp-medium td:first-child { background: #FFCDD2; }\ntr.hp-rare td:first-child { background: #ffffff; color: #455A64; }\n\ntbody.hp tr td:first-child { font-family: \"Roboto Mono\",\"Courier New\",Courier,monospace; }    Tuning Frequency  Description     Common  Typically requires tuning on a per-project basis and/or is important to set appropriately upfront.    Occasional  Might be adjusted for fine tuning.    Rare  Infrequently requires tuning and/r primarily intended for advanced users.",
            "title": "LFADS Hyperparameters"
        },
        {
            "location": "/hyperparameters/#run-manager-logistics-and-data-processing",
            "text": "Name  Default  Description     name  ''  Name of this set of parameters, used for convenience only.  Note that this parameter does not affect either the param or data hash.    version  n/a  This value you should not assign directly , as it will automatically be set to match the version of the  RunCollection  to which it is added. This is used for graceful backwards compatibility.  Note that this parameter does not affect either the param or data hash.    spikeBinMs  2  Spike bin width in milliseconds. This must be an integer multiple of the original bin width provided by the `Run` class by `generateCountsForDataset`.",
            "title": "Run Manager logistics and data Processing"
        },
        {
            "location": "/hyperparameters/#tensorflow-logistics",
            "text": "Name  Default  Description     c_allow_gpu_growth  true  Allow the GPU to dynamically allocate memory instead of allocating all the GPU's memory at the start    c_max_ckpt_to_keep  5  Max number of checkpoints to keep (rolling)    c_max_ckpt_to_keep_lve  5  Max number of checkpoints to keep for lowest validation error models (rolling)    c_device  'gpu:0'  Which visible GPU or CPU to use. Note that GPUs are typically scheduled by setting `CUDA_VISIBLE_DEVICES` rather than using this parameter.",
            "title": "TensorFlow logistics"
        },
        {
            "location": "/hyperparameters/#optimization",
            "text": "Rather put the learning rate on an exponentially decreasiong schedule,\nthe current algorithm pays attention to the learning rate, and if it\nisn\u2019t regularly decreasing, it will decrease the learning rate.  So far,\nit works fine, though it is not perfect.    Name  Default  Description     c_learning_rate_init  0.01  Initial learning rate    c_learning_rate_decay_factor  0.95  Factor by which to decrease the learning rate if progress isn't being made.    c_learning_rate_n_to_compare  6  Number of previous costs current cost has to be worse than, in order to lower learning rate.    c_learning_rate_stop  0.00001  Stop training when the learning rate reaches this threshold.    c_max_grad_norm  200  Max norm of gradient before clipping. This sets a value, above which, the gradients will be clipped.  This hp\nis extremely useful to avoid an infrequent, but highly pathological\nproblem whereby the gradient is so large that it destroys the\noptimization by setting parameters too large, leading to a vicious cycle\nthat ends in NaNs.  If it's too large, it's useless, if it's too small,\nit essentially becomes the learning rate. It's pretty insensitive, though.    trainToTestRatio  4  Ratio of training vs testing trials used.    c_batch_size  256  Number of trials to use during each training pass. The total trial count must be \u2265  c_batch_size * (trainToTestRatio + 1) .    c_cell_clip_value  5  Max value recurrent cell can take before being clipped. If your optimizations start \"NaN-ing out\", reduce this value so that the values of the network don't grow out of control.  Typically, once this parameter is set to a reasonable value, one stops having numerical problems.",
            "title": "Optimization"
        },
        {
            "location": "/hyperparameters/#overfitting",
            "text": "If controller is heavily penalized, then it won\u2019t have any output. If dynamics are heavily penalized, then generator won\u2019t make dynamics.  Note this l2 penalty is only on the recurrent portion of the RNNs, as dropout is also available, penalizing the feed-forward connections.    Name  Default  Description     c_temporal_spike_jitter_width  0  Enables jittering spike times during training. It appears that the system will happily fit spikes (blessing or curse, depending).  You may not want this.  Jittering the spikes a bit may help (-/+ bin size, as specified here). The idea is to prevent LFADS from trying to learn very fine temporal structure in the data if you believe this to be noise.    c_keep_prob  0.95  Fraction of units to randomly drop during each training pass. Dropout is done on the input data, on controller inputs (from encoder), and on outputs from generator to factors.    c_l2_gen_scale  500  L2 regularization cost for the generator only.    c_l2_con_scale  500  L2 regularization cost for the controller only.    c_co_mean_corr_scale  0  Cost of correlation (through time) in the means of controller output.",
            "title": "Overfitting"
        },
        {
            "location": "/hyperparameters/#underfitting",
            "text": "If the primary task of LFADS is \u201cfiltering\u201d of data and not\ngeneration, then it is possible that the KL penalty is too strong.\nEmpirically, we have found this to be the case.  So we add a\nhyperparameter in front of the the two KL terms (one for the initial\nconditions to the generator, the other for the controller outputs).\nYou should always think of the the default values as 1.0, and that\nleads to a standard VAE formulation whereby the numbers that are\noptimized are a lower-bound on the log-likelihood of the data. When\nthese 2 HPs deviate from 1.0, one cannot make any statement about\nwhat those LL lower bounds mean anymore, and they cannot be compared\n(AFAIK).  Sometimes the task can be sufficiently hard to learn that the\noptimizer takes the \u2018easy route\u2019, and simply minimizes the KL\ndivergence, setting it to near zero, and the optimization gets\nstuck. The same possibility is true for the L2 regularizer. One wants a simple generator, for scientific\nreasons, but not at the expense of hosing the optimization. The last 5 parameters help avoid that by by getting the\noptimization to \u2018latch\u2019 on to the main optimization, and only turning on the regularizers gradually by increasing their weighting in the overall cost functions later.    Name  Default  Description     c_kl_ic_weight  1  Strength of KL weight on initial conditions KL penalty.    c_kl_co_weight  1  Strength of KL weight on controller output KL penalty.    c_kl_start_step  0  Start increasing KL weight after this many steps.    c_kl_increase_steps  900  Number of steps over which the KL weight increases.    c_l2_start_step  0  Start increasing L2 weight after this many steps.    c_l2_increase_steps  900  Number of steps over which the L2 weight increases.    c_l2_start_step  0  Start increasing L2 weight after this many steps    scaleIncreaseStepsWithDatasets  true  If true,  c_kl_increase_steps  and  c_l2_increase_steps  will be multiplied by the number of datasets in a stitching run.",
            "title": "Underfitting"
        },
        {
            "location": "/hyperparameters/#external-inputs",
            "text": "If there are observed inputs, there are two ways to add that observed\ninput to the model.  The first is by treating as something to be\ninferred, and thus encoding the observed input via the encoders, and then\ninput to the generator via the \u201cinferred inputs\u201d channel.  Second, one\ncan input the input directly into the generator.  This has the downside\nof making the generation process strictly dependent on knowing the\nobserved input for any generated trial.    Name  Default  Description     c_ext_input_dim  0  Number of external, known (or observed) inputs.    c_inject_ext_input_to_gen  false  Should the known inputs be input to model via encoders (false) or injected directly into generator (true)?",
            "title": "External inputs"
        },
        {
            "location": "/hyperparameters/#controller-and-inferred-inputs",
            "text": "The controller will be more powerful if it can see the encoding of the entire\ntrial.  However, this allows the controller to create inferred inputs that are\nacausal with respect to the actual data generation process.  For example, the data\ngenerator could have an input at time  t , but the controller, after seeing the\nentirety of the trial could infer that the input is coming a little before\ntime  t , because there are no restrictions on the data the controller sees.\nOne can force the controller to be causal (with respect to perturbations in\nthe data generator) so that it only sees forward encodings of the data at time t  that originate at times before or at time  t .  One can also control the data\nthe controller sees by using an input lag (forward encoding at time  t-tlag \nfor controller input at time  t .  The same can be done in the reverse direction\n(controller input at time  t  from reverse encoding at time  t+tlag , in the\ncase of an acausal controller).  Setting this lag > 0 (even lag=1) can be a\npowerful way of avoiding very spiky decodes. Finally, one can manually control\nwhether the factors at time  t-1  are fed to the controller at time  t .  If you don\u2019t care about any of this, and just want to smooth your data, set do_causal_controller = False ,  do_feed_factors_to_controller = True ,  controller_input_lag = 0 .    Name  Default  Description     c_co_dim  4  Number of inferred inputs (controller outputs). This parameter critically controls whether or not there is a controller (along with controller encoders placed into the LFADS graph. If equal to 0, no controller will be added.    c_prior_ar_atau  10  Initial autocorrelation of AR(1) priors (in time bins)    c_do_train_prior_ar_atau  true  Is the value for atau an initial value (true) or the constant value (false)?    c_prior_ar_nvar  0.1  Initial noise variance for AR(1) priors    c_do_train_prior_ar_nvar  true  Is the value for the noise var an initial value (true) or the constant value (false)?    c_do_causal_controller  false  Restrict input encoder from seeing the future?    c_do_feed_factors_to_controller  true  Should  factors[t-1]  be input to controller at time t? Strictly speaking, feeding either the factors or the rates to the controller violates causality, since the g0 gets to see all the data. This may or may not be only a theoretical concern.    c_feedback_factors_or_rates  'factors'  Feedback the factors or the rates to the controller? Set to either  'factors'  or  'rates'    c_controller_input_lag  1  Time lag on the encoding to controller  t-lag  for forward,  t+lag  for reverse.    c_ci_enc_dim  128  Network size for controller input encoder.    c_con_dim  128  Controller dimensionality.    c_co_prior_var_scale  0.1  Variance of control input prior distribution.",
            "title": "Controller and inferred inputs"
        },
        {
            "location": "/hyperparameters/#encoder-and-initial-conditions-for-generator",
            "text": "Note that the dimension of the initial conditions is separated from the\ndimensions of the generator initial conditions (and a linear matrix will\nadapt the shapes if necessary).  This is just another way to control\ncomplexity.  In all likelihood, setting the IC dims to the size of the\ngenerator hidden state is just fine.  For the initial condition prior variance parameters, it\u2019s best to leave them alone.\nIThe defaults should be fine for most cases, irregardless of other parameters.\nIf you don\u2019t want the prior variance to be learned, set the\nfollowing values to the same thing:  ic_prior_var_min ,  ic_prior_var_scale ,  ic_prior_var_max .\nThe prior mean will still be learned. If you really want to limit the information from encoder to decoder,\nincrease  ic_post_var_min  above 0.    Name  Default  Description     c_num_steps_for_gen_ic  MAXINT  Number of steps to train the generator initial condition.    c_ic_dim  64  Dimensionality of the initial conditions.    c_ic_enc_dim  128  Network size for IC encoder.    c_ic_prior_var_min  0.1  Minimum variance of IC prior distribution    c_ic_prior_var_scale  0.1  Variance of IC prior distribution    c_ic_prior_var_max  0.1  Maximum variance of IC prior distribution    c_ic_post_var_min  0.0001  Minimum variance of IC posterior distribution",
            "title": "Encoder and initial conditions for generator"
        },
        {
            "location": "/hyperparameters/#generator-network-factors-rates",
            "text": "Controlling the size of the generator is one way to control complexity of\nthe dynamics (there is also l2, which will squeeze out unnecessary\ndynamics also).  The modern deep learning approach is to make these cells\nas large as tolerable (from a waiting perspective), and then regularize\nthem to death with drop out or whatever. It is not clear if this is correct\nfor the LFADS application or not.    Name  Default  Description     c_cell_weight_scale  1.0  Input scaling for input weights in generator. The combined recurrent and input weights of the encoder and controller cells are by default set to scale at ws/sqrt(#inputs) with ws=1.0.  You can change this scaling with this parameter.    c_gen_dim  100  Generator network size/td>   c_gen_cell_input_weight_scale  1.0  Input scaling for input weights in generator, which will be divided by sqrt(#inputs)    c_gen_cell_rec_weight_scale  1.0  Input scaling for recurrent weights in generator.    c_factors_dim  50  Dimensionality of factors read out from generator network. This provides dimensionality reduction from generator dimensionality down to factors and then back out to the neural rates.  Note that this property does affect the data and param hashes, unlikely the other  c_  prefixed parameters, which only affect the param hash.    c_output_dist  'poisson'  Type of output distribution for rates, either  'poisson'  or  'gaussian'",
            "title": "Generator network, factors, rates"
        },
        {
            "location": "/hyperparameters/#stitching-multi-session-models",
            "text": "Name  Default  Description     c_do_train_readin  true  For stitching models, make the readin matrices trainable (true) or fix them to equal the alignment matrices (false). The per-session readin matrices map from neurons to input factors which are fed into the shared encoder. These are initialized by the alignment matrices and can subsequently be fixed or made trainable.    useAlignmentMatrix  false  Whether to use an alignment matrix when stitching datasets together./td>   useSingleDatasetAlignmentMatrix  false  When only using a single dataset, it is also possible to use a readin matrix that reduces the dimensionality of the spikes before inputting these input factors to the encoder networks. If set true, this will set up this readin matrix and seed it with an alignment matrix computed using PCA.",
            "title": "Stitching multi-session models"
        },
        {
            "location": "/hyperparameters/#posterior-sampling",
            "text": "Name  Default  Description     posterior_mean_kind  'posterior_sample_and_average'  Mechanism to obtain the posterior mean. Either  'posterior_sample_and_average'  to take a specified number of samples from the posterior distribution, run them through the model, and average the results. Or  'posterior_push_mean'  to use the posterior mean of the ICs and inputs and push those through the model directly. Since there are nonlinearities in the network, this need not be equivalent to the mean of the samples, but in practice it's usually pretty close, and is much faster to compute.  Note that this parameter does not affect either the param or data hash.    num_samples_posterior  512  Number of samples of the posterior to use when using  'posterior_sample_and_average' .  Note that this parameter does not affect either the param or data hash.",
            "title": "Posterior sampling"
        },
        {
            "location": "/multisession/",
            "text": "Multi-dataset Stitching Models\n\u00b6\n\n\nIf you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a \nRunSpec\n, the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through \nread-in\n and \nreadout\n alignment matrices.\n\n\nBelow is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset.\n\n\n\n\nA similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial.\n\n\nGenerating alignment matrices\n\u00b6\n\n\nThese read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a \nRunSpec\n, and the hyperparameter \nuseAlignmentMatrix\n is set to \ntrue\n in the \nRunParams\n, then \nlfads-run-manager\n will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as:\n\n\n\n\nGenerate condition-averaged firing rates for each neuron for each condition for each dataset\n\n\nConcatenate all of neurons from all datasets together to build a matrix which is (\nnTime * nConditions\n) \nnNeuronsTotal\n\n\nPerform PCA on this matrix and keep the projections of the data into the top \nnFactors\n components. These represent the global shared structure of the data across all datasets.\n\n\nFor each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix.\n\n\n\n\nThese matrices will be computed for you automatically by \nrun.prepareForLFADS()\n and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by \nlfads-run-manager\n.\n\n\n\n\nAlignment biases\n\n\nIn addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts before projecting through the matrix. Consequently, \nlfads-run-manager\n seeds this bias with the negative mean of the rates of each neuron.\n\n\n\n\nSetting up a multi-session LFADS run\n\u00b6\n\n\nAssuming you have finished reading through the \nsingle-dataset LFADS walkthrough\n, you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up another \ndrive script\n that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling \nLFADS Run Manager\n to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as \nLorenzExperiment\n, but you should substitute this with your package name.\n\n\n\n\nFollow along with \nLorenzExperiment.drive_script\n\n\nA complete drive script is available as a starting point in \n+LorenzExperiment/drive_script.m\n for you to copy/paste from.\n\n\n\n\nFor this demo, as before, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code:\n\n\ndatasetPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\nLFADS\n.\nUtils\n.\ngenerateDemoDatasets\n(\ndatasetPath\n,\n \n'nDatasets'\n,\n \n3\n);\n\n\n\n\n\nThis will simulate a chaotic 3 dimensional \nLorenz attractor\n as the underlying dynamical system, initialized from 65 initial conditions. The key in these demonstration datasets is that the 65 conditions start from the same initial state and evolve identically across all 3 datasets. Each dataset, however, contains a disjoint set of neurons that are each a different linear recombination of the 3 dimensions of the Lorenz attractor state. This is analogous to the assumption we make in LFADS stitching\u2013each dataset contains different sets of neurons, which are reconstructed from a shared low-dimensional set of factors.\n\n\nBuilding a dataset collection and adding datasets\n\u00b6\n\n\nFirst, create a dataset collection that points to a folder on disk where datasets are stored:\n\n\ndataPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\ndc\n \n=\n \nLorenzExperiment\n.\nDatasetCollection\n(\ndataPath\n);\n\n\ndc\n.\nname\n \n=\n \n'lorenz_example'\n;\n\n\n\n\n\nThen, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the \nDatasetCollection\n and will replace any dataset that has the same name if present.\n\n\nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset002.mat'\n);\n\n\nLorenzExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset003.mat'\n);\n\n\n\n\n\nYou can verify that the datasets have been added to the collection:\n\n\n>>\n \ndc\n\n\nLorenzExperiment\n.\nDatasetCollection\n \"\nlorenz_example\n\"\n  \n3\n \ndatasets\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \n[\n \n1\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset001\n\"\n  \n[\n \n2\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset002\n\"\n  \n[\n \n3\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset003\n\"\n\n            \nname\n:\n \n'lorenz_example'\n\n         \ncomment\n:\n \n''\n\n            \npath\n:\n \n'~/lorenz_example/datasets'\n\n        \ndatasets\n:\n \n[\n3\nx1\n \nLorenzExperiment\n.\nDataset\n]\n\n       \nnDatasets\n:\n \n3\n\n    \ndatasetNames\n:\n \n{\n3\nx1\n \ncell\n}\n\n\n\n\n\nYou can access individual datasets using \ndc\n.\ndatasets\n(\n1\n)\n or by name with \ndc\n.\nmatchDatasetsByName\n(\n'dataset001'\n)\n.\n\n\nYou can then load all of the metadata for the datasets using:\n\ndc\n.\nloadInfo\n();\n\n\n\n\nHow this metadata is determined for each dataset may be customized as described in \nInterfacing with your Datasets\n. You can view a summary of the metadata using:\n\n\n>>\n \ndc\n.\ngetDatasetInfoTable\n          \n\n                  \nsubject\n                  \ndate\n             \nsaveTags\n    \nnTrials\n    \nnChannels\n\n              \n________________\n    \n______________________\n    \n________\n    \n_______\n    \n_________\n\n\ndataset001\n    \n'lorenz_example'\n    \n[\n31\n-\nJan\n-\n2018\n \n00\n:\n00\n:\n00\n]\n      \n'1'\n        \n1820\n         \n35\n    \n\ndataset002\n    \n'lorenz_example'\n    \n[\n31\n-\nJan\n-\n2018\n \n00\n:\n00\n:\n00\n]\n      \n'1'\n        \n1885\n         \n26\n    \n\ndataset003\n    \n'lorenz_example'\n    \n[\n31\n-\nJan\n-\n2018\n \n00\n:\n00\n:\n00\n]\n      \n'1'\n        \n1365\n         \n35\n    \n\n\n\n\nCreate a \nRunCollection\n\u00b6\n\n\nWe\u2019ll now setup a \nRunCollection\n that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.\n\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nLorenzExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleStitching'\n,\n \ndc\n);\n\n\n\n% replace with approximate date script authored as YYYYMMDD\n\n\n% to ensure forwards compatibility\n\n\nrc\n.\nversion\n \n=\n \n20180131\n;\n\n\n\n\n\nSpecify the hyperparameters in \nRunParams\n\u00b6\n\n\nWe\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. The key change we\u2019ll make is to set \nuseAlignmentMatrix\n to \ntrue\n in order to seed the read-in matrices.\n\n\npar\n \n=\n \nLorenzExperiment\n.\nRunParams\n;\n\n\npar\n.\nname\n \n=\n \n'first_attempt_stitching'\n;\n \n% completely optional\n\n\npar\n.\nuseAlignmentMatrix\n \n=\n \ntrue\n;\n \n% use alignment matrices initial guess for multisession stitching\n\n\n\npar\n.\nspikeBinMs\n \n=\n \n2\n;\n \n% rebin the data at 2 ms\n\n\npar\n.\nc_co_dim\n \n=\n \n0\n;\n \n% no controller --> no inputs to generator\n\n\npar\n.\nc_batch_size\n \n=\n \n150\n;\n \n% must be < 1/5 of the min trial count\n\n\npar\n.\nc_factors_dim\n \n=\n \n8\n;\n \n% and manually set it for multisession stitched models\n\n\npar\n.\nc_gen_dim\n \n=\n \n64\n;\n \n% number of units in generator RNN\n\n\npar\n.\nc_ic_enc_dim\n \n=\n \n64\n;\n \n% number of units in encoder RNN\n\n\npar\n.\nc_learning_rate_stop\n \n=\n \n1e-3\n;\n \n% we can stop really early for the demo\n\n\n\n\n\nWe then add this \nRunParams\n to the \nRunCollection\n:\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\n\n\n\nYou can access the parameter settings added to \nrc\n using \nrc.params\n, which will be an array of \nRunParams\n instances.\n\n\nSpecify the \nRunSpec\n set\n\u00b6\n\n\nRecall that \nRunSpec\n instances specify which datasets are included in a specific run. For stitching, we\u2019ll want to include all three datasets into a single model.\n\n\n% include all datasets\n\n\nrunSpecName\n \n=\n \n'all'\n;\n\n\nrunSpec\n \n=\n \nLorenzExperiment\n.\nRunSpec\n(\nrunSpecName\n,\n \ndc\n,\n \n1\n:\ndc\n.\nnDatasets\n);\n\n\nrc\n.\naddRunSpec\n(\nrunSpec\n);\n\n\n\n\n\nYou can adjust the arguments to the constructor of \nLorenzExperiment.RunSpec\n, but in the example provided the inputs define:\n\n\n\n\nthe unique name of the run. Here we use \ngetSingleRunName\n, a convenience method of \nDataset\n that generates a name like \nsingle_datasetName\n.\n\n\nthe \nDatasetCollection\n from which datasets will be retrieved\n\n\nthe indices or names of datasets (as a string or cell array of strings) to include\n\n\n\n\nIf you like you can also add RunSpecs to train individual models for each dataset as well to facilitate comparison.\n\n\n% add one run for each single dataset\n\n\nfor\n \niR\n \n=\n \n1\n:\ndc\n.\nnDatasets\n\n    \nrunSpecName\n \n=\n \ndc\n.\ndatasets\n(\niR\n).\ngetSingleRunName\n();\n \n% 'single_dataset###'\n\n    \nrunSpec\n \n=\n \nLorenzExperiment\n.\nRunSpec\n(\nrunSpecName\n,\n \ndc\n,\n \niR\n);\n\n    \nrc\n.\naddRunSpec\n(\nrunSpec\n);\n\n\nend\n\n\n\n\n\nCheck the \nRunCollection\n and the \nRun\n\u00b6\n\n\nThe \nRunCollection\n will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total.\n\n\n>>\n \nrc\n\n\n\nLorenzExperiment\n.\nRunCollection\n \"\nexampleStitching\n\" \n(\n1\n \nruns\n \ntotal\n)\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n3\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleStitching\n\n\n  \n1\n \nparameter\n \nsettings\n\n  \n[\n1\n \nparam_Qr2PeG\n \ndata_RE1kuL\n]\n \nLorenzExperiment\n.\nRunParams\n \"\nfirst_attempt_stitching\n\" \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n  \n1\n \nrun\n \nspecifications\n\n  \n[\n \n1\n]\n \nLorenzExperiment\n.\nRunSpec\n \"\nall\n\" \n(\n3\n \ndatasets\n)\n\n\n                          \nname\n:\n \n'exampleStitching'\n\n                       \ncomment\n:\n \n''\n\n                      \nrootPath\n:\n \n'~/lorenz_example/runs'\n\n                       \nversion\n:\n \n201801\n\n             \ndatasetCollection\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nDatasetCollection\n]\n\n                          \nruns\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRun\n]\n\n                        \nparams\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRunParams\n]\n\n                      \nrunSpecs\n:\n \n[\n1\nx1\n \nLorenzExperiment\n.\nRunSpec\n]\n\n                       \nnParams\n:\n \n1\n\n                     \nnRunSpecs\n:\n \n1\n\n                    \nnRunsTotal\n:\n \n1\n\n                     \nnDatasets\n:\n \n3\n\n                  \ndatasetNames\n:\n \n{\n3\nx1\n \ncell\n}\n\n                          \npath\n:\n \n'~/lorenz_example/runs/exampleStitching'\n\n      \npathsCommonDataForParams\n:\n \n{\n'~/lorenz_example/runs/exampleStitching/data_RE1kuL'\n}\n\n                \npathsForParams\n:\n \n{\n'~/lorenz_example/runs/exampleStitching/param_Qr2PeG'\n}\n\n    \nfileShellScriptTensorboard\n:\n \n'~/lorenz_example/runs/exampleStitching/launch_tensorboard.sh'\n\n               \nfileSummaryText\n:\n \n'~/lorenz_example/runs/exampleStitching/summary.txt'\n\n       \nfileShellScriptRunQueue\n:\n \n'~/lorenz_example/runs/exampleStitching/run_lfadsqueue.py'\n\n\n\n>>\n \nrun\n \n=\n \nrc\n.\nfindRuns\n(\n'all'\n,\n \n1\n);\n\n\n\nLorenzExperiment\n.\nRun\n \"\nall\n\" \n(\n3\n \ndatasets\n)\n\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleStitching\n/\nparam_Qr2PeG\n/\nall\n\n  \nData\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleStitching\n/\ndata_RE1kuL\n\n  \nLorenzExperiment\n.\nRunParams\n \"\nfirst_attempt_stitching\n\" \n:\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n  \n3\n \ndatasets\n \nin\n \"\nlorenz_example\n\"\n    \n[\n \n1\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset001\n\"\n    \n[\n \n2\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset002\n\"\n    \n[\n \n3\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset003\n\"\n\n\n...\n\n\n\n\n\nVerifying the alignment matrices\n\u00b6\n\n\nNext, we\u2019ll run the principal components regression that generates the alignment matrices using the algorithm described \nabove\n. Then we\u2019ll verify that these matrices are able to project the data from each dataset into similar looking low-dimensional trajectories.\n\n\nTo visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset.\n\n\nrun\n.\ndoMultisessionAlignment\n();\n\n\n\n\n\nUnder the hood, the alignment matrix calculations are performed by an instance of \nLFADS.MutlisessionAlignmentTool\n. To plot the reconstruction quality, you can call \ntool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot)\n, like so:\n\n\ntool\n \n=\n \nrun\n.\nmultisessionAlignmentTool\n;\n\n\n\nnFactorsPlot\n \n=\n \n3\n;\n\n\nconditionsToPlot\n \n=\n \n[\n1\n \n20\n \n40\n];\n\n\ntool\n.\nplotAlignmentReconstruction\n(\nnFactorsPlot\n,\n \nconditionsToPlot\n);\n\n\n\n\n\n\n\nIn this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance.\n\n\nThe actual alignment matrices can be accessed using:\n\ntool\n.\nalignmentMatrices\n \n% nDatasets x 1 cell array of read-in matrices\n\n\n\n\nPrepare for LFADS\n\u00b6\n\n\nNow that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.\n\n\nrc\n.\nprepareForLFADS\n();\n\n\n\n\n\nThis will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call \nprepareForLFADS\n again. Existing files won\u2019t be overwritten unless you call \nrc.prepareForLFADS(true)\n.\n\n\nAfter running \nprepareForLFADS\n, the run manager will create the following files on disk under \nrc.path\n:\n\n\n~/lorenz_example/runs/exampleStitching\n\u251c\u2500\u2500 data_4MaTKO\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n\u251c\u2500\u2500 param_YOs74u\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 all\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_4MaTKO/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_4MaTKO/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/lfads_dataset001.h5\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_4MaTKO/lfads_dataset002.h5\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_4MaTKO/lfads_dataset003.h5\n\u2514\u2500\u2500 summary.txt\n\n\n\n\nThe organization of these files on disk is discussed in more detail \nhere\n. Also, a \nsummary.txt\n file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling \nrc.generateSummaryText()\n.\n\n\nLorenzExperiment\n.\nRunCollection\n \"\nexampleStitching2\n\" \n(\n1\n \nruns\n \ntotal\n)\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleStitching2\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n3\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n\n  \n------------------------\n\n\n  \n1\n \nRun\n \nSpecifications\n:\n\n\n    \n[\nrunSpec\n \n1\n]\n \nLorenzExperiment\n.\nRunSpec\n \"\nall\n\" \n(\n3\n \ndatasets\n)\n\n      \n[\nds\n \n1\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset001\n\"\n      \n[\nds\n \n2\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset002\n\"\n      \n[\nds\n \n3\n]\n \nLorenzExperiment\n.\nDataset\n \"\ndataset003\n\"\n\n  \n------------------------\n\n\n  \n1\n \nParameter\n \nSettings\n:\n\n\n    \n[\n1\n \nparam_Qr2PeG\n \ndata_RE1kuL\n]\n \nLorenzExperiment\n.\nRunParams\n \"\nfirst_attempt_stitching\n\"\n      \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n      \nspikeBinMs\n:\n \n2\n\n      \ntrainToTestRatio\n:\n \n4\n\n      \nuseAlignmentMatrix\n:\n \ntrue\n\n      \nuseSingleDatasetAlignmentMatrix\n:\n \nfalse\n\n      \nscaleIncreaseStepsWithDatasets\n:\n \ntrue\n\n      \nc_cell_clip_value\n:\n \n5\n\n      \nc_factors_dim\n:\n \n8\n\n      \nc_ic_enc_dim\n:\n \n64\n\n      \nc_ci_enc_dim\n:\n \n128\n\n      \nc_gen_dim\n:\n \n64\n\n      \nc_keep_prob\n:\n \n0.95\n\n      \nc_learning_rate_decay_factor\n:\n \n0.98\n\n      \nc_device\n:\n \n/\ngpu\n:\n0\n\n      \nc_co_dim\n:\n \n0\n\n      \nc_do_causal_controller\n:\n \nfalse\n\n      \nc_do_feed_factors_to_controller\n:\n \ntrue\n\n      \nc_feedback_factors_or_rates\n:\n \nfactors\n\n      \nc_controller_input_lag\n:\n \n1\n\n      \nc_do_train_readin\n:\n \ntrue\n\n      \nc_l2_gen_scale\n:\n \n500\n\n      \nc_l2_con_scale\n:\n \n500\n\n      \nc_batch_size\n:\n \n150\n\n      \nc_kl_increase_steps\n:\n \n900\n\n      \nc_l2_increase_steps\n:\n \n900\n\n      \nc_ic_dim\n:\n \n64\n\n      \nc_con_dim\n:\n \n128\n\n      \nc_learning_rate_stop\n:\n \n0.001\n\n      \nc_temporal_spike_jitter_width\n:\n \n0\n\n      \nc_allow_gpu_growth\n:\n \ntrue\n\n      \nc_kl_ic_weight\n:\n \n1\n\n      \nc_kl_co_weight\n:\n \n1\n\n      \nc_inject_ext_input_to_gen\n:\n \nfalse\n\n      \nc_prior_ar_atau\n:\n \n10\n\n      \nc_do_train_prior_ar_atau\n:\n \ntrue\n\n      \nc_prior_ar_nvar\n:\n \n0.1\n\n      \nc_do_train_prior_ar_nvar\n:\n \ntrue\n\n      \nnum_samples_posterior\n:\n \n512\n\n      \nposterior_mean_kind\n:\n \nposterior_sample_and_average\n\n\n\n\n\nAfter running \nprepareForLFADS\n, you can then run the LFADS model or models in the same way as with single-session models, using the instructions \nhere\n.",
            "title": "Multisession Stitched Models"
        },
        {
            "location": "/multisession/#multi-dataset-stitching-models",
            "text": "If you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a  RunSpec , the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through  read-in  and  readout  alignment matrices.  Below is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset.   A similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial.",
            "title": "Multi-dataset Stitching Models"
        },
        {
            "location": "/multisession/#generating-alignment-matrices",
            "text": "These read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a  RunSpec , and the hyperparameter  useAlignmentMatrix  is set to  true  in the  RunParams , then  lfads-run-manager  will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as:   Generate condition-averaged firing rates for each neuron for each condition for each dataset  Concatenate all of neurons from all datasets together to build a matrix which is ( nTime * nConditions )  nNeuronsTotal  Perform PCA on this matrix and keep the projections of the data into the top  nFactors  components. These represent the global shared structure of the data across all datasets.  For each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix.   These matrices will be computed for you automatically by  run.prepareForLFADS()  and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by  lfads-run-manager .   Alignment biases  In addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts before projecting through the matrix. Consequently,  lfads-run-manager  seeds this bias with the negative mean of the rates of each neuron.",
            "title": "Generating alignment matrices"
        },
        {
            "location": "/multisession/#setting-up-a-multi-session-lfads-run",
            "text": "Assuming you have finished reading through the  single-dataset LFADS walkthrough , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up another  drive script  that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling  LFADS Run Manager  to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as  LorenzExperiment , but you should substitute this with your package name.   Follow along with  LorenzExperiment.drive_script  A complete drive script is available as a starting point in  +LorenzExperiment/drive_script.m  for you to copy/paste from.   For this demo, as before, we\u2019ll generate a few datasets of synthetic spiking data generated by a Lorenz attractor using the following code:  datasetPath   =   '~/lorenz_example/datasets' ;  LFADS . Utils . generateDemoDatasets ( datasetPath ,   'nDatasets' ,   3 );   This will simulate a chaotic 3 dimensional  Lorenz attractor  as the underlying dynamical system, initialized from 65 initial conditions. The key in these demonstration datasets is that the 65 conditions start from the same initial state and evolve identically across all 3 datasets. Each dataset, however, contains a disjoint set of neurons that are each a different linear recombination of the 3 dimensions of the Lorenz attractor state. This is analogous to the assumption we make in LFADS stitching\u2013each dataset contains different sets of neurons, which are reconstructed from a shared low-dimensional set of factors.",
            "title": "Setting up a multi-session LFADS run"
        },
        {
            "location": "/multisession/#building-a-dataset-collection-and-adding-datasets",
            "text": "First, create a dataset collection that points to a folder on disk where datasets are stored:  dataPath   =   '~/lorenz_example/datasets' ;  dc   =   LorenzExperiment . DatasetCollection ( dataPath );  dc . name   =   'lorenz_example' ;   Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance is created, it is automatically added to the  DatasetCollection  and will replace any dataset that has the same name if present.  LorenzExperiment . Dataset ( dc ,   'dataset001.mat' );  LorenzExperiment . Dataset ( dc ,   'dataset002.mat' );  LorenzExperiment . Dataset ( dc ,   'dataset003.mat' );   You can verify that the datasets have been added to the collection:  >>   dc  LorenzExperiment . DatasetCollection  \" lorenz_example \"\n   3   datasets   in   ~/ lorenz_example / datasets \n   [   1 ]   LorenzExperiment . Dataset  \" dataset001 \"\n   [   2 ]   LorenzExperiment . Dataset  \" dataset002 \"\n   [   3 ]   LorenzExperiment . Dataset  \" dataset003 \"\n\n             name :   'lorenz_example' \n          comment :   '' \n             path :   '~/lorenz_example/datasets' \n         datasets :   [ 3 x1   LorenzExperiment . Dataset ] \n        nDatasets :   3 \n     datasetNames :   { 3 x1   cell }   You can access individual datasets using  dc . datasets ( 1 )  or by name with  dc . matchDatasetsByName ( 'dataset001' ) .  You can then load all of the metadata for the datasets using: dc . loadInfo ();   How this metadata is determined for each dataset may be customized as described in  Interfacing with your Datasets . You can view a summary of the metadata using:  >>   dc . getDatasetInfoTable           \n\n                   subject                    date               saveTags      nTrials      nChannels \n               ________________      ______________________      ________      _______      _________  dataset001      'lorenz_example'      [ 31 - Jan - 2018   00 : 00 : 00 ]        '1'          1820           35      dataset002      'lorenz_example'      [ 31 - Jan - 2018   00 : 00 : 00 ]        '1'          1885           26      dataset003      'lorenz_example'      [ 31 - Jan - 2018   00 : 00 : 00 ]        '1'          1365           35",
            "title": "Building a dataset collection and adding datasets"
        },
        {
            "location": "/multisession/#create-a-runcollection",
            "text": "We\u2019ll now setup a  RunCollection  that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.  runRoot   =   '~/lorenz_example/runs' ;  rc   =   LorenzExperiment . RunCollection ( runRoot ,   'exampleStitching' ,   dc );  % replace with approximate date script authored as YYYYMMDD  % to ensure forwards compatibility  rc . version   =   20180131 ;",
            "title": "Create a RunCollection"
        },
        {
            "location": "/multisession/#specify-the-hyperparameters-in-runparams",
            "text": "We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8. The key change we\u2019ll make is to set  useAlignmentMatrix  to  true  in order to seed the read-in matrices.  par   =   LorenzExperiment . RunParams ;  par . name   =   'first_attempt_stitching' ;   % completely optional  par . useAlignmentMatrix   =   true ;   % use alignment matrices initial guess for multisession stitching  par . spikeBinMs   =   2 ;   % rebin the data at 2 ms  par . c_co_dim   =   0 ;   % no controller --> no inputs to generator  par . c_batch_size   =   150 ;   % must be < 1/5 of the min trial count  par . c_factors_dim   =   8 ;   % and manually set it for multisession stitched models  par . c_gen_dim   =   64 ;   % number of units in generator RNN  par . c_ic_enc_dim   =   64 ;   % number of units in encoder RNN  par . c_learning_rate_stop   =   1e-3 ;   % we can stop really early for the demo   We then add this  RunParams  to the  RunCollection :  rc . addParams ( par );   You can access the parameter settings added to  rc  using  rc.params , which will be an array of  RunParams  instances.",
            "title": "Specify the hyperparameters in RunParams"
        },
        {
            "location": "/multisession/#specify-the-runspec-set",
            "text": "Recall that  RunSpec  instances specify which datasets are included in a specific run. For stitching, we\u2019ll want to include all three datasets into a single model.  % include all datasets  runSpecName   =   'all' ;  runSpec   =   LorenzExperiment . RunSpec ( runSpecName ,   dc ,   1 : dc . nDatasets );  rc . addRunSpec ( runSpec );   You can adjust the arguments to the constructor of  LorenzExperiment.RunSpec , but in the example provided the inputs define:   the unique name of the run. Here we use  getSingleRunName , a convenience method of  Dataset  that generates a name like  single_datasetName .  the  DatasetCollection  from which datasets will be retrieved  the indices or names of datasets (as a string or cell array of strings) to include   If you like you can also add RunSpecs to train individual models for each dataset as well to facilitate comparison.  % add one run for each single dataset  for   iR   =   1 : dc . nDatasets \n     runSpecName   =   dc . datasets ( iR ). getSingleRunName ();   % 'single_dataset###' \n     runSpec   =   LorenzExperiment . RunSpec ( runSpecName ,   dc ,   iR ); \n     rc . addRunSpec ( runSpec );  end",
            "title": "Specify the RunSpec set"
        },
        {
            "location": "/multisession/#check-the-runcollection-and-the-run",
            "text": "The  RunCollection  will now display information about the parameter settings and run specifications that have been added. Here there is only one parameter setting by one run specification, so we\u2019re only performing 1 run total.  >>   rc  LorenzExperiment . RunCollection  \" exampleStitching \"  ( 1   runs   total ) \n   Dataset   Collection  \" lorenz_example \"  ( 3   datasets )   in   ~/ lorenz_example / datasets \n   Path :   ~/ lorenz_example / runs / exampleStitching \n\n   1   parameter   settings \n   [ 1   param_Qr2PeG   data_RE1kuL ]   LorenzExperiment . RunParams  \" first_attempt_stitching \"  useAlignmentMatrix = true   c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n   1   run   specifications \n   [   1 ]   LorenzExperiment . RunSpec  \" all \"  ( 3   datasets ) \n\n                           name :   'exampleStitching' \n                        comment :   '' \n                       rootPath :   '~/lorenz_example/runs' \n                        version :   201801 \n              datasetCollection :   [ 1 x1   LorenzExperiment . DatasetCollection ] \n                           runs :   [ 1 x1   LorenzExperiment . Run ] \n                         params :   [ 1 x1   LorenzExperiment . RunParams ] \n                       runSpecs :   [ 1 x1   LorenzExperiment . RunSpec ] \n                        nParams :   1 \n                      nRunSpecs :   1 \n                     nRunsTotal :   1 \n                      nDatasets :   3 \n                   datasetNames :   { 3 x1   cell } \n                           path :   '~/lorenz_example/runs/exampleStitching' \n       pathsCommonDataForParams :   { '~/lorenz_example/runs/exampleStitching/data_RE1kuL' } \n                 pathsForParams :   { '~/lorenz_example/runs/exampleStitching/param_Qr2PeG' } \n     fileShellScriptTensorboard :   '~/lorenz_example/runs/exampleStitching/launch_tensorboard.sh' \n                fileSummaryText :   '~/lorenz_example/runs/exampleStitching/summary.txt' \n        fileShellScriptRunQueue :   '~/lorenz_example/runs/exampleStitching/run_lfadsqueue.py'  >>   run   =   rc . findRuns ( 'all' ,   1 );  LorenzExperiment . Run  \" all \"  ( 3   datasets ) \n\n   Path :   ~/ lorenz_example / runs / exampleStitching / param_Qr2PeG / all \n   Data :   ~/ lorenz_example / runs / exampleStitching / data_RE1kuL \n   LorenzExperiment . RunParams  \" first_attempt_stitching \"  :   useAlignmentMatrix = true   c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n   3   datasets   in  \" lorenz_example \"\n     [   1 ]   LorenzExperiment . Dataset  \" dataset001 \"\n     [   2 ]   LorenzExperiment . Dataset  \" dataset002 \"\n     [   3 ]   LorenzExperiment . Dataset  \" dataset003 \" ...",
            "title": "Check the RunCollection and the Run"
        },
        {
            "location": "/multisession/#verifying-the-alignment-matrices",
            "text": "Next, we\u2019ll run the principal components regression that generates the alignment matrices using the algorithm described  above . Then we\u2019ll verify that these matrices are able to project the data from each dataset into similar looking low-dimensional trajectories.  To visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset.  run . doMultisessionAlignment ();   Under the hood, the alignment matrix calculations are performed by an instance of  LFADS.MutlisessionAlignmentTool . To plot the reconstruction quality, you can call  tool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot) , like so:  tool   =   run . multisessionAlignmentTool ;  nFactorsPlot   =   3 ;  conditionsToPlot   =   [ 1   20   40 ];  tool . plotAlignmentReconstruction ( nFactorsPlot ,   conditionsToPlot );    In this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance.  The actual alignment matrices can be accessed using: tool . alignmentMatrices   % nDatasets x 1 cell array of read-in matrices",
            "title": "Verifying the alignment matrices"
        },
        {
            "location": "/multisession/#prepare-for-lfads",
            "text": "Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.  rc . prepareForLFADS ();   This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call  prepareForLFADS  again. Existing files won\u2019t be overwritten unless you call  rc.prepareForLFADS(true) .  After running  prepareForLFADS , the run manager will create the following files on disk under  rc.path :  ~/lorenz_example/runs/exampleStitching\n\u251c\u2500\u2500 data_4MaTKO\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n\u251c\u2500\u2500 param_YOs74u\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 all\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_4MaTKO/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_4MaTKO/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_4MaTKO/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_4MaTKO/lfads_dataset001.h5\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_4MaTKO/lfads_dataset002.h5\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_4MaTKO/lfads_dataset003.h5\n\u2514\u2500\u2500 summary.txt  The organization of these files on disk is discussed in more detail  here . Also, a  summary.txt  file will be generated which can be useful for identifying all of the runs and their locations on disk. You can also generate this text from within Matlab by calling  rc.generateSummaryText() .  LorenzExperiment . RunCollection  \" exampleStitching2 \"  ( 1   runs   total ) \n   Path :   ~/ lorenz_example / runs / exampleStitching2 \n   Dataset   Collection  \" lorenz_example \"  ( 3   datasets )   in   ~/ lorenz_example / datasets \n\n   ------------------------ \n\n   1   Run   Specifications : \n\n     [ runSpec   1 ]   LorenzExperiment . RunSpec  \" all \"  ( 3   datasets ) \n       [ ds   1 ]   LorenzExperiment . Dataset  \" dataset001 \"\n       [ ds   2 ]   LorenzExperiment . Dataset  \" dataset002 \"\n       [ ds   3 ]   LorenzExperiment . Dataset  \" dataset003 \"\n\n   ------------------------ \n\n   1   Parameter   Settings : \n\n     [ 1   param_Qr2PeG   data_RE1kuL ]   LorenzExperiment . RunParams  \" first_attempt_stitching \"\n       useAlignmentMatrix = true   c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n       spikeBinMs :   2 \n       trainToTestRatio :   4 \n       useAlignmentMatrix :   true \n       useSingleDatasetAlignmentMatrix :   false \n       scaleIncreaseStepsWithDatasets :   true \n       c_cell_clip_value :   5 \n       c_factors_dim :   8 \n       c_ic_enc_dim :   64 \n       c_ci_enc_dim :   128 \n       c_gen_dim :   64 \n       c_keep_prob :   0.95 \n       c_learning_rate_decay_factor :   0.98 \n       c_device :   / gpu : 0 \n       c_co_dim :   0 \n       c_do_causal_controller :   false \n       c_do_feed_factors_to_controller :   true \n       c_feedback_factors_or_rates :   factors \n       c_controller_input_lag :   1 \n       c_do_train_readin :   true \n       c_l2_gen_scale :   500 \n       c_l2_con_scale :   500 \n       c_batch_size :   150 \n       c_kl_increase_steps :   900 \n       c_l2_increase_steps :   900 \n       c_ic_dim :   64 \n       c_con_dim :   128 \n       c_learning_rate_stop :   0.001 \n       c_temporal_spike_jitter_width :   0 \n       c_allow_gpu_growth :   true \n       c_kl_ic_weight :   1 \n       c_kl_co_weight :   1 \n       c_inject_ext_input_to_gen :   false \n       c_prior_ar_atau :   10 \n       c_do_train_prior_ar_atau :   true \n       c_prior_ar_nvar :   0.1 \n       c_do_train_prior_ar_nvar :   true \n       num_samples_posterior :   512 \n       posterior_mean_kind :   posterior_sample_and_average   After running  prepareForLFADS , you can then run the LFADS model or models in the same way as with single-session models, using the instructions  here .",
            "title": "Prepare for LFADS"
        },
        {
            "location": "/analysis/",
            "text": "Loading and Analyzing LFADS Posterior Means\n\u00b6\n\n\nReusing the \ndrive_script\n\u00b6\n\n\nThe \nLFADS.Run\n instances you created earlier with the \ndrive_script\n uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters.\n\n\nUsing your \nRunCollection\n \nrc\n, you can access individual runs by indexing directly into \nrc.runs\n which has size \nrc.nRunSpecs\n x \nrc.nParams\n. You can also search for a specific run using \nrc.findRun\n\n\nrun1\n \n=\n \nrc\n.\nfindRuns\n(\n'single_dataset001'\n,\n \n'param_pqQbzB'\n);\n\n\n\n\n\nThe first argument searches over the \nRunSpec\ns by name, the second searches over the \nRunParams\n by hash value.\n\n\nLoading the posterior means\n\u00b6\n\n\nUsing the \nRun\n instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully):\n\n\n>>\n \nrun1\n.\ncheckPosteriorMeansExist\n()\n\n\n  \nlogical\n\n\n   \n1\n\n\n\n\n\nAnd then load the posterior means using:\n\npm\n \n=\n \nrun1\n.\nloadPosteriorMeans\n();\n\n\n\n\nOr alternatively, load all of your runs\u2019 posterior means by calling \nrc.loadPosteriorMeans()\n. Then you can access the cached posterior means in each run\u2019s \n.posteriorMeans\n property.\n\n\npm\n will be an instance of \nLFADS.PosteriorMeans\n:\n\n\n>>\n \npm\n \n=\n \nrc\n.\nruns\n(\n1\n).\nposteriorMeans\n\n\n\npm\n \n=\n\n\n  \nPosteriorMeans\n \nwith\n \nproperties\n:\n\n\n                  \ntime\n:\n \n[\n500\nx1\n \ndouble\n]\n\n    \ncontroller_outputs\n:\n \n[]\n\n               \nfactors\n:\n \n[\n8\nx500x1560\n \ndouble\n]\n\n         \ngenerator_ics\n:\n \n[\n64\nx1560\n \ndouble\n]\n\n      \ngenerator_states\n:\n \n[\n64\nx500x1560\n \ndouble\n]\n\n                 \nrates\n:\n \n[\n29\nx500x1560\n \ndouble\n]\n\n             \nvalidInds\n:\n \n[\n312\nx1\n \nuint16\n]\n\n             \ntrainInds\n:\n \n[\n1248\nx1\n \ndouble\n]\n\n                \nparams\n:\n \n[\n1\nx1\n \nMyExperiment\n.\nRunParams\n]\n\n               \nisValid\n:\n \n1\n\n    \nnControllerOutputs\n:\n \n0\n\n       \nnGeneratorUnits\n:\n \n64\n\n              \nnFactors\n:\n \n8\n\n              \nnNeurons\n:\n \n29\n\n                     \nT\n:\n \n500\n\n               \nnTrials\n:\n \n1560\n\n\n\n\n\nWhose key properties are:\n\n\n\n\ntime\n:\n\n\nnTime\n x \n1\n time vector associated with each of the output fields, which you provided in your \ngenerateRatesForDataset()\n implementation\n\n\ncontroller_outputs\n:\n\n\nnControllerOutputs\n x \nnTime\n. Inferred inputs to the generator network. Or empty, if no controller is used (\nc_co_dim\n \n==\n \n0\n)\n\n\n\n\nfactors\n:\n:\nnFactors\n x \nnTime\n x \nnTrials\n. Factor outputs from the generator network.\n\n\n\n\ngenerator_ics\n:\n\n\nnGeneratorUnits\n x \nnTrials\n. Initial conditions for the generator units.\n\n\ngenerator_states\n:\n\n\nnGeneratorUnits\n x \nnTime\n x \nnTrials\n. Trajectories of the generator units.\n\n\nrates\n:\n\n\nnNeurons\n x \nnTime\n x \nnTrials\n. Inferred firing rates of the neurons\n\n\nvalidInds\n:\n\n\nList of trial indices used in the validation set\n\n\ntrainInds\n:\n\n\nList of trial indices used in the training set\n\n\n\n\nIf the run stitches together multiple datasets, then the \nposteriorMeans\n will be an \nnDatasets\n x 1 vector of \nLFADS.PosteriorMeans\n instances, each corresponding to an included dataset.\n\n\nVisualizing the factors\n\u00b6\n\n\nSingle trial plot of factor 1 on first 10 conditions (color-coded), i.e. \npm\n.\nfactors\n(\n1\n,\n \n:,\n \npm\n.\nconditionId\n \n<\n=\n \n10\n)\n.\n\n\n\n\nCondition-average plot of factor 1 on all conditions, flanked by standard error of the mean.\n\n\n\n\nComparing factor trajectories across datasets\n\u00b6\n\n\nSingle-dataset models\n\u00b6\n\n\nLooking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models\n\n\npmSingleRuns\n \n=\n \n[\nrc\n.\nruns\n(\n1\n).\nloadPosteriorMeans\n();\n \n...\n\n                \nrc\n.\nruns\n(\n2\n).\nloadPosteriorMeans\n();\n \n...\n\n                \nrc\n.\nruns\n(\n3\n).\nloadPosteriorMeans\n()];\n\n\n\n\n\n\n\nStitched multi-session model\n\u00b6\n\n\nHowever, if we load the posterior means for the stitched multi-session model (named \nall\n). we find that these same factor trajectories are now highly similar across datasets.\n\n\n\n\nWe can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot.\n\n\n\n\nWe can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the",
            "title": "Analyzing LFADS Posterior Means"
        },
        {
            "location": "/analysis/#loading-and-analyzing-lfads-posterior-means",
            "text": "",
            "title": "Loading and Analyzing LFADS Posterior Means"
        },
        {
            "location": "/analysis/#reusing-the-drive_script",
            "text": "The  LFADS.Run  instances you created earlier with the  drive_script  uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters.  Using your  RunCollection   rc , you can access individual runs by indexing directly into  rc.runs  which has size  rc.nRunSpecs  x  rc.nParams . You can also search for a specific run using  rc.findRun  run1   =   rc . findRuns ( 'single_dataset001' ,   'param_pqQbzB' );   The first argument searches over the  RunSpec s by name, the second searches over the  RunParams  by hash value.",
            "title": "Reusing the drive_script"
        },
        {
            "location": "/analysis/#loading-the-posterior-means",
            "text": "Using the  Run  instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully):  >>   run1 . checkPosteriorMeansExist () \n\n   logical \n\n    1   And then load the posterior means using: pm   =   run1 . loadPosteriorMeans ();   Or alternatively, load all of your runs\u2019 posterior means by calling  rc.loadPosteriorMeans() . Then you can access the cached posterior means in each run\u2019s  .posteriorMeans  property.  pm  will be an instance of  LFADS.PosteriorMeans :  >>   pm   =   rc . runs ( 1 ). posteriorMeans  pm   = \n\n   PosteriorMeans   with   properties : \n\n                   time :   [ 500 x1   double ] \n     controller_outputs :   [] \n                factors :   [ 8 x500x1560   double ] \n          generator_ics :   [ 64 x1560   double ] \n       generator_states :   [ 64 x500x1560   double ] \n                  rates :   [ 29 x500x1560   double ] \n              validInds :   [ 312 x1   uint16 ] \n              trainInds :   [ 1248 x1   double ] \n                 params :   [ 1 x1   MyExperiment . RunParams ] \n                isValid :   1 \n     nControllerOutputs :   0 \n        nGeneratorUnits :   64 \n               nFactors :   8 \n               nNeurons :   29 \n                      T :   500 \n                nTrials :   1560   Whose key properties are:   time :  nTime  x  1  time vector associated with each of the output fields, which you provided in your  generateRatesForDataset()  implementation  controller_outputs :  nControllerOutputs  x  nTime . Inferred inputs to the generator network. Or empty, if no controller is used ( c_co_dim   ==   0 )   factors :\n: nFactors  x  nTime  x  nTrials . Factor outputs from the generator network.   generator_ics :  nGeneratorUnits  x  nTrials . Initial conditions for the generator units.  generator_states :  nGeneratorUnits  x  nTime  x  nTrials . Trajectories of the generator units.  rates :  nNeurons  x  nTime  x  nTrials . Inferred firing rates of the neurons  validInds :  List of trial indices used in the validation set  trainInds :  List of trial indices used in the training set   If the run stitches together multiple datasets, then the  posteriorMeans  will be an  nDatasets  x 1 vector of  LFADS.PosteriorMeans  instances, each corresponding to an included dataset.",
            "title": "Loading the posterior means"
        },
        {
            "location": "/analysis/#visualizing-the-factors",
            "text": "Single trial plot of factor 1 on first 10 conditions (color-coded), i.e.  pm . factors ( 1 ,   :,   pm . conditionId   < =   10 ) .   Condition-average plot of factor 1 on all conditions, flanked by standard error of the mean.",
            "title": "Visualizing the factors"
        },
        {
            "location": "/analysis/#comparing-factor-trajectories-across-datasets",
            "text": "",
            "title": "Comparing factor trajectories across datasets"
        },
        {
            "location": "/analysis/#single-dataset-models",
            "text": "Looking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models  pmSingleRuns   =   [ rc . runs ( 1 ). loadPosteriorMeans ();   ... \n                 rc . runs ( 2 ). loadPosteriorMeans ();   ... \n                 rc . runs ( 3 ). loadPosteriorMeans ()];",
            "title": "Single-dataset models"
        },
        {
            "location": "/analysis/#stitched-multi-session-model",
            "text": "However, if we load the posterior means for the stitched multi-session model (named  all ). we find that these same factor trajectories are now highly similar across datasets.   We can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot.   We can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the",
            "title": "Stitched multi-session model"
        },
        {
            "location": "/trained-params/",
            "text": "Loading the trained LFADS model parameters\n\u00b6\n\n\nLoading the \nmodel_params\n\u00b6\n\n\nAfter the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called \nlfadsOutput/model_params\n, as described \nhere\n. If you used the \nrun queue\n to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed.\n\n\nmodel_params\n is an HD5 file that contains all of the model parameters. To load these, each \nLFADS.Run\n provides a method \nrun.loadModelTrainedParams()\n that will return an instance of \nLFADS.ModelTrainedParameters\n. This instance will have many fields, corresponding to the set of parameters learned by LFADS.\n\n\nList of model trained parameters\n\u00b6\n\n\nBelow is an annotated list of the properties found within the \nModelTrainedParameters\n instance, along with the size of each parameter relative to hyperparameters specified in the corresponding \nRunParams\n.\n\n\nFor reference, here is the schematic of an LFADS model:\n\n\n\n\nRead-in from spikes to input factors\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nx_to_infac_W\n\n\nreadin alignment weights, mapping from counts to input factors\n\n\nnDatasets\n x 1 cell of \nnNeuronsThisDataset\n x \nc_factors_dim\n\n\n\n\n\n\nx_to_infac_b\n\n\nreadin alignment biases to input factors\n\n\nnDatasets\n x 1 cell of 1 x \nc_factors_dim\n\n\n\n\n\n\n\n\nInitial condition encoder (forward)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nic_enc_fwd_t0\n\n\nforward IC encoder prior on t0\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_fwd_gru_xh_to_gates_ru_W\n\n\nforward IC encoder GRU, mapping input+hiddens to gates r and u, weights\n\n\n(\nc_ic_enc_dim\n + factors_dim) x (2 * \nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_fwd_gru_xh_to_gates_ru_b\n\n\nforward IC encoder GRU bmapping input+hiddens to gates r and u, biases\n\n\n1 x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_fwd_gru_xrh_to_c_W\n\n\nforward IC encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ic_enc_dim\n + \nc_factors_dim\n) x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_fwd_gru_xrh_to_c_b\n\n\nforward IC encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\n\n\nInitial condition encoder (reverse)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nic_enc_rev_t0\n\n\nreverse IC encoder prior on t0\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_rev_gru_xh_to_gates_ru_W\n\n\nreverse IC encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(\nc_factors_dim\n + \nc_ic_enc_dim\n) x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_rev_gru_xh_to_gates_ru_b\n\n\nreverse IC encoder GRU bmapping input+hidden to gates r and u, biases\n\n\n1 x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_rev_gru_xrh_to_c_W\n\n\nreverse IC encoder GRU mapping input+r+hidden to candidates (weights)\n\n\n(\nc_ic_enc_dim\n + \nc_factors_dim\n) x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_rev_gru_xrh_to_c_b\n\n\nreverse IC encoder GRU mapping input+r+hidden to candidates (bias)\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\n\n\nInitial condition g0\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nprior_g0_mean\n\n\nMean parameter in prior on initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nprior_g0_logvar\n\n\nLogvar parameter in prior on initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_mean_W\n\n\nWeights for mean parameter in posterior of the initial condition g0\n\n\n(2*\nc_ic_enc_dim\n) x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_mean_b\n\n\nBias for mean parameter in posterior of the initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_logvar_W\n\n\nWeights for logvar parameter in posterior of the initial condition g0\n\n\n(2*\nc_ic_enc_dim\n) x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_logvar_b\n\n\nBias for logvar parameter in posterior of the initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\ng0_to_gen_ic_W\n\n\nmapping from g0 to generator initial condition, weights\n\n\nc_ic_dim\n x \nc_gen_dim\n\n\n\n\n\n\ng0_to_gen_ic_b\n\n\nmapping from g0 to generator initial condition, bias\n\n\n1 x \nc_gen_dim\n\n\n\n\n\n\n\n\nController encoder (forward)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nci_enc_fwd_t0\n\n\nforward controller prior on t0\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\nci_enc_fwd_gru_xh_to_ru_W\n\n\nforward controller encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(\nci_enc_dim\n + \nc_factors_dim\n) x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xh_to_ru_b\n\n\nforward controller encoder GRU, mapping input+hidden to gates r and u, bias\n\n\n1 x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xrh_to_c_W\n\n\nforward controller encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ci_enc_dim\n + \nc_factors_dim\n) x \nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xrh_to_c_b\n\n\nforward controller encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\n\n\nController encoder (reverse)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nci_enc_rev_t0\n\n\nreverse controller prior on t0\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\nci_enc_rev_gru_xh_to_ru_W\n\n\nreverse controller encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(ci_enc_dim + factors_dim) x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xh_to_ru_b\n\n\nreverse controller encoder GRU, mapping input+hidden to gates r and u, bias\n\n\n1 x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xrh_to_c_W\n\n\nreverse controller encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ci_enc_dim\n + \nc_factors_dim\n) x \nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xrh_to_c_b\n\n\nreverse controller encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\n\n\nControlller RNN\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ncon_gengru_x_to_ru_W\n\n\ncontroller GenGRU, mapping input to gates r+u, weights\n\n\n(\nc_ci_enc_dim\n * 2 + \nc_factors_dim\n) x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_h_to_ru_W\n\n\ncontroller GenGRU, mapping hidden to gates r+u, weights\n\n\nc_con_dim\n x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_h_to_ru_b\n\n\ncontroller GenGRU, mapping hidden to gates r+u, weights\n\n\n1 x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_x_to_c_W\n\n\ncontroller GenGRU, mapping input to candidates, weights\n\n\n(\nc_ci_enc_dim\n * 2 + \nc_factors_dim\n) x \nc_con_dim\n\n\n\n\n\n\ncon_gengru_rh_to_c_b\n\n\ncontroller GenGRU, mapping r+hidden to candidates, bias\n\n\n1 x \nc_con_dim\n\n\n\n\n\n\n\n\nController output co\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nprior_ar1_logevars\n\n\nautoregressive prior on controller outputs\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\nprior_ar1_logatau\n\n\nautoregressive time constant prior on controller outputs\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\ncon_co\n\n\nprior on controller output\n\n\n1 x \nc_con_dim\n\n\n\n\n\n\ncon_to_posterior_co_mean_W\n\n\nmapping from controller to mean parameter of co, weights\n\n\nc_con_dim\n x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_mean_b\n\n\nmapping from controller to mean parameter of co, biases\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_logvar_W\n\n\nmapping from controller to logvar parameter of co, weights\n\n\nc_con_dim\n x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_logvar_b\n\n\nmapping from controller to logvar parameter of co, biases\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\n\n\nGenerator RNN\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ngen_gengru_x_to_ru_W\n\n\ngenerator GRU, mapping from input to gates r+u, weights\n\n\nc_co_dim\n x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_h_to_ru_W\n\n\ngenerator GRU, mapping from input to gates r+u, weights\n\n\nc_gen_dim\n x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_h_to_ru_b\n\n\ngenerator GRU, mapping from input to gates r+u, biases\n\n\n1 x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_x_to_c_W\n\n\ngenerator GRU, mapping from input to candidates, weights\n\n\nc_co_dim\n x \nc_gen_dim\n\n\n\n\n\n\ngen_gengru_rh_to_c_W\n\n\ngenerator GRU, mapping from r+hidden to candidates, weights\n\n\nc_gen_dim\n x \nc_gen_dim\n\n\n\n\n\n\ngen_gengru_rh_to_c_b\n\n\ngenerator GRU, mapping from r+hidden to candidates, biases\n\n\n1 x \nc_gen_dim\n\n\n\n\n\n\n\n\nGenerator output\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ngen_to_factors_W\n\n\nmapping from generator to factors, weights\n\n\nc_gen_dim\n x \nc_factors_dim\n\n\n\n\n\n\nfactors_to_logrates_W\n\n\nreadout alignment weights\n\n\nnDatasets\n x 1 cell of \nc_factors_dim\n x \nnNeuronsThisDataset\n\n\n\n\n\n\nfactors_to_logrates_b\n\n\nreadout alignment biases\n\n\nnDatasets\n x 1 cell of 1 x \nnNeuronsThisDataset\n\n\n\n\n\n\n\n\nLoading \nmodel_params\n for Lorenz example\n\u00b6\n\n\nWe can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with \nc_co_dim == 0\n.\n\n\n>>\n \nmtp\n \n=\n \nrc\n.\nfindRuns\n(\n'all'\n,\n \n1\n).\nloadModelTrainedParams\n()\n\n\n\nans\n \n=\n\n\n  \nModelTrainedParams\n \nwith\n \nproperties\n:\n\n\n   \nRead\n-\nin\n \nfrom\n \nspikes\n \nto\n \ninput\n \nfactors\n\n                       \nx_to_infac_W\n:\n \n{\n3\nx1\n \ncell\n}\n\n                       \nx_to_infac_b\n:\n \n{\n3\nx1\n \ncell\n}\n\n\n   \nInitial\n \ncondition\n \nencoder\n \n(\nforward\n)\n\n                      \nic_enc_fwd_t0\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_fwd_gru_xh_to_gates_ru_W\n:\n \n[\n128\nx72\n \nsingle\n]\n\n    \nic_enc_fwd_gru_xh_to_gates_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n          \nic_enc_fwd_gru_xrh_to_c_W\n:\n \n[\n64\nx72\n \nsingle\n]\n\n          \nic_enc_fwd_gru_xrh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nInitial\n \ncondition\n \nencoder\n \n(\nreverse\n)\n\n                      \nic_enc_rev_t0\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_rev_gru_xh_to_gates_ru_W\n:\n \n[\n128\nx72\n \nsingle\n]\n\n    \nic_enc_rev_gru_xh_to_gates_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n          \nic_enc_rev_gru_xrh_to_c_W\n:\n \n[\n64\nx72\n \nsingle\n]\n\n          \nic_enc_rev_gru_xrh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nInitial\n \ncondition\n \ng0\n\n                      \nprior_g0_mean\n:\n \n[\n64\nx1\n \nsingle\n]\n\n                    \nprior_g0_logvar\n:\n \n[\n64\nx1\n \nsingle\n]\n\n      \nic_enc_to_posterior_g0_mean_W\n:\n \n[\n64\nx128\n \nsingle\n]\n\n      \nic_enc_to_posterior_g0_mean_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_to_posterior_g0_logvar_W\n:\n \n[\n64\nx128\n \nsingle\n]\n\n    \nic_enc_to_posterior_g0_logvar_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n                     \ng0_to_gen_ic_W\n:\n \n[]\n\n                     \ng0_to_gen_ic_b\n:\n \n[]\n\n\n   \nController\n \nencoder\n \n(\nforward\n)\n\n                      \nci_enc_fwd_t0\n:\n \n[]\n\n          \nci_enc_fwd_gru_xh_to_ru_W\n:\n \n[]\n\n          \nci_enc_fwd_gru_xh_to_ru_b\n:\n \n[]\n\n          \nci_enc_fwd_gru_xrh_to_c_W\n:\n \n[]\n\n          \nci_enc_fwd_gru_xrh_to_c_b\n:\n \n[]\n\n\n   \nController\n \nencoder\n \n(\nreverse\n)\n\n                      \nci_enc_rev_t0\n:\n \n[]\n\n          \nci_enc_rev_gru_xh_to_ru_W\n:\n \n[]\n\n          \nci_enc_rev_gru_xh_to_ru_b\n:\n \n[]\n\n          \nci_enc_rev_gru_xrh_to_c_W\n:\n \n[]\n\n          \nci_enc_rev_gru_xrh_to_c_b\n:\n \n[]\n\n\n   \nControlller\n \nRNN\n\n               \ncon_gengru_x_to_ru_W\n:\n \n[]\n\n               \ncon_gengru_h_to_ru_W\n:\n \n[]\n\n               \ncon_gengru_h_to_ru_b\n:\n \n[]\n\n                \ncon_gengru_x_to_c_W\n:\n \n[]\n\n               \ncon_gengru_rh_to_c_W\n:\n \n[]\n\n               \ncon_gengru_rh_to_c_b\n:\n \n[]\n\n\n   \nController\n \noutput\n \nco\n\n                 \nprior_ar1_logevars\n:\n \n[]\n\n                  \nprior_ar1_logatau\n:\n \n[]\n\n                             \ncon_co\n:\n \n[]\n\n         \ncon_to_posterior_co_mean_W\n:\n \n[]\n\n         \ncon_to_posterior_co_mean_b\n:\n \n[]\n\n       \ncon_to_posterior_co_logvar_W\n:\n \n[]\n\n       \ncon_to_posterior_co_logvar_b\n:\n \n[]\n\n\n   \nGenerator\n \nRNN\n\n               \ngen_gengru_x_to_ru_W\n:\n \n[]\n\n               \ngen_gengru_h_to_ru_W\n:\n \n[\n128\nx64\n \nsingle\n]\n\n               \ngen_gengru_h_to_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n                \ngen_gengru_x_to_c_W\n:\n \n[]\n\n               \ngen_gengru_rh_to_c_W\n:\n \n[\n64\nx64\n \nsingle\n]\n\n               \ngen_gengru_rh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nGenerator\n \noutput\n\n                   \ngen_to_factors_W\n:\n \n[\n8\nx64\n \nsingle\n]\n\n              \nfactors_to_logrates_W\n:\n \n{\n3\nx1\n \ncell\n}\n\n              \nfactors_to_logrates_b\n:\n \n{\n3\nx1\n \ncell\n}\n\n\n\n\n\nThe recurrent connectivity weight matrix of the \nc_gen_dim==64\n GRU generator RNN is given by \nmtp.gen_gengru_rh_to_c_W\n:\n\n\n\n\nAnd the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by \nmtp.factors_to_logrates_W\n:",
            "title": "Loading the Model Trained Parameters"
        },
        {
            "location": "/trained-params/#loading-the-trained-lfads-model-parameters",
            "text": "",
            "title": "Loading the trained LFADS model parameters"
        },
        {
            "location": "/trained-params/#loading-the-model_params",
            "text": "After the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called  lfadsOutput/model_params , as described  here . If you used the  run queue  to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed.  model_params  is an HD5 file that contains all of the model parameters. To load these, each  LFADS.Run  provides a method  run.loadModelTrainedParams()  that will return an instance of  LFADS.ModelTrainedParameters . This instance will have many fields, corresponding to the set of parameters learned by LFADS.",
            "title": "Loading the model_params"
        },
        {
            "location": "/trained-params/#list-of-model-trained-parameters",
            "text": "Below is an annotated list of the properties found within the  ModelTrainedParameters  instance, along with the size of each parameter relative to hyperparameters specified in the corresponding  RunParams .  For reference, here is the schematic of an LFADS model:",
            "title": "List of model trained parameters"
        },
        {
            "location": "/trained-params/#read-in-from-spikes-to-input-factors",
            "text": "Name  Description  Size      x_to_infac_W  readin alignment weights, mapping from counts to input factors  nDatasets  x 1 cell of  nNeuronsThisDataset  x  c_factors_dim    x_to_infac_b  readin alignment biases to input factors  nDatasets  x 1 cell of 1 x  c_factors_dim",
            "title": "Read-in from spikes to input factors"
        },
        {
            "location": "/trained-params/#initial-condition-encoder-forward",
            "text": "Name  Description  Size      ic_enc_fwd_t0  forward IC encoder prior on t0  1 x  c_ic_enc_dim    ic_enc_fwd_gru_xh_to_gates_ru_W  forward IC encoder GRU, mapping input+hiddens to gates r and u, weights  ( c_ic_enc_dim  + factors_dim) x (2 *  c_ic_enc_dim )    ic_enc_fwd_gru_xh_to_gates_ru_b  forward IC encoder GRU bmapping input+hiddens to gates r and u, biases  1 x (2* c_ic_enc_dim )    ic_enc_fwd_gru_xrh_to_c_W  forward IC encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ic_enc_dim  +  c_factors_dim ) x  c_ic_enc_dim    ic_enc_fwd_gru_xrh_to_c_b  forward IC encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ic_enc_dim",
            "title": "Initial condition encoder (forward)"
        },
        {
            "location": "/trained-params/#initial-condition-encoder-reverse",
            "text": "Name  Description  Size      ic_enc_rev_t0  reverse IC encoder prior on t0  1 x  c_ic_enc_dim    ic_enc_rev_gru_xh_to_gates_ru_W  reverse IC encoder GRU, mapping input+hidden to gates r and u, weights  ( c_factors_dim  +  c_ic_enc_dim ) x (2* c_ic_enc_dim )    ic_enc_rev_gru_xh_to_gates_ru_b  reverse IC encoder GRU bmapping input+hidden to gates r and u, biases  1 x (2* c_ic_enc_dim )    ic_enc_rev_gru_xrh_to_c_W  reverse IC encoder GRU mapping input+r+hidden to candidates (weights)  ( c_ic_enc_dim  +  c_factors_dim ) x  c_ic_enc_dim    ic_enc_rev_gru_xrh_to_c_b  reverse IC encoder GRU mapping input+r+hidden to candidates (bias)  1 x  c_ic_enc_dim",
            "title": "Initial condition encoder (reverse)"
        },
        {
            "location": "/trained-params/#initial-condition-g0",
            "text": "Name  Description  Size      prior_g0_mean  Mean parameter in prior on initial condition g0  1 x  c_ic_dim    prior_g0_logvar  Logvar parameter in prior on initial condition g0  1 x  c_ic_dim    ic_enc_to_posterior_g0_mean_W  Weights for mean parameter in posterior of the initial condition g0  (2* c_ic_enc_dim ) x  c_ic_dim    ic_enc_to_posterior_g0_mean_b  Bias for mean parameter in posterior of the initial condition g0  1 x  c_ic_dim    ic_enc_to_posterior_g0_logvar_W  Weights for logvar parameter in posterior of the initial condition g0  (2* c_ic_enc_dim ) x  c_ic_dim    ic_enc_to_posterior_g0_logvar_b  Bias for logvar parameter in posterior of the initial condition g0  1 x  c_ic_dim    g0_to_gen_ic_W  mapping from g0 to generator initial condition, weights  c_ic_dim  x  c_gen_dim    g0_to_gen_ic_b  mapping from g0 to generator initial condition, bias  1 x  c_gen_dim",
            "title": "Initial condition g0"
        },
        {
            "location": "/trained-params/#controller-encoder-forward",
            "text": "Name  Description  Size      ci_enc_fwd_t0  forward controller prior on t0  1 x  c_ci_enc_dim    ci_enc_fwd_gru_xh_to_ru_W  forward controller encoder GRU, mapping input+hidden to gates r and u, weights  ( ci_enc_dim  +  c_factors_dim ) x (2* c_ci_enc_dim )    ci_enc_fwd_gru_xh_to_ru_b  forward controller encoder GRU, mapping input+hidden to gates r and u, bias  1 x (2* c_ci_enc_dim )    ci_enc_fwd_gru_xrh_to_c_W  forward controller encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ci_enc_dim  +  c_factors_dim ) x  c_ci_enc_dim )    ci_enc_fwd_gru_xrh_to_c_b  forward controller encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ci_enc_dim",
            "title": "Controller encoder (forward)"
        },
        {
            "location": "/trained-params/#controller-encoder-reverse",
            "text": "Name  Description  Size      ci_enc_rev_t0  reverse controller prior on t0  1 x  c_ci_enc_dim    ci_enc_rev_gru_xh_to_ru_W  reverse controller encoder GRU, mapping input+hidden to gates r and u, weights  (ci_enc_dim + factors_dim) x (2* c_ci_enc_dim )    ci_enc_rev_gru_xh_to_ru_b  reverse controller encoder GRU, mapping input+hidden to gates r and u, bias  1 x (2* c_ci_enc_dim )    ci_enc_rev_gru_xrh_to_c_W  reverse controller encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ci_enc_dim  +  c_factors_dim ) x  c_ci_enc_dim )    ci_enc_rev_gru_xrh_to_c_b  reverse controller encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ci_enc_dim",
            "title": "Controller encoder (reverse)"
        },
        {
            "location": "/trained-params/#controlller-rnn",
            "text": "Name  Description  Size      con_gengru_x_to_ru_W  controller GenGRU, mapping input to gates r+u, weights  ( c_ci_enc_dim  * 2 +  c_factors_dim ) x (2* c_con_dim )    con_gengru_h_to_ru_W  controller GenGRU, mapping hidden to gates r+u, weights  c_con_dim  x (2* c_con_dim )    con_gengru_h_to_ru_b  controller GenGRU, mapping hidden to gates r+u, weights  1 x (2* c_con_dim )    con_gengru_x_to_c_W  controller GenGRU, mapping input to candidates, weights  ( c_ci_enc_dim  * 2 +  c_factors_dim ) x  c_con_dim    con_gengru_rh_to_c_b  controller GenGRU, mapping r+hidden to candidates, bias  1 x  c_con_dim",
            "title": "Controlller RNN"
        },
        {
            "location": "/trained-params/#controller-output-co",
            "text": "Name  Description  Size      prior_ar1_logevars  autoregressive prior on controller outputs  1 x  c_co_dim    prior_ar1_logatau  autoregressive time constant prior on controller outputs  1 x  c_co_dim    con_co  prior on controller output  1 x  c_con_dim    con_to_posterior_co_mean_W  mapping from controller to mean parameter of co, weights  c_con_dim  x  c_co_dim    con_to_posterior_co_mean_b  mapping from controller to mean parameter of co, biases  1 x  c_co_dim    con_to_posterior_co_logvar_W  mapping from controller to logvar parameter of co, weights  c_con_dim  x  c_co_dim    con_to_posterior_co_logvar_b  mapping from controller to logvar parameter of co, biases  1 x  c_co_dim",
            "title": "Controller output co"
        },
        {
            "location": "/trained-params/#generator-rnn",
            "text": "Name  Description  Size      gen_gengru_x_to_ru_W  generator GRU, mapping from input to gates r+u, weights  c_co_dim  x (2* c_gen_dim )    gen_gengru_h_to_ru_W  generator GRU, mapping from input to gates r+u, weights  c_gen_dim  x (2* c_gen_dim )    gen_gengru_h_to_ru_b  generator GRU, mapping from input to gates r+u, biases  1 x (2* c_gen_dim )    gen_gengru_x_to_c_W  generator GRU, mapping from input to candidates, weights  c_co_dim  x  c_gen_dim    gen_gengru_rh_to_c_W  generator GRU, mapping from r+hidden to candidates, weights  c_gen_dim  x  c_gen_dim    gen_gengru_rh_to_c_b  generator GRU, mapping from r+hidden to candidates, biases  1 x  c_gen_dim",
            "title": "Generator RNN"
        },
        {
            "location": "/trained-params/#generator-output",
            "text": "Name  Description  Size      gen_to_factors_W  mapping from generator to factors, weights  c_gen_dim  x  c_factors_dim    factors_to_logrates_W  readout alignment weights  nDatasets  x 1 cell of  c_factors_dim  x  nNeuronsThisDataset    factors_to_logrates_b  readout alignment biases  nDatasets  x 1 cell of 1 x  nNeuronsThisDataset",
            "title": "Generator output"
        },
        {
            "location": "/trained-params/#loading-model_params-for-lorenz-example",
            "text": "We can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with  c_co_dim == 0 .  >>   mtp   =   rc . findRuns ( 'all' ,   1 ). loadModelTrainedParams ()  ans   = \n\n   ModelTrainedParams   with   properties : \n\n    Read - in   from   spikes   to   input   factors \n                        x_to_infac_W :   { 3 x1   cell } \n                        x_to_infac_b :   { 3 x1   cell } \n\n    Initial   condition   encoder   ( forward ) \n                       ic_enc_fwd_t0 :   [ 64 x1   single ] \n     ic_enc_fwd_gru_xh_to_gates_ru_W :   [ 128 x72   single ] \n     ic_enc_fwd_gru_xh_to_gates_ru_b :   [ 128 x1   single ] \n           ic_enc_fwd_gru_xrh_to_c_W :   [ 64 x72   single ] \n           ic_enc_fwd_gru_xrh_to_c_b :   [ 64 x1   single ] \n\n    Initial   condition   encoder   ( reverse ) \n                       ic_enc_rev_t0 :   [ 64 x1   single ] \n     ic_enc_rev_gru_xh_to_gates_ru_W :   [ 128 x72   single ] \n     ic_enc_rev_gru_xh_to_gates_ru_b :   [ 128 x1   single ] \n           ic_enc_rev_gru_xrh_to_c_W :   [ 64 x72   single ] \n           ic_enc_rev_gru_xrh_to_c_b :   [ 64 x1   single ] \n\n    Initial   condition   g0 \n                       prior_g0_mean :   [ 64 x1   single ] \n                     prior_g0_logvar :   [ 64 x1   single ] \n       ic_enc_to_posterior_g0_mean_W :   [ 64 x128   single ] \n       ic_enc_to_posterior_g0_mean_b :   [ 64 x1   single ] \n     ic_enc_to_posterior_g0_logvar_W :   [ 64 x128   single ] \n     ic_enc_to_posterior_g0_logvar_b :   [ 64 x1   single ] \n                      g0_to_gen_ic_W :   [] \n                      g0_to_gen_ic_b :   [] \n\n    Controller   encoder   ( forward ) \n                       ci_enc_fwd_t0 :   [] \n           ci_enc_fwd_gru_xh_to_ru_W :   [] \n           ci_enc_fwd_gru_xh_to_ru_b :   [] \n           ci_enc_fwd_gru_xrh_to_c_W :   [] \n           ci_enc_fwd_gru_xrh_to_c_b :   [] \n\n    Controller   encoder   ( reverse ) \n                       ci_enc_rev_t0 :   [] \n           ci_enc_rev_gru_xh_to_ru_W :   [] \n           ci_enc_rev_gru_xh_to_ru_b :   [] \n           ci_enc_rev_gru_xrh_to_c_W :   [] \n           ci_enc_rev_gru_xrh_to_c_b :   [] \n\n    Controlller   RNN \n                con_gengru_x_to_ru_W :   [] \n                con_gengru_h_to_ru_W :   [] \n                con_gengru_h_to_ru_b :   [] \n                 con_gengru_x_to_c_W :   [] \n                con_gengru_rh_to_c_W :   [] \n                con_gengru_rh_to_c_b :   [] \n\n    Controller   output   co \n                  prior_ar1_logevars :   [] \n                   prior_ar1_logatau :   [] \n                              con_co :   [] \n          con_to_posterior_co_mean_W :   [] \n          con_to_posterior_co_mean_b :   [] \n        con_to_posterior_co_logvar_W :   [] \n        con_to_posterior_co_logvar_b :   [] \n\n    Generator   RNN \n                gen_gengru_x_to_ru_W :   [] \n                gen_gengru_h_to_ru_W :   [ 128 x64   single ] \n                gen_gengru_h_to_ru_b :   [ 128 x1   single ] \n                 gen_gengru_x_to_c_W :   [] \n                gen_gengru_rh_to_c_W :   [ 64 x64   single ] \n                gen_gengru_rh_to_c_b :   [ 64 x1   single ] \n\n    Generator   output \n                    gen_to_factors_W :   [ 8 x64   single ] \n               factors_to_logrates_W :   { 3 x1   cell } \n               factors_to_logrates_b :   { 3 x1   cell }   The recurrent connectivity weight matrix of the  c_gen_dim==64  GRU generator RNN is given by  mtp.gen_gengru_rh_to_c_W :   And the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by  mtp.factors_to_logrates_W :",
            "title": "Loading model_params for Lorenz example"
        },
        {
            "location": "/files/",
            "text": "File organization used by LFADS Run Manager\n\u00b6\n\n\nYou won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to \nrunning your model\n.\n\n\nRun collection organization\n\u00b6\n\n\nAfter running \nMyExperiment.drive_script\n and calling \nrc.prepareForLFADS()\n, you\u2019ll see the following directory tree on your hard drive:\n\n\n$ tree -L \n4\n ~/lorenz_example/\n.\n\u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset003.mat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dataset004.mat\n\u2514\u2500\u2500 runs\n    \u2514\u2500\u2500 exampleRun\n        \u251c\u2500\u2500 data_RE1kuL\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 lfads_dataset003.h5\n        \u251c\u2500\u2500 param_Qr2PeG\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n        \u2514\u2500\u2500 summary.txt\n\n\n9\n directories, \n13\n files\n\n\n\n\n\n\ndatasets\n:\n\n\nInside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called \nLFADS.Utils.generateDemoDatasets(...)\n.\n\n\nruns\n:\n\n\n\n\nThe root runs folder you specified in the constructor to \nRunCollection\n.\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n\n\n\nexampleRun\n:\n\n\n\n\nThe location of this specific \nRunCollection\n, based on the name you passed to constructor of \nRunCollection\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n\n\n\ndata_RE1kuL\n:\n\n\n\n\nThe location of the exported datasets for \nRunParams\n whose data hash is \nRE1kuL\n. The data hash includes properties of \nRunParams\n that affect the exported data, as described \nhere\n. Each subfolder corresponds to the name of a \nRunSpec\n.\n\n\n\n\ninputInfo_datasetName.mat\n\n\nContains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets.\n\n\nlfads_datasetName.h5\n:\n\n\nThe spike counts data directly read by LFADS\n\n\n\n\n\n\n\n\nparam_Qr2PeG\n:\n    :   Location of the individual runs generated with the \nRunParams\n instance whose param hash is \nQr2PeG\n. The subfolders correspond to the run names passed to \nRunSpec\n, and their contents will be discussed below.\n        \nrc\n.\naddRunSpec\n(\nMyExperiment\n.\nRunSpec\n(\n'all'\n,\n \ndc\n,\n \n1\n:\ndc\n.\nnDatasets\n));\n\n\n\n\n\n\nlaunch_tensorboard.sh\n:\n\n\nShell script which will launch TensorBoard, optionally on a specific port\n\nsh launch_tensorboard.sh \n50000\n\n\n\n\nrun_lfadsqueue.py\n:\n\n\nPython script which will launch the LFADS Run Queue on all runs within the \nexampleRun\n \nRunCollection\n:\n\npython run_lfadsqueue.py\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual run folders\n\u00b6\n\n\nWithin an run folder, we find:\n\n\n$ tree ~/lorenz_example/runs/exampleRuns/param_Qr2PeG/all\n.\n\u251c\u2500\u2500 lfads.done\n\u251c\u2500\u2500 lfads.out\n\u251c\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_RE1kuL/all/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_RE1kuL/all/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_RE1kuL/all/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_RE1kuL/all/lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_RE1kuL/all/lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_RE1kuL/all/lfads_dataset003.h5\n\u251c\u2500\u2500 lfadsOutput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint_lve\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fitlog.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-0.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-38740.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 events.out...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_params\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average\n\u2514\u2500\u2500 lfads_train.sh\n\n\n\n\n\n\nlfadsInput\n:\n\n\nContains relative symbolic links to the contents of \ndata_RE1kuL\n, enabling multiple runs to share data without duplication. The \n.h5\n files will be read in by LFADS.\n\n\nlfadsOutput\n:\n\n\n\n\nThe directory to which LFADS will write generated output. Some of the key files within are:\n\n\n\n\ncheckpoint_lve\n:\n\n\nContains the saved checkpoint with the lowest validation error.\n\n\nfitlog.csv\n:\n\n\nContains information about the various costs through training\n\n\nhyperparameters-0.txt\n:\n\n\nRecords the hyperparameters used by LFADS\n\n\nmodel_runs_datasetName.h5_train_posterior_sample_and_average\n:\n\n\nContains the posterior mean samples and averages for the training trials\n\n\nmodel_runs_datasetName.h5_valid_posterior_sample_and_average\n:\n\n\nContains the posterior mean samples and averages for the validation trials\n\n\n\n\n\n\nlfads_train.sh\n:\n\n\nShell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager.\n\n\nlfads.done\n:\n\n\nEmpty text file indicating to the LFADS Run Queue that this model has already completed successfully\n\n\nlfads.out\n:\n\n\nLogged output of LFADS generated by the LFADS Run Queue\n\n\n\n\nClearing LFADS Output\n\u00b6\n\n\nIf you wanted to re-train a model from scratch, you can call \nrun.deleteLFADSOutput()\n from Matlab, or you could manually delete the \nlfadsOutput\n folder, \nlfads.done\n, and \nlfads.out\n.",
            "title": "File Organization"
        },
        {
            "location": "/files/#file-organization-used-by-lfads-run-manager",
            "text": "You won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to  running your model .",
            "title": "File organization used by LFADS Run Manager"
        },
        {
            "location": "/files/#run-collection-organization",
            "text": "After running  MyExperiment.drive_script  and calling  rc.prepareForLFADS() , you\u2019ll see the following directory tree on your hard drive:  $ tree -L  4  ~/lorenz_example/\n.\n\u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset003.mat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dataset004.mat\n\u2514\u2500\u2500 runs\n    \u2514\u2500\u2500 exampleRun\n        \u251c\u2500\u2500 data_RE1kuL\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 lfads_dataset003.h5\n        \u251c\u2500\u2500 param_Qr2PeG\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfadsInput\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 lfadsInput\n        \u2514\u2500\u2500 summary.txt 9  directories,  13  files   datasets :  Inside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called  LFADS.Utils.generateDemoDatasets(...) .  runs :   The root runs folder you specified in the constructor to  RunCollection . runRoot   =   '~/lorenz_example/runs' ;  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );    exampleRun :   The location of this specific  RunCollection , based on the name you passed to constructor of  RunCollection  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );    data_RE1kuL :   The location of the exported datasets for  RunParams  whose data hash is  RE1kuL . The data hash includes properties of  RunParams  that affect the exported data, as described  here . Each subfolder corresponds to the name of a  RunSpec .   inputInfo_datasetName.mat  Contains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets.  lfads_datasetName.h5 :  The spike counts data directly read by LFADS     param_Qr2PeG :\n    :   Location of the individual runs generated with the  RunParams  instance whose param hash is  Qr2PeG . The subfolders correspond to the run names passed to  RunSpec , and their contents will be discussed below.\n         rc . addRunSpec ( MyExperiment . RunSpec ( 'all' ,   dc ,   1 : dc . nDatasets ));    launch_tensorboard.sh :  Shell script which will launch TensorBoard, optionally on a specific port sh launch_tensorboard.sh  50000   run_lfadsqueue.py :  Python script which will launch the LFADS Run Queue on all runs within the  exampleRun   RunCollection : python run_lfadsqueue.py",
            "title": "Run collection organization"
        },
        {
            "location": "/files/#individual-run-folders",
            "text": "Within an run folder, we find:  $ tree ~/lorenz_example/runs/exampleRuns/param_Qr2PeG/all\n.\n\u251c\u2500\u2500 lfads.done\n\u251c\u2500\u2500 lfads.out\n\u251c\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_RE1kuL/all/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_RE1kuL/all/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_RE1kuL/all/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_RE1kuL/all/lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_RE1kuL/all/lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_RE1kuL/all/lfads_dataset003.h5\n\u251c\u2500\u2500 lfadsOutput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint_lve\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fitlog.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-0.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-38740.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 events.out...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_params\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average\n\u2514\u2500\u2500 lfads_train.sh   lfadsInput :  Contains relative symbolic links to the contents of  data_RE1kuL , enabling multiple runs to share data without duplication. The  .h5  files will be read in by LFADS.  lfadsOutput :   The directory to which LFADS will write generated output. Some of the key files within are:   checkpoint_lve :  Contains the saved checkpoint with the lowest validation error.  fitlog.csv :  Contains information about the various costs through training  hyperparameters-0.txt :  Records the hyperparameters used by LFADS  model_runs_datasetName.h5_train_posterior_sample_and_average :  Contains the posterior mean samples and averages for the training trials  model_runs_datasetName.h5_valid_posterior_sample_and_average :  Contains the posterior mean samples and averages for the validation trials    lfads_train.sh :  Shell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager.  lfads.done :  Empty text file indicating to the LFADS Run Queue that this model has already completed successfully  lfads.out :  Logged output of LFADS generated by the LFADS Run Queue",
            "title": "Individual run folders"
        },
        {
            "location": "/files/#clearing-lfads-output",
            "text": "If you wanted to re-train a model from scratch, you can call  run.deleteLFADSOutput()  from Matlab, or you could manually delete the  lfadsOutput  folder,  lfads.done , and  lfads.out .",
            "title": "Clearing LFADS Output"
        }
    ]
}