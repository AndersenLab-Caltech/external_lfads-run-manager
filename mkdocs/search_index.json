{
    "docs": [
        {
            "location": "/",
            "text": "LFADS Run Manager for Matlab Documentation\n\u00b6\n\n\nLFADS Run Manager is a set of tools, written in Matlab, that work with the \nPython+Tensorflow LFADS code\n to accomplish the following. LFADS, or Latent Factor Analysis via Dynamical Systems, is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018de-noised\u2019 single-trial firing rates from neural spiking data.\n\n\nRead the \nLFADS pre-print\n for more details.\n\n\nLFADS Run Manager helps you to:\n\n\n\n\nOrganize your spiking neural datasets that will be used to train LFADS models.\n\n\nSetup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating \nstitched\n multisession LFADS models.\n\n\nGenerate shell scripts that will launch individual LFADS training runs \nor\n generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs.\n\n\nLoad the posterior means and parameters of individual LFADS models after each has finished training.\n\n\nFacilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc.\n\n\n\n\nThe code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on \nGithub\n.\n\n\nTo use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. We note that to use LFADS in any context, one would need to author this dataset specific code anyway.\n\n\nThe goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk.\n\n\nQuick example\n\u00b6\n\n\nWe\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs.\n\n\n% Identify the datasets you'll be using\n\n\ndc\n \n=\n \nMyExperiment\n.\nDatasetCollection\n(\n'~/lorenz_example/datasets'\n);\n\n\ndc\n.\nname\n \n=\n \n'lorenz_example'\n;\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset002.mat'\n);\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset003.mat'\n);\n\n\ndc\n.\nloadInfo\n;\n\n\n\n% Run a single model for each dataset, and one stitched run with all datasets\n\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n% Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8\n\n\npar\n \n=\n \nMyExperiment\n.\nRunParams\n;\n\n\npar\n.\nspikeBinMs\n \n=\n \n2\n;\n \n% rebin the data at 2 ms\n\n\npar\n.\nc_co_dim\n \n=\n \n0\n;\n \n% no controller --> no inputs to generator\n\n\npar\n.\nc_batch_size\n \n=\n \n150\n;\n \n% must be < 1/5 of the min trial count\n\n\npar\n.\nuseAlignmentMatrix\n \n=\n \ntrue\n;\n \n% use alignment matrices initial guess for multisession stitching\n\n\npar\n.\nc_gen_dim\n \n=\n \n64\n;\n \n% number of units in generator RNN\n\n\npar\n.\nc_ic_enc_dim\n \n=\n \n64\n;\n \n% number of units in encoder RNN\n\n\npar\n.\nc_learning_rate_stop\n \n=\n \n1e-3\n;\n \n% we can stop really early for the demo\n\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_factors_dim'\n,\n \n[\n2\n \n4\n \n6\n \n8\n]);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n% Setup which datasets are included in each run, 1 for each dataset individually\n\n\nfor\n \niR\n \n=\n \n1\n:\ndc\n.\nnDatasets\n\n    \nrc\n.\naddRunSpec\n(\nMyExperiment\n.\nRunSpec\n(\ndc\n.\ndatasets\n(\niR\n).\ngetSingleRunName\n(),\n \ndc\n,\n \ndc\n.\ndatasets\n(\niR\n).\nname\n));\n\n\nend\n\n\n% and the final stitching run with all datasets\n\n\nrc\n.\naddRunSpec\n(\nMyExperiment\n.\nRunSpec\n(\n'all'\n,\n \ndc\n,\n \n1\n:\ndc\n.\nnDatasets\n));\n\n\n\n% Generate files needed for LFADS input on disk\n\n\nrc\n.\nprepareForLFADS\n();\n\n\n\n% Write a python script that will train all of the LFADS runs using a\n\n\n% load-balancer against the available CPUs and GPUs\n\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'display'\n,\n \n50\n,\n \n'maxTasksSimultaneously'\n,\n \n4\n,\n \n'gpuList'\n,\n \n[\n0\n \n1\n],\n \n'virtualenv'\n,\n \ntensorflow\n);\n\n\n\n\n\nYou\u2019ve now setup a 4 x 4 grid of LFADS runs, spanning 4 different hyperparameter settings and 4 different dataset subsets (3 with one dataset, 1 stitching together all datasets).\n\n\n>>\n \nrc\n\n\n\nMyExperiment\n.\nRunCollection\n \"\nexampleRun\n\" \n(\n16\n \nruns\n \ntotal\n)\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n3\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleRun\n\n\n  \n4\n \nparameter\n \nsettings\n\n  \n[\n1\n \nparam_7I6XSW\n \ndata_\n-\nMSPr6\n]\n \nMyExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n2\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n  \n[\n2\n \nparam_O4V73g\n \ndata_\n-\nMSPr6\n]\n \nMyExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n4\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n  \n[\n3\n \nparam_ngqEhM\n \ndata_\n-\nMSPr6\n]\n \nMyExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n6\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n  \n[\n4\n \nparam_Qr2PeG\n \ndata_\n-\nMSPr6\n]\n \nMyExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n  \n4\n \nrun\n \nspecifications\n\n  \n[\n \n1\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset001\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n2\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset002\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n3\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset003\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n4\n]\n \nMyExperiment\n.\nRunSpec\n \"\nall\n\" \n(\n3\n \ndatasets\n)\n\n\n                          \nname\n:\n \n'exampleRun'\n\n                       \ncomment\n:\n \n''\n\n                      \nrootPath\n:\n \n'~/lorenz_example/runs'\n\n                       \nversion\n:\n \n3\n\n             \ndatasetCollection\n:\n \n[\n1\nx1\n \nMyExperiment\n.\nDatasetCollection\n]\n\n                          \nruns\n:\n \n[\n4\nx4\n \nMyExperiment\n.\nRun\n]\n\n                        \nparams\n:\n \n[\n4\nx1\n \nMyExperiment\n.\nRunParams\n]\n\n                      \nrunSpecs\n:\n \n[\n4\nx1\n \nMyExperiment\n.\nRunSpec\n]\n\n                       \nnParams\n:\n \n4\n\n                     \nnRunSpecs\n:\n \n4\n\n                    \nnRunsTotal\n:\n \n16\n\n                     \nnDatasets\n:\n \n3\n\n                  \ndatasetNames\n:\n \n{\n3\nx1\n \ncell\n}\n\n                          \npath\n:\n \n'~/lorenz_example/runs/exampleRun'\n\n      \npathsCommonDataForParams\n:\n \n{\n4\nx1\n \ncell\n}\n\n                \npathsForParams\n:\n \n{\n4\nx1\n \ncell\n}\n\n    \nfileShellScriptTensorboard\n:\n \n'~/lorenz_example/runs/exampleRun/launch_tensorboard.sh'\n\n               \nfileSummaryText\n:\n \n'~/lorenz_example/runs/exampleRun/summary.txt'\n\n       \nfileShellScriptRunQueue\n:\n \n'~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'\n\n\n\n\n\nThen you can simply run \npython run_lfadsqueue.py\n, a script which was automatically genrated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026\n\n\nAs they finish, you can load and visualize the results easily in Matlab. Here we plot the smoothed rates\n\n\nrun\n \n=\n \nrc\n.\nruns\n(\n'single_dataset001'\n,\n \n1\n);\n\n\npm\n \n=\n \nrun\n.\nloadPosteriorMeans\n();\n\n\nrates1\n \n=\n \nsqueeze\n(\npm\n.\nrates\n(\n1\n,\n \n:,\n \n:));\n \n% time x trials\n\n\n...\n\n\n\n\n\nThe single-trial smoothed rates, colored by condition then look like:",
            "title": "Overview"
        },
        {
            "location": "/#lfads-run-manager-for-matlab-documentation",
            "text": "LFADS Run Manager is a set of tools, written in Matlab, that work with the  Python+Tensorflow LFADS code  to accomplish the following. LFADS, or Latent Factor Analysis via Dynamical Systems, is a deep learning method to infer latent dynamics from single-trial neural spiking data. LFADS uses a nonlinear dynamical system (a recurrent neural network) to infer the dynamics underlying observed population activity and to extract \u2018de-noised\u2019 single-trial firing rates from neural spiking data.  Read the  LFADS pre-print  for more details.  LFADS Run Manager helps you to:   Organize your spiking neural datasets that will be used to train LFADS models.  Setup a collection of training runs that vary in hyperparameter settings and the particular datasets included. The latter is particularly useful when generating  stitched  multisession LFADS models.  Generate shell scripts that will launch individual LFADS training runs  or  generate a script that will run the full set of runs somewhat in parallel by load balancing across GPUs and CPUs.  Load the posterior means and parameters of individual LFADS models after each has finished training.  Facilitate analysis, visualization, and comparison of the learned LFADS model generated factors, rates, etc.   The code within the run manager helps organize LFADS runs and facilitate analysis, but ultimately calls the Python+Tensorflow LFADS code available on  Github .  To use the run manager, you will need to author a few functions that perform specific data processing steps that are specific to your datasets, such as extracting spike times. We note that to use LFADS in any context, one would need to author this dataset specific code anyway.  The goal of the run manager is to facilitate the above common tasks in a fairly dataset agnostic way, sparing you the need to hand-generate many one-off scripts to export data to HD5 in the right locations, drive the Tensorflow training, and to load the results from disk.",
            "title": "LFADS Run Manager for Matlab Documentation"
        },
        {
            "location": "/#quick-example",
            "text": "We\u2019ll walkthrough this example in more detail in this documentation, but to give you an idea of how the run manager works, here\u2019s the Matlab code you\u2019d use to launch a couple of runs.  % Identify the datasets you'll be using  dc   =   MyExperiment . DatasetCollection ( '~/lorenz_example/datasets' );  dc . name   =   'lorenz_example' ;  MyExperiment . Dataset ( dc ,   'dataset001.mat' );  MyExperiment . Dataset ( dc ,   'dataset002.mat' );  MyExperiment . Dataset ( dc ,   'dataset003.mat' );  dc . loadInfo ;  % Run a single model for each dataset, and one stitched run with all datasets  runRoot   =   '~/lorenz_example/runs' ;  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );  % Setup hyperparameters, 4 sets with number of factors swept through 2,4,6,8  par   =   MyExperiment . RunParams ;  par . spikeBinMs   =   2 ;   % rebin the data at 2 ms  par . c_co_dim   =   0 ;   % no controller --> no inputs to generator  par . c_batch_size   =   150 ;   % must be < 1/5 of the min trial count  par . useAlignmentMatrix   =   true ;   % use alignment matrices initial guess for multisession stitching  par . c_gen_dim   =   64 ;   % number of units in generator RNN  par . c_ic_enc_dim   =   64 ;   % number of units in encoder RNN  par . c_learning_rate_stop   =   1e-3 ;   % we can stop really early for the demo  parSet   =   par . generateSweep ( 'c_factors_dim' ,   [ 2   4   6   8 ]);  rc . addParams ( parSet );  % Setup which datasets are included in each run, 1 for each dataset individually  for   iR   =   1 : dc . nDatasets \n     rc . addRunSpec ( MyExperiment . RunSpec ( dc . datasets ( iR ). getSingleRunName (),   dc ,   dc . datasets ( iR ). name ));  end  % and the final stitching run with all datasets  rc . addRunSpec ( MyExperiment . RunSpec ( 'all' ,   dc ,   1 : dc . nDatasets ));  % Generate files needed for LFADS input on disk  rc . prepareForLFADS ();  % Write a python script that will train all of the LFADS runs using a  % load-balancer against the available CPUs and GPUs  rc . writeShellScriptRunQueue ( 'display' ,   50 ,   'maxTasksSimultaneously' ,   4 ,   'gpuList' ,   [ 0   1 ],   'virtualenv' ,   tensorflow );   You\u2019ve now setup a 4 x 4 grid of LFADS runs, spanning 4 different hyperparameter settings and 4 different dataset subsets (3 with one dataset, 1 stitching together all datasets).  >>   rc  MyExperiment . RunCollection  \" exampleRun \"  ( 16   runs   total ) \n   Dataset   Collection  \" lorenz_example \"  ( 3   datasets )   in   ~/ lorenz_example / datasets \n   Path :   ~/ lorenz_example / runs / exampleRun \n\n   4   parameter   settings \n   [ 1   param_7I6XSW   data_ - MSPr6 ]   MyExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 2   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n   [ 2   param_O4V73g   data_ - MSPr6 ]   MyExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 4   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n   [ 3   param_ngqEhM   data_ - MSPr6 ]   MyExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 6   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n   [ 4   param_Qr2PeG   data_ - MSPr6 ]   MyExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001 \n\n   4   run   specifications \n   [   1 ]   MyExperiment . RunSpec  \" single_dataset001 \"  ( 1   datasets ) \n   [   2 ]   MyExperiment . RunSpec  \" single_dataset002 \"  ( 1   datasets ) \n   [   3 ]   MyExperiment . RunSpec  \" single_dataset003 \"  ( 1   datasets ) \n   [   4 ]   MyExperiment . RunSpec  \" all \"  ( 3   datasets ) \n\n                           name :   'exampleRun' \n                        comment :   '' \n                       rootPath :   '~/lorenz_example/runs' \n                        version :   3 \n              datasetCollection :   [ 1 x1   MyExperiment . DatasetCollection ] \n                           runs :   [ 4 x4   MyExperiment . Run ] \n                         params :   [ 4 x1   MyExperiment . RunParams ] \n                       runSpecs :   [ 4 x1   MyExperiment . RunSpec ] \n                        nParams :   4 \n                      nRunSpecs :   4 \n                     nRunsTotal :   16 \n                      nDatasets :   3 \n                   datasetNames :   { 3 x1   cell } \n                           path :   '~/lorenz_example/runs/exampleRun' \n       pathsCommonDataForParams :   { 4 x1   cell } \n                 pathsForParams :   { 4 x1   cell } \n     fileShellScriptTensorboard :   '~/lorenz_example/runs/exampleRun/launch_tensorboard.sh' \n                fileSummaryText :   '~/lorenz_example/runs/exampleRun/summary.txt' \n        fileShellScriptRunQueue :   '~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'   Then you can simply run  python run_lfadsqueue.py , a script which was automatically genrated to fire off all the LFADS jobs in parallel, load-balancing as many as your system can handle across available GPUs. Then wait a few hours/days\u2026  As they finish, you can load and visualize the results easily in Matlab. Here we plot the smoothed rates  run   =   rc . runs ( 'single_dataset001' ,   1 );  pm   =   run . loadPosteriorMeans ();  rates1   =   squeeze ( pm . rates ( 1 ,   :,   :));   % time x trials  ...   The single-trial smoothed rates, colored by condition then look like:",
            "title": "Quick example"
        },
        {
            "location": "/install/",
            "text": "Installation\n\u00b6\n\n\nInstall TensorFlow\n\u00b6\n\n\nYou\u2019ll need to install TensorFlow to run LFADS. Follow the \ndocumentation for installing Tensorflow\n. You may wish to install everything in a Python \nvirtualenv\n, which is supported by \nlfads-run-manager\n. Be sure to test that you can \nimport\n \ntensorflow\n in Python correctly:\n\n\n# Python\n\n\nimport\n \ntensorflow\n \nas\n \ntf\n\n\nhello\n \n=\n \ntf\n.\nconstant\n(\n'Hello, TensorFlow!'\n)\n\n\nsess\n \n=\n \ntf\n.\nSession\n()\n\n\nprint\n(\nsess\n.\nrun\n(\nhello\n))\n\n\n\n\n\nWhich should output:\n\nHello, TensorFlow!\n\n\n\nInstall LFADS\n\u00b6\n\n\nYou\u2019ll then need to clone the \nTensorflow models repo containing LFADS\n somewhere convenient on your system.\n\n\ngit clone https://github.com/tensorflow/models.git\n\n\n\n\nThen add this LFADS folder both to your \nPYTHONPATH\n and system \nPATH\n. Add the following to your \n.bashrc\n:\n\nexport\n \nPYTHONPATH\n=\n$PYTHONPATH\n:/path/to/models/research/lfads/\n\nexport\n \nPATH\n=\n$PATH\n:/path/to/models/research/lfads/\n\n\n\nEnsure that typing \nwhich run_lfads.py\n at your terminal prompt shows the path to \nrun_lfads.py\n.\n\n\nInstall tmux\n\u00b6\n\n\nLFADS Run manager uses tmux to run LFADS within to enable queuing of many runs and online monitoring. Fortunately installing tmux is pretty straightforward on most distributions.\n\n\n\n\nUbuntu: \nsudo apt-get install tmux\n\n\nMac: \nbrew install tmux\n using \nHomebrew\n.\n\n\n\n\nThere are many nice guides to using \ntmux\n:\n\n\n\n\nA Quick and Easy Guide to tmux - Ham Vocke\n\n\nA tmux Crash Course - Josh Clayton\n\n\n\n\nInstall LFADS Run Manager\n\u00b6\n\n\nFinally, clone the lfads-run-manager repository somewhere convenient on your system.\n\n\ngit clone https://github.com/djoshea/lfads-run-manager.git\n\n\n\n\nYou\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using \npathtool\n or by running:\n\n\naddpath\n(\n'/path/to/lfads-run-manager'\n)\n\n\n\n\n\nNo need to add path recursively.",
            "title": "Installation"
        },
        {
            "location": "/install/#installation",
            "text": "",
            "title": "Installation"
        },
        {
            "location": "/install/#install-tensorflow",
            "text": "You\u2019ll need to install TensorFlow to run LFADS. Follow the  documentation for installing Tensorflow . You may wish to install everything in a Python  virtualenv , which is supported by  lfads-run-manager . Be sure to test that you can  import   tensorflow  in Python correctly:  # Python  import   tensorflow   as   tf  hello   =   tf . constant ( 'Hello, TensorFlow!' )  sess   =   tf . Session ()  print ( sess . run ( hello ))   Which should output: Hello, TensorFlow!",
            "title": "Install TensorFlow"
        },
        {
            "location": "/install/#install-lfads",
            "text": "You\u2019ll then need to clone the  Tensorflow models repo containing LFADS  somewhere convenient on your system.  git clone https://github.com/tensorflow/models.git  Then add this LFADS folder both to your  PYTHONPATH  and system  PATH . Add the following to your  .bashrc : export   PYTHONPATH = $PYTHONPATH :/path/to/models/research/lfads/ export   PATH = $PATH :/path/to/models/research/lfads/  Ensure that typing  which run_lfads.py  at your terminal prompt shows the path to  run_lfads.py .",
            "title": "Install LFADS"
        },
        {
            "location": "/install/#install-tmux",
            "text": "LFADS Run manager uses tmux to run LFADS within to enable queuing of many runs and online monitoring. Fortunately installing tmux is pretty straightforward on most distributions.   Ubuntu:  sudo apt-get install tmux  Mac:  brew install tmux  using  Homebrew .   There are many nice guides to using  tmux :   A Quick and Easy Guide to tmux - Ham Vocke  A tmux Crash Course - Josh Clayton",
            "title": "Install tmux"
        },
        {
            "location": "/install/#install-lfads-run-manager",
            "text": "Finally, clone the lfads-run-manager repository somewhere convenient on your system.  git clone https://github.com/djoshea/lfads-run-manager.git  You\u2019ll need to have Matlab installed. Then you can add the root folder of the lfads-run-manager to your Matlab path, either using  pathtool  or by running:  addpath ( '/path/to/lfads-run-manager' )   No need to add path recursively.",
            "title": "Install LFADS Run Manager"
        },
        {
            "location": "/matlab/",
            "text": "Matlab language features used\n\u00b6\n\n\nMatlab Classes\n\u00b6\n\n\nThe run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. While there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks here (XXX). In writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though \nit is not necessary to deeply understand classes in Matlab in order to get up and running\n.\n\n\nIf you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a \nstruct\n type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term \nclass\n refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an \ninstance\n, and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class.\n\n\ny\n \n=\n \n3.0\n;\n\n\nmyInstance\n \n=\n \nMyClass\n();\n\n\n\n\n\nIn this code, \ny\n is a normal Matlab variable whose type is \ndouble\n (double-precision floating point). \nmyInstance\n is an instance whose type is the class \nMyClass\n.\n\n\nFor illustration of a complete class definition, consider a class \nMultiplier\n whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file \nMulitplier.m\n as follows:\n\n\nclassdef\n \nMultiplier\n \n<\n \nhandle\n\n    \nproperties\n\n        \ngain\n \n=\n \n1\n;\n \n% constant by which inputs are multiplied\n\n    \nend\n\n\n    \nmethods\n\n        \n% this method is called a constructor, and will be called when creating\n\n        \n% new instances of this class. Here we provide a way to specify the gain\n\n        \n% when creating the instance\n\n\n        function\n \nobj \n=\n \nMultiplier\n(\ntheGain\n)\n\n\n            \nif\n \nnargin\n \n>\n \n1\n\n                \nobj\n.\ngain\n \n=\n \ntheGain\n;\n\n            \nend\n\n        \nend\n\n\n        \n% this method does the actual multiplication. The first argument always refers\n\n        \n% to the instance variable itself, enabling you to refer to properties and other\n\n        \n% methods in that instance. Otherwise, the code acts like a normal Matlab function\n\n\n        function\n \nout \n=\n \nmutliply\n(\nobj, in\n)\n\n\n            \nout\n \n=\n \nin\n \n*\n \nobj\n.\ngain\n;\n\n        \nend\n\n    \nend\n\n\nend\n\n\n\n\n\nWith this definition complete, we can then use the class at the command line as follows:\n\n\n>>\n \nmyMult\n \n=\n \nMultiplier\n(\n5\n);\n\n\n>>\n \nmyMult\n.\nmultiply\n(\n10\n)\n\n\n50\n\n\n>>\n \nmyOtherMult\n \n=\n \nMultiplier\n(\n2\n);\n\n\n>>\n \nmyOtherMult\n.\nmultiply\n(\n10\n)\n\n\n20\n\n\n>>\n \nmyMult\n.\ngain\n \n=\n \n3\n;\n \n% only affects myMult, not myOtherMult\n\n\n>>\n \nmyMult\n.\nmultiply\n(\n10\n)\n\n\n30\n\n\n>>\n \nmyOtherMult\n.\nmultiply\n(\n10\n)\n\n\n20\n\n\n\n\n\nHere, note that \nmyMult\n is a Matlab variable which holds an instance of the class \nMutliplier\n. We then assign a value to the property \ngain\n of this instance, and then call the method \nmultiply\n.\n\n\nMatlab packages\n\u00b6\n\n\nThe run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a \n+\n. Within Matlab, you will then refer to these classes by prefixing the class names with the package name, followed by a \n.\n. So within Matlab, \nLFADS.Run\n refers to the class located on the file system at \n+LFADS/Run.m\n.\n\n\nThe main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called \n+ReachingTask\n, and within it copy the starter code provided. Then you can refer to \nReachingTask.Dataset\n and \nReachingTask.Run\n from within Matlab.",
            "title": "Matlab Classes and Packages"
        },
        {
            "location": "/matlab/#matlab-language-features-used",
            "text": "",
            "title": "Matlab language features used"
        },
        {
            "location": "/matlab/#matlab-classes",
            "text": "The run manager code is written in and will be executed within Matlab. The code is organized around Matlab classes, which are part of Matlab\u2019s very well developed object oriented programming functionality. While there are technical differences, classes in Matlab work similarly to classes in Java and other object-oriented languages, and are very well documented by Mathworks here (XXX). In writing the small amount of code needed to use the run manager with your own data, you will be overriding a small number of methods in classes that will inherit from the LFADS classes, though  it is not necessary to deeply understand classes in Matlab in order to get up and running .  If you are not familiar with object-oriented programming, the basic concept is that a class is a sort of fusion between a  struct  type (with its associated data fields, called properties), and a set of associated functions (called methods) that are defined to operate on a class\u2019s data. The term  class  refers to the specification which defines the property names and the methods. A specific variable that holds actual data is referred to as an  instance , and can be created, manipulated, and passed around in Matlab by its variable name. In the lingo of object-oriented programming, an instance is a variable whose type is some class.  y   =   3.0 ;  myInstance   =   MyClass ();   In this code,  y  is a normal Matlab variable whose type is  double  (double-precision floating point).  myInstance  is an instance whose type is the class  MyClass .  For illustration of a complete class definition, consider a class  Multiplier  whose job is simply to multiply numbers by a fixed constant. The definition of the class is located in a file  Mulitplier.m  as follows:  classdef   Multiplier   <   handle \n     properties \n         gain   =   1 ;   % constant by which inputs are multiplied \n     end \n\n     methods \n         % this method is called a constructor, and will be called when creating \n         % new instances of this class. Here we provide a way to specify the gain \n         % when creating the instance          function   obj  =   Multiplier ( theGain )               if   nargin   >   1 \n                 obj . gain   =   theGain ; \n             end \n         end \n\n         % this method does the actual multiplication. The first argument always refers \n         % to the instance variable itself, enabling you to refer to properties and other \n         % methods in that instance. Otherwise, the code acts like a normal Matlab function          function   out  =   mutliply ( obj, in )               out   =   in   *   obj . gain ; \n         end \n     end  end   With this definition complete, we can then use the class at the command line as follows:  >>   myMult   =   Multiplier ( 5 );  >>   myMult . multiply ( 10 )  50  >>   myOtherMult   =   Multiplier ( 2 );  >>   myOtherMult . multiply ( 10 )  20  >>   myMult . gain   =   3 ;   % only affects myMult, not myOtherMult  >>   myMult . multiply ( 10 )  30  >>   myOtherMult . multiply ( 10 )  20   Here, note that  myMult  is a Matlab variable which holds an instance of the class  Mutliplier . We then assign a value to the property  gain  of this instance, and then call the method  multiply .",
            "title": "Matlab Classes"
        },
        {
            "location": "/matlab/#matlab-packages",
            "text": "The run manager code is also organized within Matlab packages. Packages are a way of organizing code that are used in many other programming languages, such as Java and Python. In Matlab, a package is simply a folder that begins with a  + . Within Matlab, you will then refer to these classes by prefixing the class names with the package name, followed by a  . . So within Matlab,  LFADS.Run  refers to the class located on the file system at  +LFADS/Run.m .  The main advantage to using packages is that it keeps the namespace organized. This enables you to have multiple things with the same name on the Matlab path while referring to them uniquely with the package name prefix. To use with LFADS run manager with your data, you will probably want to create your own package to organize this code. So, for example if you had a type of experimental data from a reaching task, you might create a folder somewhere on the Matlab path called  +ReachingTask , and within it copy the starter code provided. Then you can refer to  ReachingTask.Dataset  and  ReachingTask.Run  from within Matlab.",
            "title": "Matlab packages"
        },
        {
            "location": "/concepts/",
            "text": "Key Concepts\n\u00b6\n\n\nThe run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab.\n\n\nLFADS.Dataset\n\u00b6\n\n\nA \nDataset\n instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session.\n\n\nLFADS.DatasetCollection\n\u00b6\n\n\nA \nDatasetCollection\n is a set or array of one or more datasets.\n\n\nLFADS.RunSpec\n\u00b6\n\n\nA \nRunSpec\n, short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a \nstitched\n model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models.\n\n\nLFADS.RunParams\n\u00b6\n\n\nA \nRunParams\n encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates.\n\n\nWhen adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a \ntimeWindowPre\n and \ntimeWindowPost\n that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g. \nkeepSuccessTrialsOnly\n or \nincludePerturbationTrials\n.\n\n\nThe advantage of including your dataset-specific hyperparameters in your \nRunParams\n subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters.\n\n\nLFADS.Run\n\u00b6\n\n\nA \nRun\n encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An \nRun\n is defined by the combination of an \nRunSpec\n instance (which specifies the datasets included) and an \nRunParams\n instance (which specifies the hyperparameters). Each \nRun\n will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model.\n\n\nLFADS.RunCollection\n\u00b6\n\n\nA \nRunCollection\n is a set of one or more \nLFADS.Run\ns. This collection is organized as a two-dimensional matrix of runs.\n\n\nThe first dimension of this matrix is specified by an array of \nLFADS.RunSpec\n instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10 \nLFADS.RunSpec\ns, each specifying an individual dataset to be included.\n\n\nThe second dimension of this matrix is specified by an array of \nLFADS.RunParams\n instances. This enables you to vary hyperparameter settings across the runs.\n\n\nEach cell of this matrix, defined by a particular \nRunSpec\n and \nRunParams\n combination defines a specific \nRun\n which can then be generated and trained using Tensorflow.",
            "title": "Key Concepts"
        },
        {
            "location": "/concepts/#key-concepts",
            "text": "The run manager defines a small set of key classes that encapsulate specific concepts within LFADS and enable you to organize datasets and LFADS models effectively within Matlab.",
            "title": "Key Concepts"
        },
        {
            "location": "/concepts/#lfadsdataset",
            "text": "A  Dataset  instance represents a collection of trials with associated neural spiking channels. One or more datasets will be used by LFADS to train and evaluate the model. An individual dataset would include simultaneously recorded neural signals collected during one day or one experimental session.",
            "title": "LFADS.Dataset"
        },
        {
            "location": "/concepts/#lfadsdatasetcollection",
            "text": "A  DatasetCollection  is a set or array of one or more datasets.",
            "title": "LFADS.DatasetCollection"
        },
        {
            "location": "/concepts/#lfadsrunspec",
            "text": "A  RunSpec , short for run specification, defines which of the datasets within a dataset collection will be included as input to a specific LFADS model. Typically, only one dataset is specified. If multiple datasets are specified, the resulting LFADS model will be a  stitched  model which uses alignment matrices. Stitched models share a common generator to generate spiking data collected in different experimental sessions. Refer to the LFADS paper for more information on stitched models.",
            "title": "LFADS.RunSpec"
        },
        {
            "location": "/concepts/#lfadsrunparams",
            "text": "A  RunParams  encapsulates the hyperparameters of an LFADS run. Most of these hyperparameters are fed directly to the Python+Tensorflow LFADS code and are defined in the LFADS paper. Examples are the size of the generator RNN and the dropout probability during training. Another key parameter is the bin width used to convert spike times into time-varying spike rates.  When adapting the run manager to work with your datasets, you are encouraged to include your own hyperparameters that can be used to specify the way data is extracted and processed from your datasets. For example, you might wish to define a  timeWindowPre  and  timeWindowPost  that specify the window of time from each trial in which neural spiking data is extracted. Or you might wish to define hyperparameters that affect which trials are included, e.g.  keepSuccessTrialsOnly  or  includePerturbationTrials .  The advantage of including your dataset-specific hyperparameters in your  RunParams  subclass is that the values of these fields will then affect the hash value that is used to uniquely define individual LFADS runs on disk, enabling you to easily compare across sweeps of these hyperparameter settings just as you would with the built-in LFADS hyperparameters.",
            "title": "LFADS.RunParams"
        },
        {
            "location": "/concepts/#lfadsrun",
            "text": "A  Run  encapsulates an actual LFADS model that will be trained using Python+Tensorflow. An  Run  is defined by the combination of an  RunSpec  instance (which specifies the datasets included) and an  RunParams  instance (which specifies the hyperparameters). Each  Run  will be associated with a run of the Python+Tensorflow code that defines and trains the LFADS model.",
            "title": "LFADS.Run"
        },
        {
            "location": "/concepts/#lfadsruncollection",
            "text": "A  RunCollection  is a set of one or more  LFADS.Run s. This collection is organized as a two-dimensional matrix of runs.  The first dimension of this matrix is specified by an array of  LFADS.RunSpec  instances. This enables different datasets or sets of datasets to be used within each model. For example, if you had 10 datasets, you could run LFADS on each dataset individually by having 10  LFADS.RunSpec s, each specifying an individual dataset to be included.  The second dimension of this matrix is specified by an array of  LFADS.RunParams  instances. This enables you to vary hyperparameter settings across the runs.  Each cell of this matrix, defined by a particular  RunSpec  and  RunParams  combination defines a specific  Run  which can then be generated and trained using Tensorflow.",
            "title": "LFADS.RunCollection"
        },
        {
            "location": "/adapting/",
            "text": "Using LFADS Run Manager with your datasets\n\u00b6\n\n\nCopying the \nMyExperiment\n working example code\n\u00b6\n\n\nBelow we describe how to use the run manager code with datasets from a specific experiment. The recommended way to begin this process is to copy the folder \n+MyExperiment\n inside the\nlfads-run-manager\n repository to some other folder on your Matlab path, and then to rename it to something related to the experiment. Below, we\u2019ll use the name \nMyExperiment\n, which requires renaming the folder to \n+MyExperiment\n.\n\n\nEach of the classes you have just created are defined to inherit from the corresponding \nLFADS.ClassName\n inside the \nlfads-run-manager\n repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the \n+LFADS\n folder in the repo.\n\n\nEditing the core classes\n\u00b6\n\n\nHere we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are:\n\n\n\n\nloadData\n in \nDataset.m\n - specify how to load a dataset from disk. The default implementation assumes that the data live in a \n.mat\n file that can be loaded using \nload\n.\n\n\nconvertDatasetToSequenceStruct\n in \nRun.m\n  - preprocess data and perform spike binning\n\n\n\n\nEditing \nDatasetCollection.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+MyExperiment/DatasetCollection.m\n. Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor:\n\n\nfunction\n \nds \n=\n \nDatasetCollection\n(\npath\n)\n\n\n    \nds\n \n=\n \nds\n@\nLFADS\n.\nDatasetCollection\n(\npath\n);\n\n\nend\n\n\n\n\n\nYou may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run:\n\n\ndc\n \n=\n \nMyExperiment\n.\nDatasetCollection\n(\n'/path/to/experimentData'\n);\n\n\n\n\n\nThis path will then be used as the parent folder by all of the datasets that are added to this collection.\n\n\nBelow is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function \nfilterDatasets\n to specify the indices or mask over datasets to keep.\n\n\nfunction\n \nfilterHavingMinimumTrials\n(\ndc, minTrials\n)\n\n\n    \n% example of a function that will filter down datasets based on\n\n    \n% their metadata.\n\n    \nnTrials\n \n=\n \ncat\n(\n1\n,\n \ndc\n.\ndatasets\n.\nnTrials\n);\n\n\n    \n% filterDatasets is provided by DatasetCollection\n\n    \ndc\n.\nfilterDatasets\n(\nnTrials\n \n>\n=\n \nminTrials\n);\n\n\nend\n\n\n\n\n\nNo edits are necessary to \nDatasetCollection.m\n to get up and running\n, but feel free to add any additional methods or properties as needed for your application.\n\n\nEditing \nDataset.m\n \n(Required)\n\u00b6\n\n\nEdit the file \n+MyExperiment/Dataset.m\n. Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset.\n\n\nFirst, look at the constructor.\n\n\nfunction\n \nds \n=\n \nDataset\n(\ncollection, relPath\n)\n\n\n    \nds\n \n=\n \nds\n@\nLFADS\n.\nDataset\n(\ncollection\n,\n \nrelPath\n);\n\n\nend\n\n\n\n\n\nIn order to encapsulate a particular dataset on disk, you will create a new \nMyExperiment.Dataset\n instance in Matlab. The first argument \ncollection\n is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument \nrelPath\n specifies the path to this dataset relative to the collection. For example, if the dataset were stored in \n/path/to/experimentalData/dataset001.mat\n, you might run:\n\n\nds1\n \n=\n \nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\n\n\n\nYou may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s \nload\n method and assumes that \nds.path\n points to a \n.mat\n file. \nds.path\n will be equal to the dataset collection path joined to \nrelPath\n. If your data is stored differently, you will need to replace the implementation of \nloadData\n:\n\n\nfunction\n \ndata \n=\n \nloadData\n(\nds\n)\n\n\n    \n% load this dataset's data file from .path\n\n    \nin\n \n=\n \nload\n(\nds\n.\npath\n);\n\n    \ndata\n \n=\n \nin\n.\ndata\n;\n\n\nend\n\n\n\n\n\nYou can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the \nDataset\n class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property \ninfoLoaded\n can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed.\n\n\nfunction\n \nloadInfo\n(\nds\n)\n\n\n    \n% Load this Dataset's metadata if not already loaded\n\n\n    \nif\n \nds\n.\ninfoLoaded\n,\n \nreturn\n;\n \nend\n\n\n    \n% modify this to extract the metadata loaded from the data file\n\n    \ndata\n \n=\n \nds\n.\nloadData\n();\n\n    \nds\n.\nsubject\n \n=\n \ndata\n.\nsubject\n;\n\n    \nds\n.\nsaveTags\n \n=\n \ndata\n.\nsaveTags\n;\n\n    \nds\n.\ndatenum\n  \n=\n \ndata\n.\ndatenum\n;\n\n    \nds\n.\nnChannels\n \n=\n \ndata\n.\nnChannels\n;\n\n    \nds\n.\nnTrials\n \n=\n \nnumel\n(\ndata\n.\ntrials\n);\n\n\n    \nds\n.\ninfoLoaded\n \n=\n \ntrue\n;\n\n\nend\n\n\n\n\n\nThe metadata fields you might assign are as follows:\n\n\n\n\nsubject\n - Dataset subject or participant name\n\n\ndatenum\n - a Matlab datenum identifying the collection time of the dataset\n\n\nnChannels\n - the number of unique spiking channels recorded in this dataset\n\n\nnTrials\n - the number of trials included in this dataset\n\n\nsaveTags\n - a vector of numbers indicating within-day blocks of trials included\n\n\n\n\n\n\nMetadata are optional\n\n\nWe note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your \nDataset\n class.\n\n\n\n\nEditing \nRunParams.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+MyExperiment/RunParams.m\n. Recall that \nRunParams\n encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add.\n\n\nYou can add these additional properties anywhere in the file:\n\nclassdef\n \nRunParams\n \n<\n \nLFADS\n.\nRunParams\n\n   \nproperties\n\n       \n% Add additional custom parameters here. The default you assign to\n\n       \n% them will be used when computing the hash value. Any params whose value\n\n       \n% differs from the default will be included in the hash value, to allow new\n\n       \n% parameters to be added without invalidating old hashes. So choose\n\n       \n% the default once and don't change it. If you decide to use another\n\n       \n% value later by default, override it in the constructor instead.\n\n   \nend\n\n\n\n\n\n\nWarning\n\n\nThe default values you assign next to each property should be chosen carefully and never changed once added.\n The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the \nRunParams\n constructor without affecting the hash. However, you will then want to manually assign this property to its \nold value\n in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values.\n\n\n\n\nNo changes are required to \nRunParams.m\n to get up and running.\n\n\nEditing \nRunCollection.m\n \n(Optional)\n\u00b6\n\n\nEdit the file \n+MyExperiment/RunCollection.m\n. Recall that a \nRunCollection\n specifies a set of individual LFADS runs defined by an array of \nRunSpec\ns crossed with an array of \nRunParams\n.\n\n\nclassdef\n \nRunCollection\n \n<\n \nLFADS\n.\nRunCollection\n\n    \n% no need to modify anything here, but feel free to add useful methods\n\n    \n% and properties as useful\n\n\n    \nmethods\n\n\n        function\n \nrc \n=\n \nRunCollection\n(\nvarargin\n)\n\n\n            \nrc\n@\nLFADS\n.\nRunCollection\n(\nvarargin\n{:});\n\n        \nend\n\n    \nend\n\n\nend\n\n\n\n\n\nNo changes are required to \nRunCollection.m\n to get up and running\n, but you can add any utility methods to facilitate analysis for your specific application.\n\n\nEditing \nRun.m\n \n(Required)\n\u00b6\n\n\nEdit the file \n+MyExperiment/Run.m\n. Recall that a \nRun\n represents a specific LFADS model training run. The main function you will need to provide a definition for is \nconvertDatasetToSequenceStruct\n. This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this:\n\n\nfunction\n \n[counts, timeVecMs, conditionId] \n=\n \ngenerateRatesForDataset\n(\nr, dataset, mode, varargin\n)\n\n\n\n\n\nHere, \nr\n refers to the \nMyExperiment.Run\n instance. It may be particularly helpful to refer to the \nRunParams\n instance assigned to this run via \nr.params\n, especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included.\n\n\nInputs:\n\u00b6\n\n\n\n\nr\n:\n\n\nThe \nRun\n instance. The current \nRunParams\n instance can be accessed through \nr.params\n.\n\n\ndataset\n:\n\n\nMyExperiment.Dataset\n instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run, \nconvertDatasetToSequenceStruct\n will be called once for each dataset, one at a time. You might use \ndataset.loadData()\n to load the actual data, as you defined above.\n\n\nmode\n:\n\n\n\n\nstring that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined:\n\n\n\n\nexport\n - indicates that the sequence data will exported as the input to the actual Python+Tensorflow LFADS run\n\n\nalignment\n - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run.\n\n\n\n\n\n\nvarargin\n:\n\n\nCurrently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g. \n'paramName'\n,\n \nparamValue\n,\n \n...\n) in the future without breaking existing implementations.\n\n\n\n\nOutputs:\n\u00b6\n\n\n\n\ncounts\n:\n\n\nA tensor of binned spike counts (not rates) with size \nnTrials\n x \nnChannels\n x \nnTime\n. These should be total counts, not normalized rates, as they will be added togeher during rebinning.\n\n\ntimeVecMs\n:\n\n\nA vector of timepoints with length \nnTime\n in milliseconds associated with each time bin in \ncounts\n. You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the \nraw\n spike bin width used when the data are later rebinned to match \nr.params.spikeBinMs\n.\n\n\nconditionId\n:\n\n\nVector with length \nnTrials\n identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector\n\n\n\n\n\n\nA note on bin widths\n\n\nThere are two different bin widths in \nlfads-run-manager\n. First is this \nbinWidthMs\n within \nseq\n, which is the spike binning that you will do to the data inside \nconvertDatasetToSequenceStruct\n. \nWe recommend binning here at 1 ms or the smallest bin width you might wish to use.\n Second is the field \nspikeBinMs\n inside the \nRunParams\n class. The expectation is that you will bin using a very small bin width inside \nconvertDatasetToSequenceStruct\n, and then \nthe run manager code will automatically re-bin the data at the larger bin width set by \nr.params.spikeBinMs\n for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.",
            "title": "Interfacing to your Datasets"
        },
        {
            "location": "/adapting/#using-lfads-run-manager-with-your-datasets",
            "text": "",
            "title": "Using LFADS Run Manager with your datasets"
        },
        {
            "location": "/adapting/#copying-the-myexperiment-working-example-code",
            "text": "Below we describe how to use the run manager code with datasets from a specific experiment. The recommended way to begin this process is to copy the folder  +MyExperiment  inside the lfads-run-manager  repository to some other folder on your Matlab path, and then to rename it to something related to the experiment. Below, we\u2019ll use the name  MyExperiment , which requires renaming the folder to  +MyExperiment .  Each of the classes you have just created are defined to inherit from the corresponding  LFADS.ClassName  inside the  lfads-run-manager  repo. Consequently, only a small amount of code is present in each file; the rest of the properties and methods for each class are define inside the  +LFADS  folder in the repo.",
            "title": "Copying the MyExperiment working example code"
        },
        {
            "location": "/adapting/#editing-the-core-classes",
            "text": "Here we walk through each of the classes that you\u2019ve just copied. Most of the classes can be left as is to get started, but you may find it helpful to add utility methods and addtional metadata in certain locations. However, the only required edits are:   loadData  in  Dataset.m  - specify how to load a dataset from disk. The default implementation assumes that the data live in a  .mat  file that can be loaded using  load .  convertDatasetToSequenceStruct  in  Run.m   - preprocess data and perform spike binning",
            "title": "Editing the core classes"
        },
        {
            "location": "/adapting/#editing-datasetcollectionm-optional",
            "text": "Edit the file  +MyExperiment/DatasetCollection.m . Recall that a dataset collection refers to a set of multiple individual datasets. Note the definition of the constructor:  function   ds  =   DatasetCollection ( path )       ds   =   ds @ LFADS . DatasetCollection ( path );  end   You may edit this to fit your needs, but the default approach is to create a new dataset collection by specifying a path on disk where the data live. For example, you could run:  dc   =   MyExperiment . DatasetCollection ( '/path/to/experimentData' );   This path will then be used as the parent folder by all of the datasets that are added to this collection.  Below is a function included as an example of how to filter or down-select datasets within a collection. A typical approach might be to add all of the datasets that were collected, and then filter by those having a sufficiently high trial count (or satisfying some other set of criteria). You can use the utility function  filterDatasets  to specify the indices or mask over datasets to keep.  function   filterHavingMinimumTrials ( dc, minTrials )       % example of a function that will filter down datasets based on \n     % their metadata. \n     nTrials   =   cat ( 1 ,   dc . datasets . nTrials ); \n\n     % filterDatasets is provided by DatasetCollection \n     dc . filterDatasets ( nTrials   > =   minTrials );  end   No edits are necessary to  DatasetCollection.m  to get up and running , but feel free to add any additional methods or properties as needed for your application.",
            "title": "Editing DatasetCollection.m (Optional)"
        },
        {
            "location": "/adapting/#editing-datasetm-required",
            "text": "Edit the file  +MyExperiment/Dataset.m . Recall that a dataset encapsulates a collection of trials with simultaneously recorded neural data from an individual experimental session. Here, we will make a few light edits to specify metadata about each dataset.  First, look at the constructor.  function   ds  =   Dataset ( collection, relPath )       ds   =   ds @ LFADS . Dataset ( collection ,   relPath );  end   In order to encapsulate a particular dataset on disk, you will create a new  MyExperiment.Dataset  instance in Matlab. The first argument  collection  is the DatasetCollection to add this dataset to, which will provide the parent path. The second argument  relPath  specifies the path to this dataset relative to the collection. For example, if the dataset were stored in  /path/to/experimentalData/dataset001.mat , you might run:  ds1   =   MyExperiment . Dataset ( dc ,   'dataset001.mat' );   You may need to specify how to load the actual data into Matlab in order to facilitate preprocessing. The default simply calls Matlab\u2019s  load  method and assumes that  ds.path  points to a  .mat  file.  ds.path  will be equal to the dataset collection path joined to  relPath . If your data is stored differently, you will need to replace the implementation of  loadData :  function   data  =   loadData ( ds )       % load this dataset's data file from .path \n     in   =   load ( ds . path ); \n     data   =   in . data ;  end   You can then specify how to determine certain metadata about the dataset, simply for display and organizational purposes. These metadata will then be assigned into specific properties of the  Dataset  class. The simplest approach is to simply load the data and copy or compute the values from the data. However, if loading the data is expensive, you might store the metadata in a separate file to save time. This implementation is up to you, and you can simply specify empty values for metadata fields you do not care about. Note that the logical property  infoLoaded  can be used to determine if the metadata has already been loaded, since this method will be called several times to ensure the metadata is loaded when needed.  function   loadInfo ( ds )       % Load this Dataset's metadata if not already loaded \n\n     if   ds . infoLoaded ,   return ;   end \n\n     % modify this to extract the metadata loaded from the data file \n     data   =   ds . loadData (); \n     ds . subject   =   data . subject ; \n     ds . saveTags   =   data . saveTags ; \n     ds . datenum    =   data . datenum ; \n     ds . nChannels   =   data . nChannels ; \n     ds . nTrials   =   numel ( data . trials ); \n\n     ds . infoLoaded   =   true ;  end   The metadata fields you might assign are as follows:   subject  - Dataset subject or participant name  datenum  - a Matlab datenum identifying the collection time of the dataset  nChannels  - the number of unique spiking channels recorded in this dataset  nTrials  - the number of trials included in this dataset  saveTags  - a vector of numbers indicating within-day blocks of trials included    Metadata are optional  We note that none of these fields is used for subsequent processing, and are defined only for convenience and consistency. Feel free to ignore these, and to add additional fields as properties directly to your  Dataset  class.",
            "title": "Editing Dataset.m (Required)"
        },
        {
            "location": "/adapting/#editing-runparamsm-optional",
            "text": "Edit the file  +MyExperiment/RunParams.m . Recall that  RunParams  encapsulates all of the hyperparameters used by LFADS but can also be used to specify any experiment specific hyperparameters you wish to add.  You can add these additional properties anywhere in the file: classdef   RunParams   <   LFADS . RunParams \n    properties \n        % Add additional custom parameters here. The default you assign to \n        % them will be used when computing the hash value. Any params whose value \n        % differs from the default will be included in the hash value, to allow new \n        % parameters to be added without invalidating old hashes. So choose \n        % the default once and don't change it. If you decide to use another \n        % value later by default, override it in the constructor instead. \n    end    Warning  The default values you assign next to each property should be chosen carefully and never changed once added.  The reason for this is that when generating the hash of the hyperparameters (which specifies where LFADS-related files live on disk), each property is compared against this default value. The current value of a particular property is only included in the hashing process if it differs from this default value. This design ensures that it is always safe to add new hyperparameters; previously performed LFADS runs will still have the same hash value and will be assigned the default hyperparameter. However, if you change the default value here, all of the hash values for all previously performed runs will change, which will require directories to be manually renamed on disk and symbolic links to be corrected. If you wish to change the default value that a property takes for new runs, you can change its value in the  RunParams  constructor without affecting the hash. However, you will then want to manually assign this property to its  old value  in any drive scripts you used to setup previous LFADS runs, in order to correctly specify the hyperparameters used and the corresponding hash values.   No changes are required to  RunParams.m  to get up and running.",
            "title": "Editing RunParams.m (Optional)"
        },
        {
            "location": "/adapting/#editing-runcollectionm-optional",
            "text": "Edit the file  +MyExperiment/RunCollection.m . Recall that a  RunCollection  specifies a set of individual LFADS runs defined by an array of  RunSpec s crossed with an array of  RunParams .  classdef   RunCollection   <   LFADS . RunCollection \n     % no need to modify anything here, but feel free to add useful methods \n     % and properties as useful \n\n     methods          function   rc  =   RunCollection ( varargin )               rc @ LFADS . RunCollection ( varargin {:}); \n         end \n     end  end   No changes are required to  RunCollection.m  to get up and running , but you can add any utility methods to facilitate analysis for your specific application.",
            "title": "Editing RunCollection.m (Optional)"
        },
        {
            "location": "/adapting/#editing-runm-required",
            "text": "Edit the file  +MyExperiment/Run.m . Recall that a  Run  represents a specific LFADS model training run. The main function you will need to provide a definition for is  convertDatasetToSequenceStruct . This is where you will actually need to process your datasets and return a structure array containing binned spike counts. The function signature looks like this:  function   [counts, timeVecMs, conditionId]  =   generateRatesForDataset ( r, dataset, mode, varargin )   Here,  r  refers to the  MyExperiment.Run  instance. It may be particularly helpful to refer to the  RunParams  instance assigned to this run via  r.params , especially if you have defined any additional hyperparameters that affect the way in which neural data should be extracted, e.g. which trials and what time window are included.",
            "title": "Editing Run.m (Required)"
        },
        {
            "location": "/adapting/#inputs",
            "text": "r :  The  Run  instance. The current  RunParams  instance can be accessed through  r.params .  dataset :  MyExperiment.Dataset  instance that is to be processed. If this is a single-dataset run, this will be the dataset used. If this is a multi-dataset stitched run,  convertDatasetToSequenceStruct  will be called once for each dataset, one at a time. You might use  dataset.loadData()  to load the actual data, as you defined above.  mode :   string that indicates the intended purpose of the output data. You may ignore this and simply return the same sequence struct regardless of the mode, or you may process the data differently according to the context. Currently two modes are defined:   export  - indicates that the sequence data will exported as the input to the actual Python+Tensorflow LFADS run  alignment  - for multi-dataset stitched runs, indicates that the output data will be used only to construct the alignment matrices that translate between the spiking channels across different datasets. For example, you might wish to include a subset of trials or a different time window for fitting the alignment matrices, but include all trials for the actual LFADS run.    varargin :  Currently not being used, but this enables additional arguments to be passed as named-parameter value pairs (e.g.  'paramName' ,   paramValue ,   ... ) in the future without breaking existing implementations.",
            "title": "Inputs:"
        },
        {
            "location": "/adapting/#outputs",
            "text": "counts :  A tensor of binned spike counts (not rates) with size  nTrials  x  nChannels  x  nTime . These should be total counts, not normalized rates, as they will be added togeher during rebinning.  timeVecMs :  A vector of timepoints with length  nTime  in milliseconds associated with each time bin in  counts . You can start this wherever you like, but timeVecMs(2) - timeVecMs(1) will be treated as the  raw  spike bin width used when the data are later rebinned to match  r.params.spikeBinMs .  conditionId :  Vector with length  nTrials  identifying the condition to which each trial belongs. This can either be a cell array of strings or a numeric vector    A note on bin widths  There are two different bin widths in  lfads-run-manager . First is this  binWidthMs  within  seq , which is the spike binning that you will do to the data inside  convertDatasetToSequenceStruct .  We recommend binning here at 1 ms or the smallest bin width you might wish to use.  Second is the field  spikeBinMs  inside the  RunParams  class. The expectation is that you will bin using a very small bin width inside  convertDatasetToSequenceStruct , and then  the run manager code will automatically re-bin the data at the larger bin width set by  r.params.spikeBinMs  for you. However, you are responsible for ensuring that the larger spike bin width is an integer multiple of the smaller bin width, otherwise an error will be generated.",
            "title": "Outputs:"
        },
        {
            "location": "/drive/",
            "text": "Setting up LFADS runs\n\u00b6\n\n\nAssuming you have finished \nadapting the LFADS run manager classes to your dataset\n, you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a \ndrive script\n that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling \nlfads-run-manager\n to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as \nMyExperiment\n, but you should substitute this with your package name.\n\n\n\n\nFollow along with \nMyExperiment.drive_script\n\n\nA complete drive script is available as a starting point in \n+MyExperiment/drive_script.m\n for you to copy/paste from.\n\n\n\n\nLorenz attractor example\n\u00b6\n\n\nFor this demo, we\u2019ll generate synthetic spiking data generated by a Lorenz attractor using the following code:\n\n\ndatasetPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\nnDatasets\n \n=\n \n4\n;\n \n% we'll only use 3 of the 4\n\n\nLFADS\n.\nUtils\n.\ngenerateDemoDatasets\n(\ndatasetPath\n,\n \nnDatasets\n);\n\n\n\n\n\nThis will simulate a chaotic 3 dimensional \nLorenz attractor\n as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories:\n\n\n\n\nFrom these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the \nconditions\n) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition.\n\n\nHere are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:\n\n\n\n\nBuilding a dataset collection and adding datasets\n\u00b6\n\n\nFirst, create a dataset collection that points to a folder on disk where datasets are stored:\n\n\ndataPath\n \n=\n \n'~/lorenz_example/datasets'\n;\n\n\ndc\n \n=\n \nMyExperiment\n.\nDatasetCollection\n(\ndataPath\n);\n\n\ndc\n.\nname\n \n=\n \n'lorenz_example'\n;\n\n\n\n\n\nThen, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset001.mat'\n);\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset002.mat'\n);\n\n\nMyExperiment\n.\nDataset\n(\ndc\n,\n \n'dataset003.mat'\n);\n\n\n\n\n\n\n\nAuto-detecting datasets\n\n\nYou might consider adding a method to your \nDatasetCollection\n class which can automatically detect all of the datasets in a specific folder. An example, which would add every \n.mat\n file detected in the folder might look like this:\n\n\nfunction\n \nautoDetectDatasets\n(\ndc\n)\n\n\n    \ndc\n.\nclearDatasets\n();\n \n% in case there are existing datasets already added\n\n\n    \n% automatically find all .mat files within dc.path and build datasets for each\n\n    \nfiles\n \n=\n \ndir\n(\ndc\n.\npath\n);\n\n    \nfor\n \niF\n \n=\n \n1\n:\nnumel\n(\nfiles\n)\n\n        \nif\n \nstrncmp\n(\nfiles\n(\niF\n).\nname\n,\n \n'.'\n,\n \n1\n),\n \ncontinue\n,\n \nend\n\n        \ninfo\n \n=\n \nfiles\n(\niF\n);\n\n        \n[\n~\n,\n \n~\n,\n \next\n]\n \n=\n \nfileparts\n(\ninfo\n.\nname\n);\n\n        \nif\n \n~\nstrcmp\n(\next\n,\n \n'.mat'\n),\n \ncontinue\n;\n \nend\n\n        \nds\n \n=\n \nMyExperiment\n.\nDataset\n(\ndc\n,\n \ninfo\n.\nname\n);\n \n% change this to match your package name\n\n    \nend\n\n\nend\n\n\n\n\n\n\n\nYou can verify that the datasets have been added to the collection:\n\n\n>>\n \ndc\n\n\nMyExperiment\n.\nDatasetCollection\n \"\nlorenz_example\n\"\n  \n3\n \ndatasets\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \n[\n \n1\n]\n \nMyExperiment\n.\nDataset\n \"\ndataset001\n\"\n  \n[\n \n2\n]\n \nMyExperiment\n.\nDataset\n \"\ndataset002\n\"\n  \n[\n \n3\n]\n \nMyExperiment\n.\nDataset\n \"\ndataset003\n\"\n\n         \nname\n:\n \n'lorenz_example'\n\n      \ncomment\n:\n \n''\n\n         \npath\n:\n \n'~/lorenz_example/datasetss'\n\n     \ndatasets\n:\n \n[\n3\nx1\n \nMyExperiment\n.\nDataset\n]\n\n    \nnDatasets\n:\n \n3\n\n\n\n\n\nYou can access individual datasets using \ndc\n.\ndatasets\n(\n1\n)\n or by name with \ndc\n.\nmatchDatasetsByName\n(\n'dataset001'\n)\n.\n\n\nYou can then load all of the metadata for the datasets using:\n\ndc\n.\nloadInfo\n();\n\n\n\n\nand view a summary of the results using:\n\n\n>>\n \ndc\n.\ngetDatasetInfoTable\n          \n\n                  \nsubject\n                  \ndate\n             \nsaveTags\n    \nnTrials\n    \nnChannels\n\n              \n________________\n    \n______________________\n    \n________\n    \n_______\n    \n_________\n\n\n\ndataset001\n    \n'lorenz_example'\n    \n[\n01\n-\nOct\n-\n2017\n \n00\n:\n00\n:\n00\n]\n    \n'1'\n         \n1200\n       \n24\n\n\ndataset002\n    \n'lorenz_example'\n    \n[\n02\n-\nOct\n-\n2017\n \n00\n:\n00\n:\n00\n]\n    \n'1'\n         \n1350\n       \n26\n\n\ndataset003\n    \n'lorenz_example'\n    \n[\n03\n-\nOct\n-\n2017\n \n00\n:\n00\n:\n00\n]\n    \n'1'\n         \n1000\n       \n21\n\n\n\n\n\nCreate a \nRunCollection\n\u00b6\n\n\nWe\u2019ll now setup a \nRunCollection\n that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.\n\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n\n\nAdd the \nRunSpec\n instances\n\u00b6\n\n\nRecall that \nRunSpec\n instances specify which datasets are included in a specific run. We\u2019ll start by setting up a single dataset run for each of the datasets:\n\n\nfor\n \niR\n \n=\n \n1\n:\ndc\n.\nnDatasets\n\n    \nrunSpec\n \n=\n \nMyExperiment\n.\nRunSpec\n(\ndc\n.\ndatasets\n(\niR\n).\ngetSingleRunName\n(),\n \ndc\n,\n \niR\n);\n\n    \nrc\n.\naddRunSpec\n(\nrunSpec\n);\n\n\nend\n\n\n\n\n\nYou can adjust the arguments to the constructor of \nMyExperiment.RunSpec\n, but in the example provided the inputs define:\n\n\n\n\nthe unique name of the run. Here we use \ngetSingleRunName\n, a convenience method of \nDataset\n that generates a name like \nsingle_datasetName\n.\n\n\nthe \nDatasetCollection\n\n\nthe indices or names of datasets (as a string or cell array of strings) to include\n\n\n\n\nWe will also add a multi-session stitching run which includes all datasets:\n\n\nrc\n.\naddRunSpec\n(\nMyExperiment\n.\nRunSpec\n(\n'all'\n,\n \ndc\n,\n \n1\n:\ndc\n.\nnDatasets\n));\n\n\n\n\n\nSpecify the hyperparameters\n\u00b6\n\n\nWe\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8.\n\n\npar\n \n=\n \nMyExperiment\n.\nRunParams\n;\n\n\npar\n.\nspikeBinMs\n \n=\n \n2\n;\n \n% rebin the data at 2 ms\n\n\npar\n.\nc_co_dim\n \n=\n \n0\n;\n \n% no controller --> no inputs to generator\n\n\npar\n.\nc_batch_size\n \n=\n \n150\n;\n \n% must be < 1/5 of the min trial count\n\n\n\npar\n.\nsetInFactorsMatchDataForSingleDataset\n \n=\n \ntrue\n;\n  \n% automatically change c_in_factors_dim to match the number of channels in a single dataset\n\n\npar\n.\nc_in_factors_dim\n \n=\n \n8\n;\n \n% and manually set it for multisession stitched models\n\n\npar\n.\nc_factors_dim\n \n=\n \n8\n;\n \n% number of factors read out from generator to generate rates\n\n\npar\n.\nuseAlignmentMatrix\n \n=\n \ntrue\n;\n \n% use alignment matrices initial guess for multisession stitching\n\n\n\npar\n.\nc_gen_dim\n \n=\n \n64\n;\n \n% number of units in generator RNN\n\n\npar\n.\nc_ic_enc_dim\n \n=\n \n64\n;\n \n% number of units in encoder RNN\n\n\n\npar\n.\nc_learning_rate_stop\n \n=\n \n1e-3\n;\n \n% we can stop really early for the demo\n\n\n\n\n\nAs we wish stitch multiple datasets together in one of the runs, we\u2019ll also specify that we\u2019d like to automatically specify an initial guess for the alignment matrices that link neurons to factors for each dataset using \nuseAlignmentMatrix\n. We\u2019ll also have LFADS automatically set \nc_in_factors_dim\n to match the number of channels of the dataset for each single session run using \nsetInFactorsMatchDataForSingleDataset\n. For multi-dataset stitched runs, the set value of \nc_in_factors_dim\n \n=\n \n8\n will be used.\n\n\n\n\nSetting batch size\n\n\nThe number of trials in your smallest dataset determines the largest batch size you can pick. If \ntrainToTestRatio\n is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as \nc_batch_size\n. If you choose a batch size which is too large, \nlfads-run-manager\n will generate an error to alert you.\n\n\n\n\nWe then add this \nRunParams\n to the run collection:\n\nrc\n.\naddParams\n(\npar\n);\n\n\n\n\nYou can then look at the parameter settings added to \nrc\n using \nrc.params\n:\n\n\n>>\n \nrc\n.\nparams\n\n\n\nMyExperiment\n.\nRunParams\n \nparam_pqQbzB\n \ndata_IR3OQV\n\n\nuseAlignmentMatrix\n=\ntrue\n \nsetInFactorsMatchDataForSingleDataset\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_in_factors_dim\n=\n8\n \nc_ic_enc_dim\n=\n64\n \nc_gen_dim\n=\n64\n \nc_co_dim\n=\n0\n \nc_batch_size\n=\n150\n \nc_learning_rate_stop\n=\n0.001\n\n\n...\n\n\n\n\n\nRunParams\n data and param hashes\n\u00b6\n\n\nThe six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. There are two hash values for each \nRunParams\n instance. The first is the hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with \nparam_\n.  \n\n\nThe second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by \ndata_\n. We use two separate hashes here to save space on disk; many parameters like \nc_co_dim\n only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like \nc_co_dim\n would otherwise require many copies of identical data to be saved on disk. Intead, we store the data in folders according to the \ndata_\n hash and symlink copies for each run.\n\n\nBelow the hash values are the set of properties whose values differ from their specified defaults.\n\n\n\n\nSpecifying data-hash affecting parameters\n\n\nBy default, the \ndata_\n hash includes all properties that do not begin with \nc_\n as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to \nRunParams\n. If you need to adjust this behavior, override the method \ngetListPropertiesNotAffectingInputData\n in your \nRunParams\n instance.\n\n\n\n\n\n\nRunParams\n is a value class\n\n\nUnlike all of the other classes, \nRunParams\n is not a handle but a value class, which acts similarly to a \nstruct\n in that it is passed by value. This means that after adding the \nRunParams\n instance \npar\n to the \nRunCollection\n, we can modify \npar\n and then add it again to define a second set of parameters, like this:\n\npar\n.\nc_gen_dim\n \n=\n \n96\n;\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\npar\n.\nc_gen_dim\n \n=\n \n128\n;\n\n\nrc\n.\naddParams\n(\npar\n);\n\n\n\n\n\n\n\n\nGenerating hyperparameter value sweeps\n\n\nIf you wish to sweep a specific property or set of properties, you can create a \nRunParams\n instance, set the other properties as needed, and then call \ngenerateSweep\n to build an array of \nRunParams\n instances:\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_gen_dim'\n,\n \n[\n32\n \n64\n \n96\n \n128\n]);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n\nOr along multiple parameters in a grid:\n\nparSet\n \n=\n \npar\n.\ngenerateSweep\n(\n'c_gen_dim'\n,\n \n[\n32\n \n64\n \n96\n \n128\n],\n \n'c_co_dim'\n,\n \n0\n:\n2\n:\n4\n);\n\n\nrc\n.\naddParams\n(\nparSet\n);\n\n\n\n\n\n\nCheck the \nRunCollection\n\u00b6\n\n\nThe \nRunCollection\n will now display inforation about the parameter settings and run specifications that have been added:\n\n\n>>\n \nrc\n\n\n\nMyExperiment\n.\nRunCollection\n \"\nexampleRun\n\" \n(\n5\n \nruns\n \ntotal\n)\n\n  \nDataset\n \nCollection\n \"\nlorenz_example\n\" \n(\n4\n \ndatasets\n)\n \nin\n \n~/\nlorenz_example\n/\ndatasets\n\n  \nPath\n:\n \n~/\nlorenz_example\n/\nruns\n/\nexampleRun\n\n\n  \n1\n \nparameter\n \nsettings\n\n  \n[\n1\n \nparam_jMCQCl\n \ndata_\n-\nMSPr6\n]\n \nMyExperiment\n.\nRunParams\n \nuseAlignmentMatrix\n=\ntrue\n \nc_factors_dim\n=\n8\n \nc_in_factors_dim\n=\n8\n \nc_co_dim\n=\n64\n \nc_batch_size\n=\n150\n\n\n  \n5\n \nrun\n \nspecifications\n\n  \n[\n \n1\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset001\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n2\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset002\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n3\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset003\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n4\n]\n \nMyExperiment\n.\nRunSpec\n \"\nsingle_dataset004\n\" \n(\n1\n \ndatasets\n)\n\n  \n[\n \n5\n]\n \nMyExperiment\n.\nRunSpec\n \"\nall\n\" \n(\n4\n \ndatasets\n)\n\n\n                          \nname\n:\n \n'exampleRun'\n\n                       \ncomment\n:\n \n''\n\n                      \nrootPath\n:\n \n'~/lorenz_example/runs'\n\n                       \nversion\n:\n \n3\n\n             \ndatasetCollection\n:\n \n[\n1\nx1\n \nMyExperiment\n.\nDatasetCollection\n]\n\n                          \nruns\n:\n \n[\n5\nx1\n \nMyExperiment\n.\nRun\n]\n\n                        \nparams\n:\n \n[\n1\nx1\n \nMyExperiment\n.\nRunParams\n]\n\n                      \nrunSpecs\n:\n \n[\n5\nx1\n \nMyExperiment\n.\nRunSpec\n]\n\n                       \nnParams\n:\n \n1\n\n                     \nnRunSpecs\n:\n \n5\n\n                    \nnRunsTotal\n:\n \n5\n\n                     \nnDatasets\n:\n \n4\n\n                          \npath\n:\n \n'~/lorenz_example/runs/exampleRun'\n\n      \npathsCommonDataForParams\n:\n \n{\n'~/lorenz_example/runs/exampleRun/data_-MSPr6'\n}\n\n                \npathsForParams\n:\n \n{\n'~/lorenz_example/runs/exampleRun/param_jMCQCl'\n}\n\n    \nfileShellScriptTensorboard\n:\n \n'~/lorenz_example/runs/exampleRun/launch_tensorboard.sh'\n\n               \nfileSummaryText\n:\n \n'~/lorenz_example/runs/exampleRun/summary.txt'\n\n       \nfileShellScriptRunQueue\n:\n \n'~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'\n\n\n\n\n\nPrepare for LFADS\n\u00b6\n\n\nNow that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.\n\n\nrc\n.\nprepareForLFADS\n();\n\n\n\n\n\nThis will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call \nprepareForLFADS\n again. Existing files won\u2019t be overwritten unless you call \nrc.prepareForLFADS(true)\n.\n\n\nAlso, a \nsummary.txt\n file will be generated which can be useful for identifying all of the runs and their locations on disk.\n\n\nMyExperiment.RunCollection \"exampleRun\" (4 runs total)\n  Path: ~/lorenz_example/runs/exampleRun\n  Dataset Collection \"lorenz_example\" (3 datasets) in ~/lorenz_example/datasets\n\n  ------------------------\n\n  4 Run Specifications:\n\n    [runSpec 1] MyExperiment.RunSpec \"single_dataset001\" (1 datasets)\n      [ds 1] MyExperiment.Dataset \"dataset001\"\n\n    [runSpec 2] MyExperiment.RunSpec \"single_dataset002\" (1 datasets)\n      [ds 2] MyExperiment.Dataset \"dataset002\"\n\n    [runSpec 3] MyExperiment.RunSpec \"single_dataset003\" (1 datasets)\n      [ds 3] MyExperiment.Dataset \"dataset003\"\n\n    [runSpec 4] MyExperiment.RunSpec \"all\" (3 datasets)\n      [ds 1] MyExperiment.Dataset \"dataset001\"\n      [ds 2] MyExperiment.Dataset \"dataset002\"\n      [ds 3] MyExperiment.Dataset \"dataset003\"\n\n  ------------------------\n\n  1 Parameter Settings:\n\n    [1 param_pqQbzB] MyExperiment.RunParams\n      Diff: useAlignmentMatrix=true setInFactorsMatchDataForSingleDataset=true c_factors_dim=8 c_in_factors_dim=8 c_ic_enc_dim=64 c_gen_dim=64 c_co_dim=0 c_batch_size=150 c_learning_rate_stop=0.001\n\n      spikeBinMs: 2\n      trainToTestRatio: 4\n      useAlignmentMatrix: true\n      scaleIncreaseStepsWithDatasets: true\n      setInFactorsMatchDataForSingleDataset: true\n      c_cell_clip_value: 5\n      c_factors_dim: 8\n      c_in_factors_dim: 8\n      c_ic_enc_dim: 64\n      c_ci_enc_dim: 128\n      c_gen_dim: 64\n      c_keep_prob: 0.95\n      c_learning_rate_decay_factor: 0.98\n      c_device: /gpu:0\n      c_co_dim: 0\n      c_do_causal_controller: false\n      c_l2_gen_scale: 500\n      c_l2_con_scale: 500\n      c_batch_size: 150\n      c_kl_increase_steps: 900\n      c_l2_increase_steps: 900\n      c_controller_input_lag: 1\n      c_ic_dim: 64\n      c_con_dim: 128\n      c_learning_rate_stop: 0.001\n      c_temporal_spike_jitter_width: 0\n      c_allow_gpu_growth: true\n      c_kl_ic_weight: 1\n      c_kl_co_weight: 1",
            "title": "Preparing for LFADS"
        },
        {
            "location": "/drive/#setting-up-lfads-runs",
            "text": "Assuming you have finished  adapting the LFADS run manager classes to your dataset , you should be all set to generate some LFADS runs and start training. We\u2019ll be setting up a  drive script  that will do the work of creating the appropriate instances, pointing at the datasets, creating the runs, and telling  lfads-run-manager  to generate the files needed for LFADS. Below, we\u2019ll refer to the package name as  MyExperiment , but you should substitute this with your package name.   Follow along with  MyExperiment.drive_script  A complete drive script is available as a starting point in  +MyExperiment/drive_script.m  for you to copy/paste from.",
            "title": "Setting up LFADS runs"
        },
        {
            "location": "/drive/#lorenz-attractor-example",
            "text": "For this demo, we\u2019ll generate synthetic spiking data generated by a Lorenz attractor using the following code:  datasetPath   =   '~/lorenz_example/datasets' ;  nDatasets   =   4 ;   % we'll only use 3 of the 4  LFADS . Utils . generateDemoDatasets ( datasetPath ,   nDatasets );   This will simulate a chaotic 3 dimensional  Lorenz attractor  as the underlying dynamical system, initialized from 65 initial conditions. Here is a subset of 10 conditions\u2019 trajectories:   From these 3 dimensions, we generate random matrices along which to project these 3 dimensions to produce the firing rates of individual units (plus a constant bias term). The initial conditions (defining the  conditions ) and subsequent dynamical trajectories are the same across datasets. Each dataset will contain a variable number of neurons (between 25\u201335). The rates of these neurons are then constructed by projecting the 3-d Lorenz trajectory through a dataset-specific readout matrix, adding the bias, and exponentiating. We then draw spikes from the inhomogenous Poisson process for 20-30 trials for each condition.  Here are a few examples of single trial spike rasters. The units have been sorted according to their loading onto the first dimension of the attractor:",
            "title": "Lorenz attractor example"
        },
        {
            "location": "/drive/#building-a-dataset-collection-and-adding-datasets",
            "text": "First, create a dataset collection that points to a folder on disk where datasets are stored:  dataPath   =   '~/lorenz_example/datasets' ;  dc   =   MyExperiment . DatasetCollection ( dataPath );  dc . name   =   'lorenz_example' ;   Then, we can add the individual datasets within based on their individual paths. Note that when a new dataset instance  MyExperiment . Dataset ( dc ,   'dataset001.mat' );  MyExperiment . Dataset ( dc ,   'dataset002.mat' );  MyExperiment . Dataset ( dc ,   'dataset003.mat' );    Auto-detecting datasets  You might consider adding a method to your  DatasetCollection  class which can automatically detect all of the datasets in a specific folder. An example, which would add every  .mat  file detected in the folder might look like this:  function   autoDetectDatasets ( dc )       dc . clearDatasets ();   % in case there are existing datasets already added \n\n     % automatically find all .mat files within dc.path and build datasets for each \n     files   =   dir ( dc . path ); \n     for   iF   =   1 : numel ( files ) \n         if   strncmp ( files ( iF ). name ,   '.' ,   1 ),   continue ,   end \n         info   =   files ( iF ); \n         [ ~ ,   ~ ,   ext ]   =   fileparts ( info . name ); \n         if   ~ strcmp ( ext ,   '.mat' ),   continue ;   end \n         ds   =   MyExperiment . Dataset ( dc ,   info . name );   % change this to match your package name \n     end  end    You can verify that the datasets have been added to the collection:  >>   dc  MyExperiment . DatasetCollection  \" lorenz_example \"\n   3   datasets   in   ~/ lorenz_example / datasets \n   [   1 ]   MyExperiment . Dataset  \" dataset001 \"\n   [   2 ]   MyExperiment . Dataset  \" dataset002 \"\n   [   3 ]   MyExperiment . Dataset  \" dataset003 \"\n\n          name :   'lorenz_example' \n       comment :   '' \n          path :   '~/lorenz_example/datasetss' \n      datasets :   [ 3 x1   MyExperiment . Dataset ] \n     nDatasets :   3   You can access individual datasets using  dc . datasets ( 1 )  or by name with  dc . matchDatasetsByName ( 'dataset001' ) .  You can then load all of the metadata for the datasets using: dc . loadInfo ();   and view a summary of the results using:  >>   dc . getDatasetInfoTable           \n\n                   subject                    date               saveTags      nTrials      nChannels \n               ________________      ______________________      ________      _______      _________  dataset001      'lorenz_example'      [ 01 - Oct - 2017   00 : 00 : 00 ]      '1'           1200         24  dataset002      'lorenz_example'      [ 02 - Oct - 2017   00 : 00 : 00 ]      '1'           1350         26  dataset003      'lorenz_example'      [ 03 - Oct - 2017   00 : 00 : 00 ]      '1'           1000         21",
            "title": "Building a dataset collection and adding datasets"
        },
        {
            "location": "/drive/#create-a-runcollection",
            "text": "We\u2019ll now setup a  RunCollection  that will contain all of the LFADS runs we\u2019ll be training. Inside this folder will be stored all of the processed data and LFADS output, nicely organized within subfolders.  runRoot   =   '~/lorenz_example/runs' ;  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );",
            "title": "Create a RunCollection"
        },
        {
            "location": "/drive/#add-the-runspec-instances",
            "text": "Recall that  RunSpec  instances specify which datasets are included in a specific run. We\u2019ll start by setting up a single dataset run for each of the datasets:  for   iR   =   1 : dc . nDatasets \n     runSpec   =   MyExperiment . RunSpec ( dc . datasets ( iR ). getSingleRunName (),   dc ,   iR ); \n     rc . addRunSpec ( runSpec );  end   You can adjust the arguments to the constructor of  MyExperiment.RunSpec , but in the example provided the inputs define:   the unique name of the run. Here we use  getSingleRunName , a convenience method of  Dataset  that generates a name like  single_datasetName .  the  DatasetCollection  the indices or names of datasets (as a string or cell array of strings) to include   We will also add a multi-session stitching run which includes all datasets:  rc . addRunSpec ( MyExperiment . RunSpec ( 'all' ,   dc ,   1 : dc . nDatasets ));",
            "title": "Add the RunSpec instances"
        },
        {
            "location": "/drive/#specify-the-hyperparameters",
            "text": "We\u2019ll next specify a single set of hyperparameters to begin with. Since this is a simple dataset, we\u2019ll reduce the size of the generator network to 64 and reduce the number of factors to 8.  par   =   MyExperiment . RunParams ;  par . spikeBinMs   =   2 ;   % rebin the data at 2 ms  par . c_co_dim   =   0 ;   % no controller --> no inputs to generator  par . c_batch_size   =   150 ;   % must be < 1/5 of the min trial count  par . setInFactorsMatchDataForSingleDataset   =   true ;    % automatically change c_in_factors_dim to match the number of channels in a single dataset  par . c_in_factors_dim   =   8 ;   % and manually set it for multisession stitched models  par . c_factors_dim   =   8 ;   % number of factors read out from generator to generate rates  par . useAlignmentMatrix   =   true ;   % use alignment matrices initial guess for multisession stitching  par . c_gen_dim   =   64 ;   % number of units in generator RNN  par . c_ic_enc_dim   =   64 ;   % number of units in encoder RNN  par . c_learning_rate_stop   =   1e-3 ;   % we can stop really early for the demo   As we wish stitch multiple datasets together in one of the runs, we\u2019ll also specify that we\u2019d like to automatically specify an initial guess for the alignment matrices that link neurons to factors for each dataset using  useAlignmentMatrix . We\u2019ll also have LFADS automatically set  c_in_factors_dim  to match the number of channels of the dataset for each single session run using  setInFactorsMatchDataForSingleDataset . For multi-dataset stitched runs, the set value of  c_in_factors_dim   =   8  will be used.   Setting batch size  The number of trials in your smallest dataset determines the largest batch size you can pick. If  trainToTestRatio  is 4 (the default), then you will need at least 4+1 = 5 times as many trials in every dataset as  c_batch_size . If you choose a batch size which is too large,  lfads-run-manager  will generate an error to alert you.   We then add this  RunParams  to the run collection: rc . addParams ( par );   You can then look at the parameter settings added to  rc  using  rc.params :  >>   rc . params  MyExperiment . RunParams   param_pqQbzB   data_IR3OQV  useAlignmentMatrix = true   setInFactorsMatchDataForSingleDataset = true   c_factors_dim = 8   c_in_factors_dim = 8   c_ic_enc_dim = 64   c_gen_dim = 64   c_co_dim = 0   c_batch_size = 150   c_learning_rate_stop = 0.001  ...",
            "title": "Specify the hyperparameters"
        },
        {
            "location": "/drive/#runparams-data-and-param-hashes",
            "text": "The six digit alphanumeric hash values are used to uniquely and concisely identify the runs so that they can be conveniently located on disk in a predictable fashion. There are two hash values for each  RunParams  instance. The first is the hash of the whole collection of parameter settings which differ from their defaults, which is prefixed with  param_ .    The second is a hash of only those parameter settings that affect the input data used by LFADS, prefixed by  data_ . We use two separate hashes here to save space on disk; many parameters like  c_co_dim  only affect LFADS internally, but the input data is the same. Consequently, generating a large sweep of parameters like  c_co_dim  would otherwise require many copies of identical data to be saved on disk. Intead, we store the data in folders according to the  data_  hash and symlink copies for each run.  Below the hash values are the set of properties whose values differ from their specified defaults.   Specifying data-hash affecting parameters  By default, the  data_  hash includes all properties that do not begin with  c_  as these are passed directly to the Python+Tensorflow LFADS code. This includes all of the parameters that you have added to  RunParams . If you need to adjust this behavior, override the method  getListPropertiesNotAffectingInputData  in your  RunParams  instance.    RunParams  is a value class  Unlike all of the other classes,  RunParams  is not a handle but a value class, which acts similarly to a  struct  in that it is passed by value. This means that after adding the  RunParams  instance  par  to the  RunCollection , we can modify  par  and then add it again to define a second set of parameters, like this: par . c_gen_dim   =   96 ;  rc . addParams ( par );  par . c_gen_dim   =   128 ;  rc . addParams ( par );     Generating hyperparameter value sweeps  If you wish to sweep a specific property or set of properties, you can create a  RunParams  instance, set the other properties as needed, and then call  generateSweep  to build an array of  RunParams  instances: parSet   =   par . generateSweep ( 'c_gen_dim' ,   [ 32   64   96   128 ]);  rc . addParams ( parSet );   Or along multiple parameters in a grid: parSet   =   par . generateSweep ( 'c_gen_dim' ,   [ 32   64   96   128 ],   'c_co_dim' ,   0 : 2 : 4 );  rc . addParams ( parSet );",
            "title": "RunParams data and param hashes"
        },
        {
            "location": "/drive/#check-the-runcollection",
            "text": "The  RunCollection  will now display inforation about the parameter settings and run specifications that have been added:  >>   rc  MyExperiment . RunCollection  \" exampleRun \"  ( 5   runs   total ) \n   Dataset   Collection  \" lorenz_example \"  ( 4   datasets )   in   ~/ lorenz_example / datasets \n   Path :   ~/ lorenz_example / runs / exampleRun \n\n   1   parameter   settings \n   [ 1   param_jMCQCl   data_ - MSPr6 ]   MyExperiment . RunParams   useAlignmentMatrix = true   c_factors_dim = 8   c_in_factors_dim = 8   c_co_dim = 64   c_batch_size = 150 \n\n   5   run   specifications \n   [   1 ]   MyExperiment . RunSpec  \" single_dataset001 \"  ( 1   datasets ) \n   [   2 ]   MyExperiment . RunSpec  \" single_dataset002 \"  ( 1   datasets ) \n   [   3 ]   MyExperiment . RunSpec  \" single_dataset003 \"  ( 1   datasets ) \n   [   4 ]   MyExperiment . RunSpec  \" single_dataset004 \"  ( 1   datasets ) \n   [   5 ]   MyExperiment . RunSpec  \" all \"  ( 4   datasets ) \n\n                           name :   'exampleRun' \n                        comment :   '' \n                       rootPath :   '~/lorenz_example/runs' \n                        version :   3 \n              datasetCollection :   [ 1 x1   MyExperiment . DatasetCollection ] \n                           runs :   [ 5 x1   MyExperiment . Run ] \n                         params :   [ 1 x1   MyExperiment . RunParams ] \n                       runSpecs :   [ 5 x1   MyExperiment . RunSpec ] \n                        nParams :   1 \n                      nRunSpecs :   5 \n                     nRunsTotal :   5 \n                      nDatasets :   4 \n                           path :   '~/lorenz_example/runs/exampleRun' \n       pathsCommonDataForParams :   { '~/lorenz_example/runs/exampleRun/data_-MSPr6' } \n                 pathsForParams :   { '~/lorenz_example/runs/exampleRun/param_jMCQCl' } \n     fileShellScriptTensorboard :   '~/lorenz_example/runs/exampleRun/launch_tensorboard.sh' \n                fileSummaryText :   '~/lorenz_example/runs/exampleRun/summary.txt' \n        fileShellScriptRunQueue :   '~/lorenz_example/runs/exampleRun/run_lfadsqueue.py'",
            "title": "Check the RunCollection"
        },
        {
            "location": "/drive/#prepare-for-lfads",
            "text": "Now that you\u2019ve set up your run collection with all of your runs, you can run the following to generate the files needed for running LFADS.  rc . prepareForLFADS ();   This will generate files for all runs. If you decide to add new runs, by adding additional run specifications or parameters, you can simply call  prepareForLFADS  again. Existing files won\u2019t be overwritten unless you call  rc.prepareForLFADS(true) .  Also, a  summary.txt  file will be generated which can be useful for identifying all of the runs and their locations on disk.  MyExperiment.RunCollection \"exampleRun\" (4 runs total)\n  Path: ~/lorenz_example/runs/exampleRun\n  Dataset Collection \"lorenz_example\" (3 datasets) in ~/lorenz_example/datasets\n\n  ------------------------\n\n  4 Run Specifications:\n\n    [runSpec 1] MyExperiment.RunSpec \"single_dataset001\" (1 datasets)\n      [ds 1] MyExperiment.Dataset \"dataset001\"\n\n    [runSpec 2] MyExperiment.RunSpec \"single_dataset002\" (1 datasets)\n      [ds 2] MyExperiment.Dataset \"dataset002\"\n\n    [runSpec 3] MyExperiment.RunSpec \"single_dataset003\" (1 datasets)\n      [ds 3] MyExperiment.Dataset \"dataset003\"\n\n    [runSpec 4] MyExperiment.RunSpec \"all\" (3 datasets)\n      [ds 1] MyExperiment.Dataset \"dataset001\"\n      [ds 2] MyExperiment.Dataset \"dataset002\"\n      [ds 3] MyExperiment.Dataset \"dataset003\"\n\n  ------------------------\n\n  1 Parameter Settings:\n\n    [1 param_pqQbzB] MyExperiment.RunParams\n      Diff: useAlignmentMatrix=true setInFactorsMatchDataForSingleDataset=true c_factors_dim=8 c_in_factors_dim=8 c_ic_enc_dim=64 c_gen_dim=64 c_co_dim=0 c_batch_size=150 c_learning_rate_stop=0.001\n\n      spikeBinMs: 2\n      trainToTestRatio: 4\n      useAlignmentMatrix: true\n      scaleIncreaseStepsWithDatasets: true\n      setInFactorsMatchDataForSingleDataset: true\n      c_cell_clip_value: 5\n      c_factors_dim: 8\n      c_in_factors_dim: 8\n      c_ic_enc_dim: 64\n      c_ci_enc_dim: 128\n      c_gen_dim: 64\n      c_keep_prob: 0.95\n      c_learning_rate_decay_factor: 0.98\n      c_device: /gpu:0\n      c_co_dim: 0\n      c_do_causal_controller: false\n      c_l2_gen_scale: 500\n      c_l2_con_scale: 500\n      c_batch_size: 150\n      c_kl_increase_steps: 900\n      c_l2_increase_steps: 900\n      c_controller_input_lag: 1\n      c_ic_dim: 64\n      c_con_dim: 128\n      c_learning_rate_stop: 0.001\n      c_temporal_spike_jitter_width: 0\n      c_allow_gpu_growth: true\n      c_kl_ic_weight: 1\n      c_kl_co_weight: 1",
            "title": "Prepare for LFADS"
        },
        {
            "location": "/files/",
            "text": "File organization used by LFADS Run Manager\n\u00b6\n\n\nYou won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to \nrunning your model\n.\n\n\nRun collection organization\n\u00b6\n\n\nAfter running \nMyExperiment.drive_script\n and calling \nrc.prepareForLFADS()\n, you\u2019ll see the following directory tree on your hard drive:\n\n\n$ tree -L \n4\n ~/lorenz_example/\n.\n\u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset003.mat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dataset004.mat\n\u2514\u2500\u2500 runs\n    \u2514\u2500\u2500 exampleRun\n        \u251c\u2500\u2500 data_IR3OQV\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n        \u251c\u2500\u2500 launch_tensorboard.sh\n        \u251c\u2500\u2500 param_pqQbzB\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u251c\u2500\u2500 run_lfadsqueue.py\n        \u2514\u2500\u2500 summary.txt\n\n\n9\n directories, \n13\n files\n\n\n\n\n\n\ndatasets\n:\n\n\nInside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called \nLFADS.Utils.generateDemoDatasets(...)\n.\n\n\nruns\n:\n\n\n\n\nThe root runs folder you specified in the constructor to \nRunCollection\n.\n\nrunRoot\n \n=\n \n'~/lorenz_example/runs'\n;\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n\n\n\nexampleRun\n:\n\n\n\n\nThe location of this specific \nRunCollection\n, based on the name you passed to constructor of \nRunCollection\n\n\nrc\n \n=\n \nMyExperiment\n.\nRunCollection\n(\nrunRoot\n,\n \n'exampleRun'\n,\n \ndc\n);\n\n\n\n\n\n\ndata_IR3OQV\n:\n\n\n\n\nThe location of the exported datasets for \nRunParams\n whose data hash is \nIR3OQV\n. The data hash includes properties of \nRunParams\n that affect the exported data, as described \nhere\n.\n\n\n\n\ninputInfo_datasetName.mat\n\n\nContains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets.\n\n\nlfads_datasetName.h5\n:\n\n\nThe spike counts data directly read by LFADS\n\n\n\n\n\n\n\n\nparam_pqQbzB\n:\n    :   Location of the individual runs generated with the \nRunParams\n instance whose param hash is \npqQbzB\n. The subfolders correspond to the run names passed to \nRunSpec\n, and their contents will be discussed below.\n        \nrc\n.\naddRunSpec\n(\nMyExperiment\n.\nRunSpec\n(\n'all'\n,\n \ndc\n,\n \n1\n:\ndc\n.\nnDatasets\n));\n\n\n\n\n\n\nlaunch_tensorboard.sh\n:\n\n\nShell script which will launch TensorBoard, optionally on a specific port\n\n./launch_tensorboard.sh \n50000\n\n\n\n\nrun_lfadsqueue.py\n:\n\n\nPython script which will launch the LFADS Run Queue on all runs within the \nexampleRun\n \nRunCollection\n:\n\npython run_lfadsqueue.py\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual run folders\n\u00b6\n\n\nWithin an run folder, we find:\n\n\n$ tree ~/lorenz_example/runs/exampleRuns/param_pqQbzB/all\n.\n\u251c\u2500\u2500 lfads.done\n\u251c\u2500\u2500 lfads.out\n\u251c\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_IR3OQV/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_IR3OQV/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_IR3OQV/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_IR3OQV/lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_IR3OQV/lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_IR3OQV/lfads_dataset003.h5\n\u251c\u2500\u2500 lfadsOutput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint_lve\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fitlog.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-0.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-38740.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 events.out.tfevents.1507613307.photon\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_params\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average\n\u2514\u2500\u2500 lfads_train.sh\n\n\n\n\n\n\nlfadsInput\n:\n\n\nContains relative symbolic links to the contents of \ndata_IR3OQV\n, enabling multiple runs to share data without duplication. The \n.h5\n files will be read in by LFADS.\n\n\nlfadsOutput\n:\n\n\n\n\nThe directory to which LFADS will write generated output. Some of the key files within are:\n\n\n\n\ncheckpoint_lve\n:\n\n\nContains the saved checkpoint with the lowest validation error.\n\n\nfitlog.csv\n:\n\n\nContains information about the various costs through training\n\n\nhyperparameters-0.txt\n:\n\n\nRecords the hyperparameters used by LFADS\n\n\nmodel_runs_datasetName.h5_train_posterior_sample_and_average\n:\n\n\nContains the posterior mean samples and averages for the training trials\n\n\nmodel_runs_datasetName.h5_valid_posterior_sample_and_average\n:\n\n\nContains the posterior mean samples and averages for the validation trials\n\n\n\n\n\n\nlfads_train.sh\n:\n\n\nShell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager.\n\n\nlfads.done\n:\n\n\nEmpty text file indicating to the LFADS Run Queue that this model has already completed successfully\n\n\nlfads.out\n:\n\n\nLogged output of LFADS generated by the LFADS Run Queue\n\n\n\n\nClearing LFADS Output\n\u00b6\n\n\nIf you wanted to re-train a model from scratch, you can call \nrun.deleteLFADSOutput()\n from Matlab, or you could manually delete the \nlfadsOutput\n folder, \nlfads.done\n, and \nlfads.out\n.",
            "title": "File Organization"
        },
        {
            "location": "/files/#file-organization-used-by-lfads-run-manager",
            "text": "You won\u2019t likely need to dive into the raw files produced by lfads-run-manager and LFADS, but we include a brief overview here to help understand what\u2019s stored where. You can safely skip to  running your model .",
            "title": "File organization used by LFADS Run Manager"
        },
        {
            "location": "/files/#run-collection-organization",
            "text": "After running  MyExperiment.drive_script  and calling  rc.prepareForLFADS() , you\u2019ll see the following directory tree on your hard drive:  $ tree -L  4  ~/lorenz_example/\n.\n\u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dataset003.mat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dataset004.mat\n\u2514\u2500\u2500 runs\n    \u2514\u2500\u2500 exampleRun\n        \u251c\u2500\u2500 data_IR3OQV\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5\n        \u251c\u2500\u2500 launch_tensorboard.sh\n        \u251c\u2500\u2500 param_pqQbzB\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 all\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset001\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 single_dataset002\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 single_dataset003\n        \u251c\u2500\u2500 run_lfadsqueue.py\n        \u2514\u2500\u2500 summary.txt 9  directories,  13  files   datasets :  Inside live the raw datasets, unrelated to lfads-run-manager. These were created by you when you called  LFADS.Utils.generateDemoDatasets(...) .  runs :   The root runs folder you specified in the constructor to  RunCollection . runRoot   =   '~/lorenz_example/runs' ;  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );    exampleRun :   The location of this specific  RunCollection , based on the name you passed to constructor of  RunCollection  rc   =   MyExperiment . RunCollection ( runRoot ,   'exampleRun' ,   dc );    data_IR3OQV :   The location of the exported datasets for  RunParams  whose data hash is  IR3OQV . The data hash includes properties of  RunParams  that affect the exported data, as described  here .   inputInfo_datasetName.mat  Contains data collected when generating the LFADS input, including the raw spike counts, condition ids, time vector, and trial indices assigned to the training and validation sets.  lfads_datasetName.h5 :  The spike counts data directly read by LFADS     param_pqQbzB :\n    :   Location of the individual runs generated with the  RunParams  instance whose param hash is  pqQbzB . The subfolders correspond to the run names passed to  RunSpec , and their contents will be discussed below.\n         rc . addRunSpec ( MyExperiment . RunSpec ( 'all' ,   dc ,   1 : dc . nDatasets ));    launch_tensorboard.sh :  Shell script which will launch TensorBoard, optionally on a specific port ./launch_tensorboard.sh  50000   run_lfadsqueue.py :  Python script which will launch the LFADS Run Queue on all runs within the  exampleRun   RunCollection : python run_lfadsqueue.py",
            "title": "Run collection organization"
        },
        {
            "location": "/files/#individual-run-folders",
            "text": "Within an run folder, we find:  $ tree ~/lorenz_example/runs/exampleRuns/param_pqQbzB/all\n.\n\u251c\u2500\u2500 lfads.done\n\u251c\u2500\u2500 lfads.out\n\u251c\u2500\u2500 lfadsInput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset001.mat -> ../../../data_IR3OQV/inputInfo_dataset001.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset002.mat -> ../../../data_IR3OQV/inputInfo_dataset002.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inputInfo_dataset003.mat -> ../../../data_IR3OQV/inputInfo_dataset003.mat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset001.h5 -> ../../../data_IR3OQV/lfads_dataset001.h5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_dataset002.h5 -> ../../../data_IR3OQV/lfads_dataset002.h5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lfads_dataset003.h5 -> ../../../data_IR3OQV/lfads_dataset003.h5\n\u251c\u2500\u2500 lfadsOutput\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 checkpoint_lve\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fitlog.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-0.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hyperparameters-38740.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 events.out.tfevents.1507613307.photon\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.data-00000-of-00001\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.index\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lfads_vae.ckpt-37206.meta\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_params\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset001.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset002.h5_valid_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_runs_dataset003.h5_train_posterior_sample_and_average\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 model_runs_dataset003.h5_valid_posterior_sample_and_average\n\u2514\u2500\u2500 lfads_train.sh   lfadsInput :  Contains relative symbolic links to the contents of  data_IR3OQV , enabling multiple runs to share data without duplication. The  .h5  files will be read in by LFADS.  lfadsOutput :   The directory to which LFADS will write generated output. Some of the key files within are:   checkpoint_lve :  Contains the saved checkpoint with the lowest validation error.  fitlog.csv :  Contains information about the various costs through training  hyperparameters-0.txt :  Records the hyperparameters used by LFADS  model_runs_datasetName.h5_train_posterior_sample_and_average :  Contains the posterior mean samples and averages for the training trials  model_runs_datasetName.h5_valid_posterior_sample_and_average :  Contains the posterior mean samples and averages for the validation trials    lfads_train.sh :  Shell script which will launch LFADS to train the model. This script may potentially chain performing posterior mean sampling and writing the model parameters, depending on how it was generated by lfads-run-manager.  lfads.done :  Empty text file indicating to the LFADS Run Queue that this model has already completed successfully  lfads.out :  Logged output of LFADS generated by the LFADS Run Queue",
            "title": "Individual run folders"
        },
        {
            "location": "/files/#clearing-lfads-output",
            "text": "If you wanted to re-train a model from scratch, you can call  run.deleteLFADSOutput()  from Matlab, or you could manually delete the  lfadsOutput  folder,  lfads.done , and  lfads.out .",
            "title": "Clearing LFADS Output"
        },
        {
            "location": "/multisession/",
            "text": "Multi-dataset Stitching Models\n\u00b6\n\n\nIf you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a \nRunSpec\n, the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through \nread-in\n and \nreadout\n alignment matrices.\n\n\nBelow is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset.\n\n\n\n\nA similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial.\n\n\nGenerating alignment matrices\n\u00b6\n\n\nThese read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a \nRunSpec\n, and the hyperparameter \nuseAlignmentMatrix\n is set to \ntrue\n in the \nRunParams\n, then \nlfads-run-manager\n will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as:\n\n\n\n\nGenerate condition-averaged firing rates for each neuron for each condition for each dataset\n\n\nConcatenate all of neurons from all datasets together to build a matrix which is (\nnTime * nConditions\n) \nnNeuronsTotal\n\n\nPerform PCA on this matrix and keep the projections of the data into the top \nnFactors\n components. These represent the global shared structure of the data across all datasets.\n\n\nFor each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix.\n\n\n\n\nThese matrices will be computed for you automatically by \nrun.prepareForLFADS()\n and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by \nlfads-run-manager\n.\n\n\n\n\nAlignment biases\n\n\nIn addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts befor projecting through the matrix. Consequently, \nlfads-run-manager\n seeds this bias with the negative mean of the rates of each neuron.\n\n\n\n\nVerifying the alignment matrices\n\u00b6\n\n\nTo visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset.\n\n\nUnder the hood, the alignment matrix calculations are performed by an instance of \nLFADS.MutlisessionAlignmentTool\n. To plot the reconstruction quality, you can call \ntool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot)\n, like so:\n\n\nrun\n.\ndoMultisessionAlignment\n();\n\n\ntool\n \n=\n \nrun\n.\nmultisessionAlignmentTool\n;\n\n\n\nnFactorsPlot\n \n=\n \n3\n;\n\n\nconditionsToPlot\n \n=\n \n[\n1\n \n20\n \n40\n];\n\n\ntool\n.\nplotAlignmentReconstruction\n(\nnFactorsPlot\n,\n \nconditionsToPlot\n);\n\n\n\n\n\n\n\nIn this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance.\n\n\nThe actual alignment matrices can be accessed using:\n\ntool\n.\nalignmentMatrices\n \n% nDatasets x 1 cell array of read-in matrices",
            "title": "Multi-sesion Stitched Models"
        },
        {
            "location": "/multisession/#multi-dataset-stitching-models",
            "text": "If you specify multiple datasets to be included in an LFADS run by selecting multiple datasets in a  RunSpec , the resulting model will stitch together the multiple datasets. The concept is to generate the spiking data in all of the included datasets using the same encoder and generator RNNs, but to interface to the separate neural datasets through  read-in  and  readout  alignment matrices.  Below is a schematic of the readout side. Here, the generator RNN and readout from generator units to factors is the same for all datasets. Therefore, one intends that the factor trajectories would be similar for similar trials / conditions across the datasets. Going from factors to rates, however, the recorded neurons are, in general, not the same across datasets, and the cardinality may differ. Thus, dataset-specific readout matrices are used to combine the factors to produce each of the recorded neurons\u2019 rates on each dataset.   A similar set of dataset specific read-in matrices are used to connect the spiking data to the encoder RNN in order to produce initial conditions and inferred inputs for each trial.",
            "title": "Multi-dataset Stitching Models"
        },
        {
            "location": "/multisession/#generating-alignment-matrices",
            "text": "These read-in and readout alignment matrices are learned from the data along with the other parameters. However, it\u2019s useful to seed the alignment matrices with an initial guess that suggests the correspondence between the datasets. If you have multiple datasets in a  RunSpec , and the hyperparameter  useAlignmentMatrix  is set to  true  in the  RunParams , then  lfads-run-manager  will automatically generate read-in alignment matrices from your data using a principal components regression algorithm that proceeds as:   Generate condition-averaged firing rates for each neuron for each condition for each dataset  Concatenate all of neurons from all datasets together to build a matrix which is ( nTime * nConditions )  nNeuronsTotal  Perform PCA on this matrix and keep the projections of the data into the top  nFactors  components. These represent the global shared structure of the data across all datasets.  For each dataset individually, regress these projection scores onto the condition-averaged rates from that dataset alone. The regression coefficients thus transform from that dataset\u2019s neurons to the global shared structure, and consequently, we take this matrix of regression coefficients as the readout matrix.   These matrices will be computed for you automatically by  run.prepareForLFADS()  and exported in the LFADS input folder. LFADS will generate an initial guess for the readout alignment matrix, which transforms from common factors back to dataset-specific rates, using the pseudo-inverse of the read-in alignment matrix computed by  lfads-run-manager .   Alignment biases  In addition to this alignment read-in matrix, there is also an alignment bias vector which will be added to each neuron\u2019s counts befor projecting through the matrix. Consequently,  lfads-run-manager  seeds this bias with the negative mean of the rates of each neuron.",
            "title": "Generating alignment matrices"
        },
        {
            "location": "/multisession/#verifying-the-alignment-matrices",
            "text": "To visualize how well these initial alignment matrices are working, we can compare the common global PCs from all datasets against the projection of each dataset through the read-in matrices. That is, we can plot the regression target (global PCs) against the best possible reconstruction from each dataset.  Under the hood, the alignment matrix calculations are performed by an instance of  LFADS.MutlisessionAlignmentTool . To plot the reconstruction quality, you can call  tool.plotAlignmentReconstruction(numberOrIndicesOfFactorsToPlot, numberOrIndicesOfConditionsToPlot) , like so:  run . doMultisessionAlignment ();  tool   =   run . multisessionAlignmentTool ;  nFactorsPlot   =   3 ;  conditionsToPlot   =   [ 1   20   40 ];  tool . plotAlignmentReconstruction ( nFactorsPlot ,   conditionsToPlot );    In this example, the single-dataset predictions look quite similar to the global target, especially in the first 2 principal components which capture most of the variance.  The actual alignment matrices can be accessed using: tool . alignmentMatrices   % nDatasets x 1 cell array of read-in matrices",
            "title": "Verifying the alignment matrices"
        },
        {
            "location": "/running/",
            "text": "Running LFADS\n\u00b6\n\n\nTo train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call \nrun_lfads.py\n and do the work of training the model. \nlfads-run-manager\n provides two ways to go about this.\n\n\n\n\nAdd the \nrun_lfads.py\n folder to your shell PATH\n\n\nBe sure that the LFADS python source folder is on your shell path, such that running \nwhich run_lfads.py\n prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like \nexport PATH=$PATH:/path/to/models/research/lfads\n and consider adding this to your \n.bashrc\n file.\n\n\nIf Matlab is able to determine the location of \nrun_lfads.py\n (meaning that it\u2019s own inherited \nPATH\n was set correctly), it will prepend an \nexport PATH=...\n statement to each generated shell script for you. If not, you can try calling \nsetenv('PATH', '...')\n from within Matlab to add \nrun_lfads.py\n to the path. before generating the shell scripts.\n\n\n\n\n\n\nVirtualenv support\n\n\nEach of the methods below supports a \n'virtualenv'\n,\n \n'environmentName'\n parameter-value argument. If specified, a \nsource activate environmentName\n will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment.\n\n\n\n\nLaunching each run individually from shell scripts\n\u00b6\n\n\nIt is possible to run each model individually, but you\u2019ll probably prefer to \nqueue everything at once\n.\n\n\nTraining the model\n\u00b6\n\n\nThe first is to manually generate shell scripts for each run and then run them yourself. First, for each run \ni\n, you will call:\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptLFADSTrain\n(\n'cuda_visible_devices'\n,\n \n0\n,\n \n'display'\n,\n \n500\n);\n\n\n\n\n\nHere, you should specify options that will be written into the shell script, the key ones being:\n\n\n\n\ncuda_visible_devices\n - which GPU index to run this model on, e.g. \n500\n\n\ndisplay\n - the X display to use, e.g. \n0\n. The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like \ntightvnc\n.\n\n\nappendPosteriorMeanSample\n - \ntrue\n or \nfalse\n specifying whether to chain the posterior mean sampling operation after the training is finished. The default is \nfalse\n, but if you set this to \ntrue\n, you won\u2019t need to call \nwriteShellScriptPosteriorMeanSample\n below.\n\n\nappendWriteModelParams\n - \ntrue\n or \nfalse\n specifying whether to chain the posterior mean sampling operation after the training is finished. The default is \nfalse\n, but if you set this to \ntrue\n, you won\u2019t need to call \nwriteShellScriptWriteModelParams\n below.\n\n\n\n\nThis will generate an \nlfads_train.sh\n in the corresponding run\u2019s folder. For the first run in our example, this is at\n\n~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfads_train.sh\n\n\n\nThe script essentially launches Python to run \nrun_lfads.py\n with the specific parameters you\u2019ve indicated in \nRunParams\n and pointing at the corresponding datasets, which were saved earlier when we called \nrc.prepareForLFADS\n.\n\n\n#!/bin/bash\n\n\nCUDA_VISIBLE_DEVICES\n=\n0\n python \n$(\nwhich run_lfads.py\n)\n --data_dir\n=\n~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfadsInput --data_filename_stem\n=\nlfads --lfads_save_dir\n=\n~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfadsOutput --allow_gpu_growth\n=\ntrue\n --batch_size\n=\n256\n --cell_clip_value\n=\n5\n.000000 --ci_enc_dim\n=\n128\n --co_dim\n=\n4\n --con_dim\n=\n128\n --controller_input_lag\n=\n1\n --device\n=\n/gpu:0 --do_causal_controller\n=\nfalse\n --factors_dim\n=\n8\n --gen_dim\n=\n100\n --ic_dim\n=\n64\n --ic_enc_dim\n=\n128\n --in_factors_dim\n=\n8\n --keep_prob\n=\n0\n.950000 --kl_co_weight\n=\n1\n.000000 --kl_ic_weight\n=\n1\n.000000 --kl_increase_steps\n=\n900\n --l2_con_scale\n=\n500\n.000000 --l2_gen_scale\n=\n500\n.000000 --l2_increase_steps\n=\n900\n --learning_rate_decay_factor\n=\n0\n.980000 --learning_rate_stop\n=\n0\n.000010 --temporal_spike_jitter_width\n=\n0\n\n\n\n\n\nRunning the \nlfads_train.sh\n script will launch the Tensorflow training which will take some time. You likely want to launch this in a \ntmux\n session if running remotely.\n\n\nSampling the posterior means\n\u00b6\n\n\nNext, generate the \nlfads_posterior_mean_sample.sh\n script to sample the posterior means, which can be launched after training has completed. If you set \nappendPosteriorMeanSample\n to \ntrue\n in \nwriteShellScriptLFADSTrain\n, you can skip this step.\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptLFADSPosteriorMeanSample\n(\n'cuda_visible_devices'\n,\n \n0\n);\n\n\n\n\n\nWriting the model parameters\n\u00b6\n\n\nLastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using\n\n\nrc\n.\nruns\n(\ni\n).\nwriteShellScriptWriteModelParams\n(\n'cuda_visible_devices'\n,\n \n0\n);\n\n\n\n\n\nIf you set \nappendWriteModelParams\n to \ntrue\n in \nwriteShellScriptLFADSTrain\n, you can skip this step. These results will be written to a file called \nlfadsOutput/model_params\n, though these results can be loaded into Matlab using \nrun.loadModelTrainedParams()\n.\n\n\nLaunching Tensorboard\n\u00b6\n\n\nYou can monitor the progress of each run by generating a script that launches TensorBoard.\n\nrc\n.\nwriteTensorboardShellScript\n();\n\n\n\n\nThis will create \nlaunch_tensorboard.sh\n which will launch Tensorboard which can then be visited at \nhttp://localhost:PORT\n.\n\n\nLFADS Queue: Automatically queueing many runs\n\u00b6\n\n\nManually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the Python task queueing system which will take care of training all the LFADS models for you.\n\n\n\n\nOnly supported on Linux\n\n\nUnfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on \nnvidia-smi\n, though it\u2019s theoretically possible with \ncuda-smi\n with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get \ntmux\n working.\n\n\n\n\nFirst, we\u2019ll generate the Python script from Matlab that enumerates all of the runs:\n\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'display'\n,\n \n500\n,\n \n'gpuList'\n,\n \n[\n0\n \n1\n \n2\n \n3\n]);\n\n\n\n\n\nThe first argument \ndisplay\n specifies the X11 display for plotting as before. \ngpuList\n enumerates the indices of GPUs that can be used for the runs. This argument is optional if all of the GPUs are viable for Tensorflow on your system.\n\n\n\n\nCapping the number of simultaneous runs\n\n\nYou can also manually specify \nmaxTasksSimultaneously\n if you wish to cap the number of simultaneous runs. By default this is set to the minimum of the number of CPUs on your system and the available GPU memory. By default, each LFADS task is assumed to use 2000 MB of GPU memory, but you can adjust this by specifying \ngpuMemoryRequired\n.\n\n\n\n\nThis will generate a Python script \nrun_lfads.py\n, which for our example lives here:\n\n\n~/lorenz_exajjmple/runs/exampleRun/run_lfadsqueue.py\n\n\n\n\n\n\nlfads-run-manager repo folder will be added to your PYTHONPATH automatically\n\n\nThe \nrun_lfadsqueue.py\n script depends on \nlfadsqueue.py\n, which lives in the root of the \nlfads-run-manager\n repository. This will be added to your PYTHONPATH environment variable in the \nrun_lfadsqueue.py\n script.\n\n\n\n\n\n\nInstall and configure \ntmux\n\n\nThe LFADS queue launches each LFADS run inside its own \ntmux\n session to make it easy to monitor the runs as they are running. You\u2019ll need to install \ntmux\n.\n\n\nAlso, \ntmux\n is finnicky about environment variables, which are only loaded when the \ntmux\n server first launches, not when a new session is started. The main one you need is that \nrun_lfads.py\n must be on your \nPATH\n somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited \nPATH\n was set correctly), it will prepend an \nexport PATH=...\n statement to each \nlfads_train.sh\n script for you. If not, you can try calling \nsetenv('PATH', '...')\n from within Matlab to add \nrun_lfads.py\n to the path. before generating the shell scripts.\n\n\nIf you\u2019re having trouble, you might want to launch a new \ntmux\n session using:\n\n\ntmux new-session\n\n\n\n\nThen from inside \ntmux\n, test that \nwhich run_lfads.py\n prints a location and that you are able to launch python and run \nimport\n \ntensorflow\n \nas\n \ntf\n without any issues.\n\n\n\n\nYou can then kick everything off by running \npython run_lfadsqueue.py\n at the command line. It\u2019s recommended to do this from inside your own \ntmux\n session if you\u2019re running on a remote server, so you can monitor the task runner.\n\n\n\n\nPython virtual environments\n\n\nIf tensorflow is installed in a Python virtual environment, you can have this environment be automatically \nsource activate\nd within the training scripts using:\n\nrc\n.\nwriteShellScriptRunQueue\n(\n'display'\n,\n \n500\n,\n \n'gpuList'\n,\n \n[\n0\n \n1\n \n2\n \n3\n],\n \n'virtualenv'\n,\n \n'tensorflow'\n);\n\n\n\n\n\n\nA few notes on how the system works:\n\n\n\n\nOutput from Python will be \ntee\n\u2018d into \nlfads.out\n, so you can check the output during or afterwards either there or in the \ntmux\n session.\n\n\nWhen a model finishes training and posterior mean sampling, a file called \nlfads.done\n will be created\n\n\nIf the task runner detects an \nlfads.done\n file, it will skip that run. Unless you pass \n'rerun'\n,\n \ntrue\n to \nwriteShellScriptRunQueue\n, in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run.\n\n\nIf a run fails, the error will be printed by the task runner and \nlfads.done\n will not be created\n\n\nA running tally of how many runs are currently running, have finished, or have failed will be printed\n\n\nYou can enter a run\u2019s \ntmux\n session directly to monitor it. The list of sessions can be obtained using \ntmux list-sessions\n. You can also abort it using \nCtrl-C\n and it will be marked as failed by the task runner.\n\n\n\n\nThe \nrun_lfadsqueue.py\n script will periodically output updates about how the runs are proceeding:\n\n\n(\ntensorflow\n)\n \u279c  exampleRun python run_lfadsqueue.py\nWarning: tmux sessions will be nested inside the current session\nQueue: Launching TensorBoard on port \n42561\n in tmux session exampleRun_tensorboard_port42561\nbash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port\n=\n42561\n\nQueue: Initializing with \n2\n GPUs and \n12\n CPUs, max \n4\n simultaneous tasks\nTask lfads_param_pqQbzB__single_dataset001: launching on gpu \n0\n\nTask lfads_param_pqQbzB__single_dataset001: started in tmux session lfads_param_pqQbzB__single_dataset001 on GPU \n0\n with PID \n19498\n\nTask lfads_param_pqQbzB__single_dataset002: launching on gpu \n1\n\nTask lfads_param_pqQbzB__single_dataset002: started in tmux session lfads_param_pqQbzB__single_dataset002 on GPU \n1\n with PID \n19527\n\nTask lfads_param_pqQbzB__single_dataset003: launching on gpu \n0\n\nTask lfads_param_pqQbzB__single_dataset003: started in tmux session lfads_param_pqQbzB__single_dataset003 on GPU \n0\n with PID \n19551\n\nTask lfads_param_pqQbzB__all: launching on gpu \n1\n\nTask lfads_param_pqQbzB__all: started in tmux session lfads_param_pqQbzB__all on GPU \n1\n with PID \n19585\n\nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to \n0\n.009800.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to \n0\n.009800.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to \n0\n.009604.\nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to \n0\n.009604.\nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to \n0\n.009412.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to \n0\n.009412.\n\n\n\n\nAs the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits \nc_learning_rate_stop\n). When a task fails or completes, the queue will print out a running tally.\n\n\nNote that TensorBoard has automatically been launched on an available port, here on \n42561\n. You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using \ntmux list-sessions\n.\n\n\n\u279c  exampleRun tmux list-sessions\nmatlab: \n4\n windows \n(\ncreated Tue Oct  \n3\n \n21\n:51:49 \n2017\n)\n \n[\n201x114\n]\n \n(\nattached\n)\n\nexampleRun_tensorboard_port42561: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_pqQbzB__all: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:17 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_pqQbzB__single_dataset001: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x114\n]\n\nlfads_param_pqQbzB__single_dataset002: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:16 \n2017\n)\n \n[\n201x113\n]\n\nlfads_param_pqQbzB__single_dataset003: \n1\n windows \n(\ncreated Fri Oct  \n6\n \n14\n:43:17 \n2017\n)\n \n[\n201x113\n]\n\n\n\n\n\nIf you wish to abort ongoing runs, you can either attach to them directly and use \nCtrl-C\n, or use \ntmux kill-session SESSIONNAME\n. When everything has completed, you\u2019ll see something like this:\n\n\nTask lfads_param_pqQbzB__all: Stopping optimization based on learning rate criteria.\nTask lfads_param_pqQbzB__all: completed successfully\nQueue: All tasks completed.\nQueue: \n0\n skipped, \n4\n finished, \n0\n failed, \n0\n running",
            "title": "Running LFADS"
        },
        {
            "location": "/running/#running-lfads",
            "text": "To train the LFADS model using Python+Tensorflow, you need to generate shell scripts that will actually call  run_lfads.py  and do the work of training the model.  lfads-run-manager  provides two ways to go about this.   Add the  run_lfads.py  folder to your shell PATH  Be sure that the LFADS python source folder is on your shell path, such that running  which run_lfads.py  prints the directory where the Python+Tensorflow code LFADS is located. If not, you\u2019ll need to run something like  export PATH=$PATH:/path/to/models/research/lfads  and consider adding this to your  .bashrc  file.  If Matlab is able to determine the location of  run_lfads.py  (meaning that it\u2019s own inherited  PATH  was set correctly), it will prepend an  export PATH=...  statement to each generated shell script for you. If not, you can try calling  setenv('PATH', '...')  from within Matlab to add  run_lfads.py  to the path. before generating the shell scripts.    Virtualenv support  Each of the methods below supports a  'virtualenv' ,   'environmentName'  parameter-value argument. If specified, a  source activate environmentName  will be prepended to each script that calls Python for you. This is needed when Tensorflow is installed inside a virtual environment.",
            "title": "Running LFADS"
        },
        {
            "location": "/running/#launching-each-run-individually-from-shell-scripts",
            "text": "It is possible to run each model individually, but you\u2019ll probably prefer to  queue everything at once .",
            "title": "Launching each run individually from shell scripts"
        },
        {
            "location": "/running/#training-the-model",
            "text": "The first is to manually generate shell scripts for each run and then run them yourself. First, for each run  i , you will call:  rc . runs ( i ). writeShellScriptLFADSTrain ( 'cuda_visible_devices' ,   0 ,   'display' ,   500 );   Here, you should specify options that will be written into the shell script, the key ones being:   cuda_visible_devices  - which GPU index to run this model on, e.g.  500  display  - the X display to use, e.g.  0 . The python code generates plots during training that will appear in TensorBoard. Generating these plots requires a display. When running in a remote server, you\u2019ll need to specify this, and possibly to launch an X server using something like  tightvnc .  appendPosteriorMeanSample  -  true  or  false  specifying whether to chain the posterior mean sampling operation after the training is finished. The default is  false , but if you set this to  true , you won\u2019t need to call  writeShellScriptPosteriorMeanSample  below.  appendWriteModelParams  -  true  or  false  specifying whether to chain the posterior mean sampling operation after the training is finished. The default is  false , but if you set this to  true , you won\u2019t need to call  writeShellScriptWriteModelParams  below.   This will generate an  lfads_train.sh  in the corresponding run\u2019s folder. For the first run in our example, this is at ~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfads_train.sh  The script essentially launches Python to run  run_lfads.py  with the specific parameters you\u2019ve indicated in  RunParams  and pointing at the corresponding datasets, which were saved earlier when we called  rc.prepareForLFADS .  #!/bin/bash  CUDA_VISIBLE_DEVICES = 0  python  $( which run_lfads.py )  --data_dir = ~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfadsInput --data_filename_stem = lfads --lfads_save_dir = ~/lorenz_example/runs/exampleRun/param_yMRS4W/single_dataset001/lfadsOutput --allow_gpu_growth = true  --batch_size = 256  --cell_clip_value = 5 .000000 --ci_enc_dim = 128  --co_dim = 4  --con_dim = 128  --controller_input_lag = 1  --device = /gpu:0 --do_causal_controller = false  --factors_dim = 8  --gen_dim = 100  --ic_dim = 64  --ic_enc_dim = 128  --in_factors_dim = 8  --keep_prob = 0 .950000 --kl_co_weight = 1 .000000 --kl_ic_weight = 1 .000000 --kl_increase_steps = 900  --l2_con_scale = 500 .000000 --l2_gen_scale = 500 .000000 --l2_increase_steps = 900  --learning_rate_decay_factor = 0 .980000 --learning_rate_stop = 0 .000010 --temporal_spike_jitter_width = 0   Running the  lfads_train.sh  script will launch the Tensorflow training which will take some time. You likely want to launch this in a  tmux  session if running remotely.",
            "title": "Training the model"
        },
        {
            "location": "/running/#sampling-the-posterior-means",
            "text": "Next, generate the  lfads_posterior_mean_sample.sh  script to sample the posterior means, which can be launched after training has completed. If you set  appendPosteriorMeanSample  to  true  in  writeShellScriptLFADSTrain , you can skip this step.  rc . runs ( i ). writeShellScriptLFADSPosteriorMeanSample ( 'cuda_visible_devices' ,   0 );",
            "title": "Sampling the posterior means"
        },
        {
            "location": "/running/#writing-the-model-parameters",
            "text": "Lastly, we want to export the trained model parameters to disk as an HD5 file. We do this by generating the shell script using  rc . runs ( i ). writeShellScriptWriteModelParams ( 'cuda_visible_devices' ,   0 );   If you set  appendWriteModelParams  to  true  in  writeShellScriptLFADSTrain , you can skip this step. These results will be written to a file called  lfadsOutput/model_params , though these results can be loaded into Matlab using  run.loadModelTrainedParams() .",
            "title": "Writing the model parameters"
        },
        {
            "location": "/running/#launching-tensorboard",
            "text": "You can monitor the progress of each run by generating a script that launches TensorBoard. rc . writeTensorboardShellScript ();   This will create  launch_tensorboard.sh  which will launch Tensorboard which can then be visited at  http://localhost:PORT .",
            "title": "Launching Tensorboard"
        },
        {
            "location": "/running/#lfads-queue-automatically-queueing-many-runs",
            "text": "Manually running each of these shell scripts in sequence can be tedious, especially if you don\u2019t have enough GPUs or CPUs to run them all in parallel and individual runs take hours or days to complete. To make this part of the process more complete, you can alternatively use the Python task queueing system which will take care of training all the LFADS models for you.   Only supported on Linux  Unfortunately, this task queueing system is not supported on Mac OS at the moment, primarily because it depends on  nvidia-smi , though it\u2019s theoretically possible with  cuda-smi  with light code changes. However, Tensorflow has discontinued explicit GPU support on Mac OS anyway. This has also never been tested on Windows, as you\u2019d need to get  tmux  working.   First, we\u2019ll generate the Python script from Matlab that enumerates all of the runs:  rc . writeShellScriptRunQueue ( 'display' ,   500 ,   'gpuList' ,   [ 0   1   2   3 ]);   The first argument  display  specifies the X11 display for plotting as before.  gpuList  enumerates the indices of GPUs that can be used for the runs. This argument is optional if all of the GPUs are viable for Tensorflow on your system.   Capping the number of simultaneous runs  You can also manually specify  maxTasksSimultaneously  if you wish to cap the number of simultaneous runs. By default this is set to the minimum of the number of CPUs on your system and the available GPU memory. By default, each LFADS task is assumed to use 2000 MB of GPU memory, but you can adjust this by specifying  gpuMemoryRequired .   This will generate a Python script  run_lfads.py , which for our example lives here:  ~/lorenz_exajjmple/runs/exampleRun/run_lfadsqueue.py   lfads-run-manager repo folder will be added to your PYTHONPATH automatically  The  run_lfadsqueue.py  script depends on  lfadsqueue.py , which lives in the root of the  lfads-run-manager  repository. This will be added to your PYTHONPATH environment variable in the  run_lfadsqueue.py  script.    Install and configure  tmux  The LFADS queue launches each LFADS run inside its own  tmux  session to make it easy to monitor the runs as they are running. You\u2019ll need to install  tmux .  Also,  tmux  is finnicky about environment variables, which are only loaded when the  tmux  server first launches, not when a new session is started. The main one you need is that  run_lfads.py  must be on your  PATH  somewhere. If Matlab is able to determine this location (meaning that it\u2019s own inherited  PATH  was set correctly), it will prepend an  export PATH=...  statement to each  lfads_train.sh  script for you. If not, you can try calling  setenv('PATH', '...')  from within Matlab to add  run_lfads.py  to the path. before generating the shell scripts.  If you\u2019re having trouble, you might want to launch a new  tmux  session using:  tmux new-session  Then from inside  tmux , test that  which run_lfads.py  prints a location and that you are able to launch python and run  import   tensorflow   as   tf  without any issues.   You can then kick everything off by running  python run_lfadsqueue.py  at the command line. It\u2019s recommended to do this from inside your own  tmux  session if you\u2019re running on a remote server, so you can monitor the task runner.   Python virtual environments  If tensorflow is installed in a Python virtual environment, you can have this environment be automatically  source activate d within the training scripts using: rc . writeShellScriptRunQueue ( 'display' ,   500 ,   'gpuList' ,   [ 0   1   2   3 ],   'virtualenv' ,   'tensorflow' );    A few notes on how the system works:   Output from Python will be  tee \u2018d into  lfads.out , so you can check the output during or afterwards either there or in the  tmux  session.  When a model finishes training and posterior mean sampling, a file called  lfads.done  will be created  If the task runner detects an  lfads.done  file, it will skip that run. Unless you pass  'rerun' ,   true  to  writeShellScriptRunQueue , in which case every run will be rerun. This is convenient if you\u2019ve added additional runs and just want the new ones to run.  If a run fails, the error will be printed by the task runner and  lfads.done  will not be created  A running tally of how many runs are currently running, have finished, or have failed will be printed  You can enter a run\u2019s  tmux  session directly to monitor it. The list of sessions can be obtained using  tmux list-sessions . You can also abort it using  Ctrl-C  and it will be marked as failed by the task runner.   The  run_lfadsqueue.py  script will periodically output updates about how the runs are proceeding:  ( tensorflow )  \u279c  exampleRun python run_lfadsqueue.py\nWarning: tmux sessions will be nested inside the current session\nQueue: Launching TensorBoard on port  42561  in tmux session exampleRun_tensorboard_port42561\nbash /home/djoshea/lorenz_example/runs/exampleRun/launch_tensorboard.sh --port = 42561 \nQueue: Initializing with  2  GPUs and  12  CPUs, max  4  simultaneous tasks\nTask lfads_param_pqQbzB__single_dataset001: launching on gpu  0 \nTask lfads_param_pqQbzB__single_dataset001: started in tmux session lfads_param_pqQbzB__single_dataset001 on GPU  0  with PID  19498 \nTask lfads_param_pqQbzB__single_dataset002: launching on gpu  1 \nTask lfads_param_pqQbzB__single_dataset002: started in tmux session lfads_param_pqQbzB__single_dataset002 on GPU  1  with PID  19527 \nTask lfads_param_pqQbzB__single_dataset003: launching on gpu  0 \nTask lfads_param_pqQbzB__single_dataset003: started in tmux session lfads_param_pqQbzB__single_dataset003 on GPU  0  with PID  19551 \nTask lfads_param_pqQbzB__all: launching on gpu  1 \nTask lfads_param_pqQbzB__all: started in tmux session lfads_param_pqQbzB__all on GPU  1  with PID  19585 \nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to  0 .009800.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to  0 .009800.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to  0 .009604.\nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to  0 .009604.\nTask lfads_param_pqQbzB__single_dataset003:      Decreasing learning rate to  0 .009412.\nTask lfads_param_pqQbzB__single_dataset001:      Decreasing learning rate to  0 .009412.  As the tasks run, the task queue will print out messages related to decreasing the learning rate, which is one way to measure ongonig progress towards the termination criterion (when the learning rate hits  c_learning_rate_stop ). When a task fails or completes, the queue will print out a running tally.  Note that TensorBoard has automatically been launched on an available port, here on  42561 . You can also directly attach to the tmux sessions whose names are indicated in the script as \u201cTasks\u201d, which can be listed using  tmux list-sessions .  \u279c  exampleRun tmux list-sessions\nmatlab:  4  windows  ( created Tue Oct   3   21 :51:49  2017 )   [ 201x114 ]   ( attached ) \nexampleRun_tensorboard_port42561:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x113 ] \nlfads_param_pqQbzB__all:  1  windows  ( created Fri Oct   6   14 :43:17  2017 )   [ 201x113 ] \nlfads_param_pqQbzB__single_dataset001:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x114 ] \nlfads_param_pqQbzB__single_dataset002:  1  windows  ( created Fri Oct   6   14 :43:16  2017 )   [ 201x113 ] \nlfads_param_pqQbzB__single_dataset003:  1  windows  ( created Fri Oct   6   14 :43:17  2017 )   [ 201x113 ]   If you wish to abort ongoing runs, you can either attach to them directly and use  Ctrl-C , or use  tmux kill-session SESSIONNAME . When everything has completed, you\u2019ll see something like this:  Task lfads_param_pqQbzB__all: Stopping optimization based on learning rate criteria.\nTask lfads_param_pqQbzB__all: completed successfully\nQueue: All tasks completed.\nQueue:  0  skipped,  4  finished,  0  failed,  0  running",
            "title": "LFADS Queue: Automatically queueing many runs"
        },
        {
            "location": "/analysis/",
            "text": "Loading and Analyzing LFADS Posterior Means\n\u00b6\n\n\nReusing the \ndrive_script\n\u00b6\n\n\nThe \nLFADS.Run\n instances you created earlier with the \ndrive_script\n uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters.\n\n\nUsing your \nRunCollection\n \nrc\n, you can access individual runs by indexing directly into \nrc.runs\n which has size \nrc.nRunSpecs\n x \nrc.nParams\n. You can also search for a specific run using \nrc.findRun\n\n\nrun1\n \n=\n \nrc\n.\nfindRuns\n(\n'single_dataset001'\n,\n \n'param_pqQbzB'\n);\n\n\n\n\n\nThe first argument searches over the \nRunSpec\ns by name, the second searches over the \nRunParams\n by hash value.\n\n\nLoading the posterior means\n\u00b6\n\n\nUsing the \nRun\n instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully):\n\n\n>>\n \nrun1\n.\ncheckPosteriorMeansExist\n()\n\n\n  \nlogical\n\n\n   \n1\n\n\n\n\n\nAnd then load the posterior means using:\n\npm\n \n=\n \nrun1\n.\nloadPosteriorMeans\n();\n\n\n\n\nOr alternatively, load all of your runs\u2019 posterior means by calling \nrc.loadPosteriorMeans()\n. Then you can access the cached posterior means in each run\u2019s \n.posteriorMeans\n property.\n\n\npm\n will be an instance of \nLFADS.PosteriorMeans\n:\n\n\n>>\n \npm\n \n=\n \nrc\n.\nruns\n(\n1\n).\nposteriorMeans\n\n\n\npm\n \n=\n\n\n  \nPosteriorMeans\n \nwith\n \nproperties\n:\n\n\n                  \ntime\n:\n \n[\n500\nx1\n \ndouble\n]\n\n    \ncontroller_outputs\n:\n \n[]\n\n               \nfactors\n:\n \n[\n8\nx500x1560\n \ndouble\n]\n\n         \ngenerator_ics\n:\n \n[\n64\nx1560\n \ndouble\n]\n\n      \ngenerator_states\n:\n \n[\n64\nx500x1560\n \ndouble\n]\n\n                 \nrates\n:\n \n[\n29\nx500x1560\n \ndouble\n]\n\n             \nvalidInds\n:\n \n[\n312\nx1\n \nuint16\n]\n\n             \ntrainInds\n:\n \n[\n1248\nx1\n \ndouble\n]\n\n                \nparams\n:\n \n[\n1\nx1\n \nMyExperiment\n.\nRunParams\n]\n\n               \nisValid\n:\n \n1\n\n    \nnControllerOutputs\n:\n \n0\n\n       \nnGeneratorUnits\n:\n \n64\n\n              \nnFactors\n:\n \n8\n\n              \nnNeurons\n:\n \n29\n\n                     \nT\n:\n \n500\n\n               \nnTrials\n:\n \n1560\n\n\n\n\n\nWhose key properties are:\n\n\n\n\ntime\n:\n\n\nnTime\n x \n1\n time vector associated with each of the output fields, which you provided in your \ngenerateRatesForDataset()\n implementation\n\n\ncontroller_outputs\n:\n\n\nnControllerOutputs\n x \nnTime\n. Inferred inputs to the generator network. Or empty, if no controller is used (\nc_co_dim\n \n==\n \n0\n)\n\n\n\n\nfactors\n:\n:\nnFactors\n x \nnTime\n x \nnTrials\n. Factor outputs from the generator network.\n\n\n\n\ngenerator_ics\n:\n\n\nnGeneratorUnits\n x \nnTrials\n. Initial conditions for the generator units.\n\n\ngenerator_states\n:\n\n\nnGeneratorUnits\n x \nnTime\n x \nnTrials\n. Trajectories of the generator units.\n\n\nrates\n:\n\n\nnNeurons\n x \nnTime\n x \nnTrials\n. Inferred firing rates of the neurons\n\n\nvalidInds\n:\n\n\nList of trial indices used in the validation set\n\n\ntrainInds\n:\n\n\nList of trial indices used in the training set\n\n\n\n\nIf the run stitches together multiple datasets, then the \nposteriorMeans\n will be an \nnDatasets\n x 1 vector of \nLFADS.PosteriorMeans\n instances, each corresponding to an included dataset.\n\n\nVisualizing the factors\n\u00b6\n\n\nSingle trial plot of factor 1 on first 10 conditions (color-coded), i.e. \npm\n.\nfactors\n(\n1\n,\n \n:,\n \npm\n.\nconditionId\n \n<\n=\n \n10\n)\n.\n\n\n\n\nCondition-average plot of factor 1 on all conditions, flanked by standard error of the mean.\n\n\n\n\nComparing factor trajectories across datasets\n\u00b6\n\n\nSingle-dataset models\n\u00b6\n\n\nLooking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models\n\n\npmSingleRuns\n \n=\n \n[\nrc\n.\nruns\n(\n1\n).\nloadPosteriorMeans\n();\n \n...\n\n                \nrc\n.\nruns\n(\n2\n).\nloadPosteriorMeans\n();\n \n...\n\n                \nrc\n.\nruns\n(\n3\n).\nloadPosteriorMeans\n()];\n\n\n\n\n\n\n\nStitched multi-session model\n\u00b6\n\n\nHowever, if we load the posterior means for the stitched multi-session model (named \nall\n). we find that these same factor trajectories are now highly similar across datasets.\n\n\n\n\nWe can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot.\n\n\n\n\nWe can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the",
            "title": "Analyzing LFADS Posterior Means"
        },
        {
            "location": "/analysis/#loading-and-analyzing-lfads-posterior-means",
            "text": "",
            "title": "Loading and Analyzing LFADS Posterior Means"
        },
        {
            "location": "/analysis/#reusing-the-drive_script",
            "text": "The  LFADS.Run  instances you created earlier with the  drive_script  uniquely specify the location of all LFADS related files on disk. In addition to enabling you to generate the inputs and scripts required to train LFADS, these objects also make it straightforward to load the results of LFADS back into Matlab for subsequent analysis. These results include the estimates of the posterior mean of the LFADS generator units, factors, and rates for each trial, as well as the learned model parameters.  Using your  RunCollection   rc , you can access individual runs by indexing directly into  rc.runs  which has size  rc.nRunSpecs  x  rc.nParams . You can also search for a specific run using  rc.findRun  run1   =   rc . findRuns ( 'single_dataset001' ,   'param_pqQbzB' );   The first argument searches over the  RunSpec s by name, the second searches over the  RunParams  by hash value.",
            "title": "Reusing the drive_script"
        },
        {
            "location": "/analysis/#loading-the-posterior-means",
            "text": "Using the  Run  instance, you can verify that its posterior means have been written to disk (indicating that the model has finished training successfully):  >>   run1 . checkPosteriorMeansExist () \n\n   logical \n\n    1   And then load the posterior means using: pm   =   run1 . loadPosteriorMeans ();   Or alternatively, load all of your runs\u2019 posterior means by calling  rc.loadPosteriorMeans() . Then you can access the cached posterior means in each run\u2019s  .posteriorMeans  property.  pm  will be an instance of  LFADS.PosteriorMeans :  >>   pm   =   rc . runs ( 1 ). posteriorMeans  pm   = \n\n   PosteriorMeans   with   properties : \n\n                   time :   [ 500 x1   double ] \n     controller_outputs :   [] \n                factors :   [ 8 x500x1560   double ] \n          generator_ics :   [ 64 x1560   double ] \n       generator_states :   [ 64 x500x1560   double ] \n                  rates :   [ 29 x500x1560   double ] \n              validInds :   [ 312 x1   uint16 ] \n              trainInds :   [ 1248 x1   double ] \n                 params :   [ 1 x1   MyExperiment . RunParams ] \n                isValid :   1 \n     nControllerOutputs :   0 \n        nGeneratorUnits :   64 \n               nFactors :   8 \n               nNeurons :   29 \n                      T :   500 \n                nTrials :   1560   Whose key properties are:   time :  nTime  x  1  time vector associated with each of the output fields, which you provided in your  generateRatesForDataset()  implementation  controller_outputs :  nControllerOutputs  x  nTime . Inferred inputs to the generator network. Or empty, if no controller is used ( c_co_dim   ==   0 )   factors :\n: nFactors  x  nTime  x  nTrials . Factor outputs from the generator network.   generator_ics :  nGeneratorUnits  x  nTrials . Initial conditions for the generator units.  generator_states :  nGeneratorUnits  x  nTime  x  nTrials . Trajectories of the generator units.  rates :  nNeurons  x  nTime  x  nTrials . Inferred firing rates of the neurons  validInds :  List of trial indices used in the validation set  trainInds :  List of trial indices used in the training set   If the run stitches together multiple datasets, then the  posteriorMeans  will be an  nDatasets  x 1 vector of  LFADS.PosteriorMeans  instances, each corresponding to an included dataset.",
            "title": "Loading the posterior means"
        },
        {
            "location": "/analysis/#visualizing-the-factors",
            "text": "Single trial plot of factor 1 on first 10 conditions (color-coded), i.e.  pm . factors ( 1 ,   :,   pm . conditionId   < =   10 ) .   Condition-average plot of factor 1 on all conditions, flanked by standard error of the mean.",
            "title": "Visualizing the factors"
        },
        {
            "location": "/analysis/#comparing-factor-trajectories-across-datasets",
            "text": "",
            "title": "Comparing factor trajectories across datasets"
        },
        {
            "location": "/analysis/#single-dataset-models",
            "text": "Looking at the 3 single-dataset model runs, we can plot single trials from the first 10 conditions for each of the 3 datasets. Note that the initial condition and subsequent 3 dimensional Lorenz atractor trajectory that defines each of the conditions is fixed and constant across datasets. However, we find that the factor 1 trajectories differ across the 3 datasets. As these factor trajectories are independently generated by 3 separate LFADS models  pmSingleRuns   =   [ rc . runs ( 1 ). loadPosteriorMeans ();   ... \n                 rc . runs ( 2 ). loadPosteriorMeans ();   ... \n                 rc . runs ( 3 ). loadPosteriorMeans ()];",
            "title": "Single-dataset models"
        },
        {
            "location": "/analysis/#stitched-multi-session-model",
            "text": "However, if we load the posterior means for the stitched multi-session model (named  all ). we find that these same factor trajectories are now highly similar across datasets.   We can then take all 8 factors, average within conditions, and perform dimensionality reduction using PCA to visualize the factor trajectories in the top 2 principal components. Here are the factor trajectories from all 65 conditions from the first dataset. The initial conditions are marked with a black dot.   We can also plot the condition-averaged factor trajectories from all 3 datasets in the same PC space. Here are 10 conditions (color coded by condition). Note the similarity of each of the sets of 3 traces of the same color, which indicates that LFADS has successfully stitched these datasets together using the",
            "title": "Stitched multi-session model"
        },
        {
            "location": "/trained_params/",
            "text": "Loading the trained LFADS model parameters\n\u00b6\n\n\nLoading the \nmodel_params\n\u00b6\n\n\nAfter the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called \nlfadsOutput/model_params\n, as described \nhere\n. If you used the \nrun queue\n to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed.\n\n\nmodel_params\n is an HD5 file that contains all of the model parameters. To load these, each \nLFADS.Run\n provides a method \nrun.loadModelTrainedParams()\n that will return an instance of \nLFADS.ModelTrainedParameters\n. This instance will have many fields, corresponding to the set of parameters learned by LFADS.\n\n\nList of model trained parameters\n\u00b6\n\n\nBelow is an annotated list of the properties found within the \nModelTrainedParameters\n instance, along with the size of each parameter relative to hyperparameters specified in the corresponding \nRunParams\n.\n\n\nFor reference, here is the schematic of an LFADS model:\n\n\n\n\nRead-in from spikes to input factors\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nx_to_infac_W\n\n\nreadin alignment weights, mapping from counts to input factors\n\n\nnDatasets\n x 1 cell of \nnNeuronsThisDataset\n x \nc_factors_dim\n\n\n\n\n\n\nx_to_infac_b\n\n\nreadin alignment biases to input factors\n\n\nnDatasets\n x 1 cell of 1 x \nc_factors_dim\n\n\n\n\n\n\n\n\nInitial condition encoder (forward)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nic_enc_fwd_t0\n\n\nforward IC encoder prior on t0\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_fwd_gru_xh_to_gates_ru_W\n\n\nforward IC encoder GRU, mapping input+hiddens to gates r and u, weights\n\n\n(\nc_ic_enc_dim\n + factors_dim) x (2 * \nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_fwd_gru_xh_to_gates_ru_b\n\n\nforward IC encoder GRU bmapping input+hiddens to gates r and u, biases\n\n\n1 x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_fwd_gru_xrh_to_c_W\n\n\nforward IC encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ic_enc_dim\n + \nc_factors_dim\n) x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_fwd_gru_xrh_to_c_b\n\n\nforward IC encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\n\n\nInitial condition encoder (reverse)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nic_enc_rev_t0\n\n\nreverse IC encoder prior on t0\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_rev_gru_xh_to_gates_ru_W\n\n\nreverse IC encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(\nc_factors_dim\n + \nc_ic_enc_dim\n) x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_rev_gru_xh_to_gates_ru_b\n\n\nreverse IC encoder GRU bmapping input+hidden to gates r and u, biases\n\n\n1 x (2*\nc_ic_enc_dim\n)\n\n\n\n\n\n\nic_enc_rev_gru_xrh_to_c_W\n\n\nreverse IC encoder GRU mapping input+r+hidden to candidates (weights)\n\n\n(\nc_ic_enc_dim\n + \nc_factors_dim\n) x \nc_ic_enc_dim\n\n\n\n\n\n\nic_enc_rev_gru_xrh_to_c_b\n\n\nreverse IC encoder GRU mapping input+r+hidden to candidates (bias)\n\n\n1 x \nc_ic_enc_dim\n\n\n\n\n\n\n\n\nInitial condition g0\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nprior_g0_mean\n\n\nMean parameter in prior on initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nprior_g0_logvar\n\n\nLogvar parameter in prior on initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_mean_W\n\n\nWeights for mean parameter in posterior of the initial condition g0\n\n\n(2*\nc_ic_enc_dim\n) x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_mean_b\n\n\nBias for mean parameter in posterior of the initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_logvar_W\n\n\nWeights for logvar parameter in posterior of the initial condition g0\n\n\n(2*\nc_ic_enc_dim\n) x \nc_ic_dim\n\n\n\n\n\n\nic_enc_to_posterior_g0_logvar_b\n\n\nBias for logvar parameter in posterior of the initial condition g0\n\n\n1 x \nc_ic_dim\n\n\n\n\n\n\ng0_to_gen_ic_W\n\n\nmapping from g0 to generator initial condition, weights\n\n\nc_ic_dim\n x \nc_gen_dim\n\n\n\n\n\n\ng0_to_gen_ic_b\n\n\nmapping from g0 to generator initial condition, bias\n\n\n1 x \nc_gen_dim\n\n\n\n\n\n\n\n\nController encoder (forward)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nci_enc_fwd_t0\n\n\nforward controller prior on t0\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\nci_enc_fwd_gru_xh_to_ru_W\n\n\nforward controller encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(\nci_enc_dim\n + \nc_factors_dim\n) x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xh_to_ru_b\n\n\nforward controller encoder GRU, mapping input+hidden to gates r and u, bias\n\n\n1 x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xrh_to_c_W\n\n\nforward controller encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ci_enc_dim\n + \nc_factors_dim\n) x \nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_fwd_gru_xrh_to_c_b\n\n\nforward controller encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\n\n\nController encoder (reverse)\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nci_enc_rev_t0\n\n\nreverse controller prior on t0\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\nci_enc_rev_gru_xh_to_ru_W\n\n\nreverse controller encoder GRU, mapping input+hidden to gates r and u, weights\n\n\n(ci_enc_dim + factors_dim) x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xh_to_ru_b\n\n\nreverse controller encoder GRU, mapping input+hidden to gates r and u, bias\n\n\n1 x (2*\nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xrh_to_c_W\n\n\nreverse controller encoder GRU mapping input, r, and hidden to candidates (weights)\n\n\n(\nc_ci_enc_dim\n + \nc_factors_dim\n) x \nc_ci_enc_dim\n)\n\n\n\n\n\n\nci_enc_rev_gru_xrh_to_c_b\n\n\nreverse controller encoder GRU mapping input, r, and hidden to candidates (bias)\n\n\n1 x \nc_ci_enc_dim\n\n\n\n\n\n\n\n\nControlller RNN\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ncon_gengru_x_to_ru_W\n\n\ncontroller GenGRU, mapping input to gates r+u, weights\n\n\n(\nc_ci_enc_dim\n * 2 + \nc_factors_dim\n) x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_h_to_ru_W\n\n\ncontroller GenGRU, mapping hidden to gates r+u, weights\n\n\nc_con_dim\n x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_h_to_ru_b\n\n\ncontroller GenGRU, mapping hidden to gates r+u, weights\n\n\n1 x (2*\nc_con_dim\n)\n\n\n\n\n\n\ncon_gengru_x_to_c_W\n\n\ncontroller GenGRU, mapping input to candidates, weights\n\n\n(\nc_ci_enc_dim\n * 2 + \nc_factors_dim\n) x \nc_con_dim\n\n\n\n\n\n\ncon_gengru_rh_to_c_b\n\n\ncontroller GenGRU, mapping r+hidden to candidates, bias\n\n\n1 x \nc_con_dim\n\n\n\n\n\n\n\n\nController output co\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\nprior_ar1_logevars\n\n\nautoregressive prior on controller outputs\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\nprior_ar1_logatau\n\n\nautoregressive time constant prior on controller outputs\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\ncon_co\n\n\nprior on controller output\n\n\n1 x \nc_con_dim\n\n\n\n\n\n\ncon_to_posterior_co_mean_W\n\n\nmapping from controller to mean parameter of co, weights\n\n\nc_con_dim\n x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_mean_b\n\n\nmapping from controller to mean parameter of co, biases\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_logvar_W\n\n\nmapping from controller to logvar parameter of co, weights\n\n\nc_con_dim\n x \nc_co_dim\n\n\n\n\n\n\ncon_to_posterior_co_logvar_b\n\n\nmapping from controller to logvar parameter of co, biases\n\n\n1 x \nc_co_dim\n\n\n\n\n\n\n\n\nGenerator RNN\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ngen_gengru_x_to_ru_W\n\n\ngenerator GRU, mapping from input to gates r+u, weights\n\n\nc_co_dim\n x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_h_to_ru_W\n\n\ngenerator GRU, mapping from input to gates r+u, weights\n\n\nc_gen_dim\n x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_h_to_ru_b\n\n\ngenerator GRU, mapping from input to gates r+u, biases\n\n\n1 x (2*\nc_gen_dim\n)\n\n\n\n\n\n\ngen_gengru_x_to_c_W\n\n\ngenerator GRU, mapping from input to candidates, weights\n\n\nc_co_dim\n x \nc_gen_dim\n\n\n\n\n\n\ngen_gengru_rh_to_c_W\n\n\ngenerator GRU, mapping from r+hidden to candidates, weights\n\n\nc_gen_dim\n x \nc_gen_dim\n\n\n\n\n\n\ngen_gengru_rh_to_c_b\n\n\ngenerator GRU, mapping from r+hidden to candidates, biases\n\n\n1 x \nc_gen_dim\n\n\n\n\n\n\n\n\nGenerator output\n\u00b6\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nSize\n\n\n\n\n\n\n\n\n\n\ngen_to_factors_W\n\n\nmapping from generator to factors, weights\n\n\nc_gen_dim\n x \nc_factors_dim\n\n\n\n\n\n\nfactors_to_logrates_W\n\n\nreadout alignment weights\n\n\nnDatasets\n x 1 cell of \nc_factors_dim\n x \nnNeuronsThisDataset\n\n\n\n\n\n\nfactors_to_logrates_b\n\n\nreadout alignment biases\n\n\nnDatasets\n x 1 cell of 1 x \nnNeuronsThisDataset\n\n\n\n\n\n\n\n\nLoading \nmodel_params\n for Lorenz example\n\u00b6\n\n\nWe can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with \nc_co_dim == 0\n.\n\n\n>>\n \nmtp\n \n=\n \nrc\n.\nfindRuns\n(\n'all'\n,\n \n1\n).\nloadModelTrainedParams\n()\n\n\n\nans\n \n=\n\n\n  \nModelTrainedParams\n \nwith\n \nproperties\n:\n\n\n   \nRead\n-\nin\n \nfrom\n \nspikes\n \nto\n \ninput\n \nfactors\n\n                       \nx_to_infac_W\n:\n \n{\n3\nx1\n \ncell\n}\n\n                       \nx_to_infac_b\n:\n \n{\n3\nx1\n \ncell\n}\n\n\n   \nInitial\n \ncondition\n \nencoder\n \n(\nforward\n)\n\n                      \nic_enc_fwd_t0\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_fwd_gru_xh_to_gates_ru_W\n:\n \n[\n128\nx72\n \nsingle\n]\n\n    \nic_enc_fwd_gru_xh_to_gates_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n          \nic_enc_fwd_gru_xrh_to_c_W\n:\n \n[\n64\nx72\n \nsingle\n]\n\n          \nic_enc_fwd_gru_xrh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nInitial\n \ncondition\n \nencoder\n \n(\nreverse\n)\n\n                      \nic_enc_rev_t0\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_rev_gru_xh_to_gates_ru_W\n:\n \n[\n128\nx72\n \nsingle\n]\n\n    \nic_enc_rev_gru_xh_to_gates_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n          \nic_enc_rev_gru_xrh_to_c_W\n:\n \n[\n64\nx72\n \nsingle\n]\n\n          \nic_enc_rev_gru_xrh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nInitial\n \ncondition\n \ng0\n\n                      \nprior_g0_mean\n:\n \n[\n64\nx1\n \nsingle\n]\n\n                    \nprior_g0_logvar\n:\n \n[\n64\nx1\n \nsingle\n]\n\n      \nic_enc_to_posterior_g0_mean_W\n:\n \n[\n64\nx128\n \nsingle\n]\n\n      \nic_enc_to_posterior_g0_mean_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n    \nic_enc_to_posterior_g0_logvar_W\n:\n \n[\n64\nx128\n \nsingle\n]\n\n    \nic_enc_to_posterior_g0_logvar_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n                     \ng0_to_gen_ic_W\n:\n \n[]\n\n                     \ng0_to_gen_ic_b\n:\n \n[]\n\n\n   \nController\n \nencoder\n \n(\nforward\n)\n\n                      \nci_enc_fwd_t0\n:\n \n[]\n\n          \nci_enc_fwd_gru_xh_to_ru_W\n:\n \n[]\n\n          \nci_enc_fwd_gru_xh_to_ru_b\n:\n \n[]\n\n          \nci_enc_fwd_gru_xrh_to_c_W\n:\n \n[]\n\n          \nci_enc_fwd_gru_xrh_to_c_b\n:\n \n[]\n\n\n   \nController\n \nencoder\n \n(\nreverse\n)\n\n                      \nci_enc_rev_t0\n:\n \n[]\n\n          \nci_enc_rev_gru_xh_to_ru_W\n:\n \n[]\n\n          \nci_enc_rev_gru_xh_to_ru_b\n:\n \n[]\n\n          \nci_enc_rev_gru_xrh_to_c_W\n:\n \n[]\n\n          \nci_enc_rev_gru_xrh_to_c_b\n:\n \n[]\n\n\n   \nControlller\n \nRNN\n\n               \ncon_gengru_x_to_ru_W\n:\n \n[]\n\n               \ncon_gengru_h_to_ru_W\n:\n \n[]\n\n               \ncon_gengru_h_to_ru_b\n:\n \n[]\n\n                \ncon_gengru_x_to_c_W\n:\n \n[]\n\n               \ncon_gengru_rh_to_c_W\n:\n \n[]\n\n               \ncon_gengru_rh_to_c_b\n:\n \n[]\n\n\n   \nController\n \noutput\n \nco\n\n                 \nprior_ar1_logevars\n:\n \n[]\n\n                  \nprior_ar1_logatau\n:\n \n[]\n\n                             \ncon_co\n:\n \n[]\n\n         \ncon_to_posterior_co_mean_W\n:\n \n[]\n\n         \ncon_to_posterior_co_mean_b\n:\n \n[]\n\n       \ncon_to_posterior_co_logvar_W\n:\n \n[]\n\n       \ncon_to_posterior_co_logvar_b\n:\n \n[]\n\n\n   \nGenerator\n \nRNN\n\n               \ngen_gengru_x_to_ru_W\n:\n \n[]\n\n               \ngen_gengru_h_to_ru_W\n:\n \n[\n128\nx64\n \nsingle\n]\n\n               \ngen_gengru_h_to_ru_b\n:\n \n[\n128\nx1\n \nsingle\n]\n\n                \ngen_gengru_x_to_c_W\n:\n \n[]\n\n               \ngen_gengru_rh_to_c_W\n:\n \n[\n64\nx64\n \nsingle\n]\n\n               \ngen_gengru_rh_to_c_b\n:\n \n[\n64\nx1\n \nsingle\n]\n\n\n   \nGenerator\n \noutput\n\n                   \ngen_to_factors_W\n:\n \n[\n8\nx64\n \nsingle\n]\n\n              \nfactors_to_logrates_W\n:\n \n{\n3\nx1\n \ncell\n}\n\n              \nfactors_to_logrates_b\n:\n \n{\n3\nx1\n \ncell\n}\n\n\n\n\n\nThe recurrent connectivity weight matrix of the \nc_gen_dim==64\n GRU generator RNN is given by \nmtp.gen_gengru_rh_to_c_W\n:\n\n\n\n\nAnd the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by \nmtp.factors_to_logrates_W\n:",
            "title": "Loading the trained model parameters"
        },
        {
            "location": "/trained_params/#loading-the-trained-lfads-model-parameters",
            "text": "",
            "title": "Loading the trained LFADS model parameters"
        },
        {
            "location": "/trained_params/#loading-the-model_params",
            "text": "After the LFADS run has finished, you will need to have LFADS write the model parameters to disk in a file called  lfadsOutput/model_params , as described  here . If you used the  run queue  to automatically launch all of your runs, you can skip this step as it was taken care of for you after training was completed.  model_params  is an HD5 file that contains all of the model parameters. To load these, each  LFADS.Run  provides a method  run.loadModelTrainedParams()  that will return an instance of  LFADS.ModelTrainedParameters . This instance will have many fields, corresponding to the set of parameters learned by LFADS.",
            "title": "Loading the model_params"
        },
        {
            "location": "/trained_params/#list-of-model-trained-parameters",
            "text": "Below is an annotated list of the properties found within the  ModelTrainedParameters  instance, along with the size of each parameter relative to hyperparameters specified in the corresponding  RunParams .  For reference, here is the schematic of an LFADS model:",
            "title": "List of model trained parameters"
        },
        {
            "location": "/trained_params/#read-in-from-spikes-to-input-factors",
            "text": "Name  Description  Size      x_to_infac_W  readin alignment weights, mapping from counts to input factors  nDatasets  x 1 cell of  nNeuronsThisDataset  x  c_factors_dim    x_to_infac_b  readin alignment biases to input factors  nDatasets  x 1 cell of 1 x  c_factors_dim",
            "title": "Read-in from spikes to input factors"
        },
        {
            "location": "/trained_params/#initial-condition-encoder-forward",
            "text": "Name  Description  Size      ic_enc_fwd_t0  forward IC encoder prior on t0  1 x  c_ic_enc_dim    ic_enc_fwd_gru_xh_to_gates_ru_W  forward IC encoder GRU, mapping input+hiddens to gates r and u, weights  ( c_ic_enc_dim  + factors_dim) x (2 *  c_ic_enc_dim )    ic_enc_fwd_gru_xh_to_gates_ru_b  forward IC encoder GRU bmapping input+hiddens to gates r and u, biases  1 x (2* c_ic_enc_dim )    ic_enc_fwd_gru_xrh_to_c_W  forward IC encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ic_enc_dim  +  c_factors_dim ) x  c_ic_enc_dim    ic_enc_fwd_gru_xrh_to_c_b  forward IC encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ic_enc_dim",
            "title": "Initial condition encoder (forward)"
        },
        {
            "location": "/trained_params/#initial-condition-encoder-reverse",
            "text": "Name  Description  Size      ic_enc_rev_t0  reverse IC encoder prior on t0  1 x  c_ic_enc_dim    ic_enc_rev_gru_xh_to_gates_ru_W  reverse IC encoder GRU, mapping input+hidden to gates r and u, weights  ( c_factors_dim  +  c_ic_enc_dim ) x (2* c_ic_enc_dim )    ic_enc_rev_gru_xh_to_gates_ru_b  reverse IC encoder GRU bmapping input+hidden to gates r and u, biases  1 x (2* c_ic_enc_dim )    ic_enc_rev_gru_xrh_to_c_W  reverse IC encoder GRU mapping input+r+hidden to candidates (weights)  ( c_ic_enc_dim  +  c_factors_dim ) x  c_ic_enc_dim    ic_enc_rev_gru_xrh_to_c_b  reverse IC encoder GRU mapping input+r+hidden to candidates (bias)  1 x  c_ic_enc_dim",
            "title": "Initial condition encoder (reverse)"
        },
        {
            "location": "/trained_params/#initial-condition-g0",
            "text": "Name  Description  Size      prior_g0_mean  Mean parameter in prior on initial condition g0  1 x  c_ic_dim    prior_g0_logvar  Logvar parameter in prior on initial condition g0  1 x  c_ic_dim    ic_enc_to_posterior_g0_mean_W  Weights for mean parameter in posterior of the initial condition g0  (2* c_ic_enc_dim ) x  c_ic_dim    ic_enc_to_posterior_g0_mean_b  Bias for mean parameter in posterior of the initial condition g0  1 x  c_ic_dim    ic_enc_to_posterior_g0_logvar_W  Weights for logvar parameter in posterior of the initial condition g0  (2* c_ic_enc_dim ) x  c_ic_dim    ic_enc_to_posterior_g0_logvar_b  Bias for logvar parameter in posterior of the initial condition g0  1 x  c_ic_dim    g0_to_gen_ic_W  mapping from g0 to generator initial condition, weights  c_ic_dim  x  c_gen_dim    g0_to_gen_ic_b  mapping from g0 to generator initial condition, bias  1 x  c_gen_dim",
            "title": "Initial condition g0"
        },
        {
            "location": "/trained_params/#controller-encoder-forward",
            "text": "Name  Description  Size      ci_enc_fwd_t0  forward controller prior on t0  1 x  c_ci_enc_dim    ci_enc_fwd_gru_xh_to_ru_W  forward controller encoder GRU, mapping input+hidden to gates r and u, weights  ( ci_enc_dim  +  c_factors_dim ) x (2* c_ci_enc_dim )    ci_enc_fwd_gru_xh_to_ru_b  forward controller encoder GRU, mapping input+hidden to gates r and u, bias  1 x (2* c_ci_enc_dim )    ci_enc_fwd_gru_xrh_to_c_W  forward controller encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ci_enc_dim  +  c_factors_dim ) x  c_ci_enc_dim )    ci_enc_fwd_gru_xrh_to_c_b  forward controller encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ci_enc_dim",
            "title": "Controller encoder (forward)"
        },
        {
            "location": "/trained_params/#controller-encoder-reverse",
            "text": "Name  Description  Size      ci_enc_rev_t0  reverse controller prior on t0  1 x  c_ci_enc_dim    ci_enc_rev_gru_xh_to_ru_W  reverse controller encoder GRU, mapping input+hidden to gates r and u, weights  (ci_enc_dim + factors_dim) x (2* c_ci_enc_dim )    ci_enc_rev_gru_xh_to_ru_b  reverse controller encoder GRU, mapping input+hidden to gates r and u, bias  1 x (2* c_ci_enc_dim )    ci_enc_rev_gru_xrh_to_c_W  reverse controller encoder GRU mapping input, r, and hidden to candidates (weights)  ( c_ci_enc_dim  +  c_factors_dim ) x  c_ci_enc_dim )    ci_enc_rev_gru_xrh_to_c_b  reverse controller encoder GRU mapping input, r, and hidden to candidates (bias)  1 x  c_ci_enc_dim",
            "title": "Controller encoder (reverse)"
        },
        {
            "location": "/trained_params/#controlller-rnn",
            "text": "Name  Description  Size      con_gengru_x_to_ru_W  controller GenGRU, mapping input to gates r+u, weights  ( c_ci_enc_dim  * 2 +  c_factors_dim ) x (2* c_con_dim )    con_gengru_h_to_ru_W  controller GenGRU, mapping hidden to gates r+u, weights  c_con_dim  x (2* c_con_dim )    con_gengru_h_to_ru_b  controller GenGRU, mapping hidden to gates r+u, weights  1 x (2* c_con_dim )    con_gengru_x_to_c_W  controller GenGRU, mapping input to candidates, weights  ( c_ci_enc_dim  * 2 +  c_factors_dim ) x  c_con_dim    con_gengru_rh_to_c_b  controller GenGRU, mapping r+hidden to candidates, bias  1 x  c_con_dim",
            "title": "Controlller RNN"
        },
        {
            "location": "/trained_params/#controller-output-co",
            "text": "Name  Description  Size      prior_ar1_logevars  autoregressive prior on controller outputs  1 x  c_co_dim    prior_ar1_logatau  autoregressive time constant prior on controller outputs  1 x  c_co_dim    con_co  prior on controller output  1 x  c_con_dim    con_to_posterior_co_mean_W  mapping from controller to mean parameter of co, weights  c_con_dim  x  c_co_dim    con_to_posterior_co_mean_b  mapping from controller to mean parameter of co, biases  1 x  c_co_dim    con_to_posterior_co_logvar_W  mapping from controller to logvar parameter of co, weights  c_con_dim  x  c_co_dim    con_to_posterior_co_logvar_b  mapping from controller to logvar parameter of co, biases  1 x  c_co_dim",
            "title": "Controller output co"
        },
        {
            "location": "/trained_params/#generator-rnn",
            "text": "Name  Description  Size      gen_gengru_x_to_ru_W  generator GRU, mapping from input to gates r+u, weights  c_co_dim  x (2* c_gen_dim )    gen_gengru_h_to_ru_W  generator GRU, mapping from input to gates r+u, weights  c_gen_dim  x (2* c_gen_dim )    gen_gengru_h_to_ru_b  generator GRU, mapping from input to gates r+u, biases  1 x (2* c_gen_dim )    gen_gengru_x_to_c_W  generator GRU, mapping from input to candidates, weights  c_co_dim  x  c_gen_dim    gen_gengru_rh_to_c_W  generator GRU, mapping from r+hidden to candidates, weights  c_gen_dim  x  c_gen_dim    gen_gengru_rh_to_c_b  generator GRU, mapping from r+hidden to candidates, biases  1 x  c_gen_dim",
            "title": "Generator RNN"
        },
        {
            "location": "/trained_params/#generator-output",
            "text": "Name  Description  Size      gen_to_factors_W  mapping from generator to factors, weights  c_gen_dim  x  c_factors_dim    factors_to_logrates_W  readout alignment weights  nDatasets  x 1 cell of  c_factors_dim  x  nNeuronsThisDataset    factors_to_logrates_b  readout alignment biases  nDatasets  x 1 cell of 1 x  nNeuronsThisDataset",
            "title": "Generator output"
        },
        {
            "location": "/trained_params/#loading-model_params-for-lorenz-example",
            "text": "We can load the model trained parameters for our multi-dataset stitching run as follows. Note that all of the entries associated with the controller and inferred inputs to the generator are missing, as we trained without inferred inputs with  c_co_dim == 0 .  >>   mtp   =   rc . findRuns ( 'all' ,   1 ). loadModelTrainedParams ()  ans   = \n\n   ModelTrainedParams   with   properties : \n\n    Read - in   from   spikes   to   input   factors \n                        x_to_infac_W :   { 3 x1   cell } \n                        x_to_infac_b :   { 3 x1   cell } \n\n    Initial   condition   encoder   ( forward ) \n                       ic_enc_fwd_t0 :   [ 64 x1   single ] \n     ic_enc_fwd_gru_xh_to_gates_ru_W :   [ 128 x72   single ] \n     ic_enc_fwd_gru_xh_to_gates_ru_b :   [ 128 x1   single ] \n           ic_enc_fwd_gru_xrh_to_c_W :   [ 64 x72   single ] \n           ic_enc_fwd_gru_xrh_to_c_b :   [ 64 x1   single ] \n\n    Initial   condition   encoder   ( reverse ) \n                       ic_enc_rev_t0 :   [ 64 x1   single ] \n     ic_enc_rev_gru_xh_to_gates_ru_W :   [ 128 x72   single ] \n     ic_enc_rev_gru_xh_to_gates_ru_b :   [ 128 x1   single ] \n           ic_enc_rev_gru_xrh_to_c_W :   [ 64 x72   single ] \n           ic_enc_rev_gru_xrh_to_c_b :   [ 64 x1   single ] \n\n    Initial   condition   g0 \n                       prior_g0_mean :   [ 64 x1   single ] \n                     prior_g0_logvar :   [ 64 x1   single ] \n       ic_enc_to_posterior_g0_mean_W :   [ 64 x128   single ] \n       ic_enc_to_posterior_g0_mean_b :   [ 64 x1   single ] \n     ic_enc_to_posterior_g0_logvar_W :   [ 64 x128   single ] \n     ic_enc_to_posterior_g0_logvar_b :   [ 64 x1   single ] \n                      g0_to_gen_ic_W :   [] \n                      g0_to_gen_ic_b :   [] \n\n    Controller   encoder   ( forward ) \n                       ci_enc_fwd_t0 :   [] \n           ci_enc_fwd_gru_xh_to_ru_W :   [] \n           ci_enc_fwd_gru_xh_to_ru_b :   [] \n           ci_enc_fwd_gru_xrh_to_c_W :   [] \n           ci_enc_fwd_gru_xrh_to_c_b :   [] \n\n    Controller   encoder   ( reverse ) \n                       ci_enc_rev_t0 :   [] \n           ci_enc_rev_gru_xh_to_ru_W :   [] \n           ci_enc_rev_gru_xh_to_ru_b :   [] \n           ci_enc_rev_gru_xrh_to_c_W :   [] \n           ci_enc_rev_gru_xrh_to_c_b :   [] \n\n    Controlller   RNN \n                con_gengru_x_to_ru_W :   [] \n                con_gengru_h_to_ru_W :   [] \n                con_gengru_h_to_ru_b :   [] \n                 con_gengru_x_to_c_W :   [] \n                con_gengru_rh_to_c_W :   [] \n                con_gengru_rh_to_c_b :   [] \n\n    Controller   output   co \n                  prior_ar1_logevars :   [] \n                   prior_ar1_logatau :   [] \n                              con_co :   [] \n          con_to_posterior_co_mean_W :   [] \n          con_to_posterior_co_mean_b :   [] \n        con_to_posterior_co_logvar_W :   [] \n        con_to_posterior_co_logvar_b :   [] \n\n    Generator   RNN \n                gen_gengru_x_to_ru_W :   [] \n                gen_gengru_h_to_ru_W :   [ 128 x64   single ] \n                gen_gengru_h_to_ru_b :   [ 128 x1   single ] \n                 gen_gengru_x_to_c_W :   [] \n                gen_gengru_rh_to_c_W :   [ 64 x64   single ] \n                gen_gengru_rh_to_c_b :   [ 64 x1   single ] \n\n    Generator   output \n                    gen_to_factors_W :   [ 8 x64   single ] \n               factors_to_logrates_W :   { 3 x1   cell } \n               factors_to_logrates_b :   { 3 x1   cell }   The recurrent connectivity weight matrix of the  c_gen_dim==64  GRU generator RNN is given by  mtp.gen_gengru_rh_to_c_W :   And the per-dataset readout matrices mapping factors to neurons\u2019 log(rates) are given by  mtp.factors_to_logrates_W :",
            "title": "Loading model_params for Lorenz example"
        }
    ]
}